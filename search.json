[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rで学ぶ大規模学力調査（Version 1.0）",
    "section": "",
    "text": "はじめに\n本書はRを使い， PISAや TIMSSといった 教育における大規模学力調査（Large Scale Assessment in Education: LSA）を分析する方法を説明しています。 もともと授業のために作成していたのですが， 資料が溜まってきたので，自身の勉強も兼ねてまとめてみることにしました。 いろいろとおかしな記述もあると思いますので，気づいたらご指摘くださいますと幸いです。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#本書の特徴",
    "href": "index.html#本書の特徴",
    "title": "Rで学ぶ大規模学力調査（Version 1.0）",
    "section": "本書の特徴",
    "text": "本書の特徴\n読者がLSAの概要を理解し， とりあえずRで分析ができるようになることを目的に執筆しています。 そのため一般的な社会調査・心理統計・Rの入門書で書かれていることが書かれていなかったり， 順序がバラバラに詰め込まれていたりします。 本書で統計をわかったつもりになるのではなく， あくまで学びの入口として利用してください。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#著者について",
    "href": "index.html#著者について",
    "title": "Rで学ぶ大規模学力調査（Version 1.0）",
    "section": "著者について",
    "text": "著者について\n\n川口俊明（researchmap）\n\n学力調査について発信しています。 本書を読んで学力調査に関心を持った方は，下記の書籍をお買い求めいただけますと幸いです。\n\n\n\n\n\n全国学力テストはなぜ失敗したのか\n\n\n\n\n\n\n\n教育格差の診断書",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "index.html#改定履歴",
    "href": "index.html#改定履歴",
    "title": "Rで学ぶ大規模学力調査（Version 1.0）",
    "section": "改定履歴",
    "text": "改定履歴\n\n2025年2月25日: Version 1.0を公開",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "intro_lsa.html",
    "href": "intro_lsa.html",
    "title": "1  なぜLSAを学ぶのか",
    "section": "",
    "text": "1.1 LSA（Large-Scale Assessment）とは？\n大規模学力調査（Large-scale Assessment: LSA）とは， 集団レベルの学力を調査することを目的に設計された調査のことを指します1。 LSAでは，いわゆるComplex Survey2と呼ばれる複雑な標本抽出を行い， 標本ウェイトやレプリケーション法を利用します。 また，学力の推定には項目反応理論（Item Response Theory: IRT）3を利用する点も特徴です。\nLSAの例として，もっとも有名なのはOECDが実施する PISA （Programme for International Student Assessment）でしょう。 PISAに知名度は劣りますが， TIMSS （Trend in International Mathematics and Science Study）も 国際的なLSAの代表格です。 また，現在もアメリカで行われている全米学力調査 （NAEP） はLSAの「古典」です。 これらの調査は，いずれも複雑な標本抽出とそれに伴う標本ウェイト・レプリケーション法を使った推定， そして項目反応理論による学力推定が行われています。\n大規模な学力調査というと，日本にも毎年度行われている 全国学力・学習状況調査 （いわゆる悉皆調査）が存在します。 しかし悉皆調査はLSAの定義に該当しません。 少なくとも毎年度行われている悉皆調査は， 2024年時点ではIRTを採用していませんし，標本抽出も行っていないからです。 今後の悉皆調査はCBT化に伴いIRTを採用すると言われています4が， そこでもComplex Surveyへの言及はありません。\nむしろLSAに近いのは，3年に1度行われる 経年変化分析調査 や 保護者に対する調査 の方でしょう。 前者はIRTを採用していますし，後者はComplex Surveyの方法論に則っています。 その意味では，「経年変化分析調査＋保護者に対する調査が日本のLSAである」とは言えるかもしれません。\nだから何だ？という声が聞こえてきそうです。 悉皆調査がLSAでないとして，何が問題なのか。 LSAとは何で，どんな利点があるのか。 そもそもComplex SurveyやIRTといった難しそうな考え方が， 教育を考える上で本当に必要なのか。\n本書の目的は，こうした疑問に答えることです。 具体的には，以下の問いに答えることを目指します。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>なぜLSAを学ぶのか</span>"
    ]
  },
  {
    "objectID": "intro_lsa.html#lsalarge-scale-assessmentとは",
    "href": "intro_lsa.html#lsalarge-scale-assessmentとは",
    "title": "1  なぜLSAを学ぶのか",
    "section": "",
    "text": "LSAとは何なのか。そこにどのような技術が採用されているのか。\nLSAで何が明らかになるのか。逆にLSAでない調査は何が明らかにできないのか。\nLSAについて知ることで，私たちにどのような利点があるのか（逆に言えば， 知らないことでどのような問題があるのか）",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>なぜLSAを学ぶのか</span>"
    ]
  },
  {
    "objectID": "intro_lsa.html#なぜlsaを学ぶのか",
    "href": "intro_lsa.html#なぜlsaを学ぶのか",
    "title": "1  なぜLSAを学ぶのか",
    "section": "1.2 なぜLSAを学ぶのか？",
    "text": "1.2 なぜLSAを学ぶのか？\nさっそくですが，なぜLSAについて学ぶべきなのか考えてみましょう。 大きく言うと，次の2点があります。 1点目は，LSAが日本の教育政策に大きな影響を与えているためです。 2点目は，LSAに関する知識が知られていないことが，日本の教育政策・教育実践に 悪影響を与えているからです。\n前者については，PISAの影響力を考えれば容易に理解できるでしょう。 PISA調査は，教育関係者はもちろん， そうでない人も知っているというくらい有名な調査です。 2003年に日本の順位が低下したときは，「PISAショック」と呼ばれるインパクトがありました5し， 「PISA型学力」を育てると主張する書籍も多数存在しています。 これだけインパクトのある調査なのですから，その調査設計について学ぶことには価値があります。\nあわせて注意しておきたいことは， 「PISA調査について言及する人は多いが，PISA調査の設計について知っている人は少ない」 という点です。 これは考えてみると不思議な現象です。 自分がよく知らない調査の結果を宣伝したり，ましてやその結果を根拠に 教育政策を変えたりするのは，かなり危険な行為です。 医療にたとえると，健康診断の数値がよくわからない人が， 「あなたに必要な改善は＊＊＊です！」と言っているようなものです。 ここらで少し時間を使い，果たして世間で言われていることが正しいのかどうか， 真面目に考えてみる価値があると思います。\n後者については，全国学力・学習状況調査がその典型例でしょう。 とくに悉皆調査については，その問題点がたびたび指摘されてきました。 にもかかわらず，2024年になっても問題は改善していません6。 こうした混乱が生じる理由は，悉皆調査がLSAではないというところに根本的な原因があります7。\n残念ながら，日本ではLSAを学ぶ機会がほとんどありません。 そのためLSAを知らない人たちが，全国学力・学習状況調査について議論しているというのが実情です。 これで教育政策が良くなったらほとんど奇跡でしょう。 少なくとも，教育政策について議論する人（ここには，一般の人も含まれます）は LSAについて知るべきだと言うのが本書の主張です。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>なぜLSAを学ぶのか</span>"
    ]
  },
  {
    "objectID": "intro_lsa.html#本書の想定する読者",
    "href": "intro_lsa.html#本書の想定する読者",
    "title": "1  なぜLSAを学ぶのか",
    "section": "1.3 本書の想定する読者",
    "text": "1.3 本書の想定する読者\nここまでの説明でわかったと思いますが， 本書は，学校教育に関わっている人・関心を持つ人であれば， ほとんど統計に関する知識のない人であっても読者として想定しています。 具体的には，教育学部の学部や修士の学生，現職の教員，教育行政関係者，あるいは保護者といった人々です。 もっともパソコンは使いますので， ある程度パソコンの操作ができる（≒ブラウザで本書を読める）技術は必要です。 また2乗や平方根といった概念も出てきますので，高校で習う数学の知識（数Iや数II）も必要です。\n読者の皆さんに準備してほしいものは二つあり，一つはインターネットに接続されたパソコンです。 そこまでの性能は求められませんが， ブラウザ（EdgeとかSafariとかChromeとか）が動く程度のスペックは必要です。 多くの方は，この文章をブラウザで見ているはずなので， その時点で前提はクリアしています。\nもう一つはGoogleアカウントです。 本書では，Rという統計ソフト（あるいはプログラミング言語）を使い， 大規模学力調査について学びます。 その際，Rを手元のパソコンにインストールするのは大変なので， ウェブ上でGoogleのColabというシステムを使ってRを動かします。 Colabについては後で説明しますが，これを使うためには Googleアカウントが必要です。 何らかの理由でGoogleアカウントが取得できない方はColabが利用できませんので， 手元のパソコンにRをインストールする必要があります。 Rのインストールは本書の守備範囲外ですので，各自で調べて作業を行ってください。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>なぜLSAを学ぶのか</span>"
    ]
  },
  {
    "objectID": "intro_lsa.html#本書の構成",
    "href": "intro_lsa.html#本書の構成",
    "title": "1  なぜLSAを学ぶのか",
    "section": "1.4 本書の構成",
    "text": "1.4 本書の構成\nはじめにでも触れましたが， 本書は，ほとんど統計を知らない読者がLSAについて学ぶという（無茶な） 目的を掲げている関係上，やや特殊な構成を取っています。 具体的には，統計学の知識やRの操作を「必要になったら学ぶ」というスタンスで記述しています。 まともに必要な知識を学ぶと，それだけで数冊の本が書けてしまうからです8。 そのため一般的な入門書と比べると，個々の知識がバラバラに詰め込まれていますし， 普通は触れるべき内容をばっさり省略していたりします。 本書で統計や調査をわかったつもりになるのではなく，あくまで学びの入口として利用してください。\n導入では，Rの基本操作や社会調査の基礎知識について学びます。 初学者に厳密な定義や数式は辛いと思いますので， できるだけ数式や厳密な定義を避けたざっくりとした解説にしています。 ただ，数式や厳密な定義を避けているため，逆に分かりづらいという方もいると思います。 そのような方はまとめに挙げた文献を参照してください。\n理論編では，LSAを理解するために重要な要素について解説します。 社会調査に馴染みのある人は，ここから読んだほうがよいかもしれません。 ただ，導入と同じく厳密な説明よりは，ざっくりと概要を伝えることに主眼を置いていますので， 数式や厳密な定義が必要という方はまとめの文献を参照してください。\n実践編では，intsvyというパッケージを使ったPISAやTIMSSの分析法を説明します。 基本的に，コードをそのまま入力すれば動くというレベルで解説しています。 ただ，理屈がわからないと間違った解釈を行う危険が高いので， できるだけ導入や理論編を踏まえたうえで実践編に進むようにしてください。\n補足では，追加トピックとしてPISAやTIMSSのデータを入手する方法を解説しています。 日本以外の国や地域のデータが必要な場合は，この章を参考にしてください。 ただしこれらの調査のデータはファイルサイズが大きく， Colabで作業することができません。 この章だけは，自身のパソコンにRやPythonをインストールして利用できることが前提になります。\n\n\n\n\n1. 川口俊明. (2020年). 全国学力テストはなぜ失敗したのか. 岩波書店.",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>なぜLSAを学ぶのか</span>"
    ]
  },
  {
    "objectID": "intro_lsa.html#footnotes",
    "href": "intro_lsa.html#footnotes",
    "title": "1  なぜLSAを学ぶのか",
    "section": "",
    "text": "Large-scale Assessment in Education↩︎\nComplex Surveys: a guide to analysis using R↩︎\nテストは何を測るのか-項目反応理論の考え方↩︎\n令和７年度以降の全国学力・学習状況調査（悉皆調査）の CBT での実施について↩︎\n【そもそも解説】PISAってなに？全国学力調査が復活したきっかけ↩︎\n全国学力テスト公表方法、見直しへ　全国知事会アンケの反対受け↩︎\n全国学力・学習状況調査の問題点とその要因は拙著[1]を参照してください。↩︎\n日本語で読める社会調査・教育測定・Rに関する優れた入門書・専門書は多数存在します。 関心のある方は，まとめに挙げた文献を参照してください。↩︎",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>なぜLSAを学ぶのか</span>"
    ]
  },
  {
    "objectID": "r_colab.html",
    "href": "r_colab.html",
    "title": "2  R on Colab",
    "section": "",
    "text": "2.1 Rとは\n本書では，R（アール）という統計ソフト （あるいはプログラミング言語）を使って LSAについて学びます。 プログラミングというと難しそうと思うかもしれませんが， ここ数年の急速なコンピュータ技術の進展に伴い， Rを使うハードルは確実に下がっています。 2025年現在では，自分のパソコンにインストールしなくても ブラウザさえあれば，RでLSAの分析ができるようになりました。 Rには，無料でさまざまな統計解析ができるという特徴があります。 ぜひこの機会にRを学び，新たな世界に触れてみてください。\n最初にRの概要について説明します1。 何度か述べたように，Rは，統計解析向けのプログラミング言語です。 統計処理に必要なコードを簡単に書けること・ 高度な統計分析のパッケージが充実していること・ 無料で利用できることもあって， 統計を必要とするさまざまな分野で利用されています。 本書が扱うPISAやTIMSSといった大規模学力調査の分析もRで行うことができます。\n本書がRを薦める理由は，Rが使いやすく，かつ無料であるという点にあります。 社会調査に馴染みのある人の中には， SPSS（エスピーエスエス）や STATA（ステータ，スタータ） といったソフトウェアを知っている人もいるでしょう。 確かに，これらのソフトウェアを使ってLSAを分析することもできます。 ただ，SPSSやSTATAは無償というわけにはいきません。 そのため，大学や大学院に在籍しているあいだは使えても， そこを離れてしまうと使えないという事態に陥りがちです。 無料というのは本当に重要で，とくに財政難・物価高の昨今， たとえ大学教員であっても年に数万円を捻出するのも難しいという人は少なくないと思います。\nRであればパソコンとインターネットさえあれば誰でも使えますし， 分析結果を他者と共有することも容易です。 本書で扱うColabというシステムを使えば， 作成したファイル（.ipynb）を渡せば情報共有は完了です。 Rからhtmlを作成し，成果をインターネットで公開することもできます。 実際に本書は，Rによるレポート作成機能2を使って作成しています。 ついでに，統計に詳しい人の中にはRを使っている人が多いので， Rが使えると，かれらにアドバイスをもらえたり， かれらの使っているコードを真似できたりといった利点もあります。 最初の一歩はハードルが高いかもしれませんが， そこを超えると，さまざまな可能性が広がっているのです。 ぜひこの機会にRに挑戦してみてください。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R on Colab</span>"
    ]
  },
  {
    "objectID": "r_colab.html#colabとは",
    "href": "r_colab.html#colabとは",
    "title": "2  R on Colab",
    "section": "2.2 Colabとは",
    "text": "2.2 Colabとは\nColab（コラボ）とは， Googleが提供するクラウドベース3の開発環境です。 機械学習やデータサイエンスなどで利用されています。 ブラウザ上でPython（パイソン）というプログラム言語を直接実行でき， 特別な準備が要らないという特徴があります。 Colabは基本的にはPythonを利用するための環境なのですが，簡単な設定でRを利用することができるので， 本書ではColabの利用を前提に，Rについて説明していきます。\nRをColabで使うには，いくつかステップを踏む必要があります。 順に解説していきますので，手順に沿って進めてみてください。\n\n2.2.1 Google アカウントを用意する\nColabはGoogleのサービスなので，利用にはGoogle アカウントが必要です。 というわけで，Google アカウントを作成して Googleにログインしてください。 以下の説明は，すでにログインしている前提で行います。\n\n\n2.2.2 Colabのサイトにアクセスする\nまずはColabにアクセスしてください。 おそらく，図 2.1 のような画面が表示されるはずです。 ここで，左下の「ノートブックを新規作成」（青いところ）をクリックすると， 図 2.2 の画面が表示されます。\n\n\n\n\n\n\n図 2.1: Colabにアクセスした画面\n\n\n\n\n\n\n\n\n\n図 2.2: Colabの初期画面\n\n\n\nこれがColabです。 この画面にRのコードや文章を入力しながら， レポートを作成することができます。\n\n\n2.2.3 ランタイムをRに変更する\n初期設定ではPythonが前提になっているので， Rのコードを入力するとエラーが発生します。 これを防ぐには，ひと工夫が必要です。\nまず，メニューにある「ランタイム」をクリックします。 すると，図 2.3 の画面になるので， 「ランタイムのタイプを変更」をクリックします。\n\n\n\n\n\n\n図 2.3: ランタイムのタイプを変更\n\n\n\n続いて，図 2.4 の画面で， 「ランタイムのタイプ」をPython 3からRに変更します。\n\n\n\n\n\n\n図 2.4: ランタイムのタイプ\n\n\n\nこれで準備は完了です。 続いて，R on Colabの使い方を簡単に説明します。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R on Colab</span>"
    ]
  },
  {
    "objectID": "r_colab.html#r-on-colabの基本操作",
    "href": "r_colab.html#r-on-colabの基本操作",
    "title": "2  R on Colab",
    "section": "2.3 R on Colabの基本操作",
    "text": "2.3 R on Colabの基本操作\n\n2.3.1 コードを実行する\nまずは，簡単なコードを実行してみましょう。 ここでは例として，簡単な足し算をしてみましょう。 図 2.5 のように，3 + 4と入力してから「▷」のボタンを押してみてください。 最初は少し時間がかかると思いますが， しばらくすると，図 2.6 のような画面が現れるはずです。\n\n\n\n\n\n\n図 2.5: コードの入力\n\n\n\n\n\n\n\n\n\n図 2.6: 実行結果\n\n\n\n\n\n2.3.2 テキストを追加する\nColabの便利なところは，コードだけでなく， テキストを書けるところです。 テキストを書くには， 図 2.7 のように境界付近にカーソルを移動すると出てくる「＋テキスト」をクリックします。 すると，図 2.8 のように， 新しいブロック（セルと呼びます）が出現します。\n\n\n\n\n\n\n図 2.7: セルを追加\n\n\n\n\n\n\n\n\n\n図 2.8: テキスト入力画面\n\n\n\n図 2.8 の画面をよく見ると，ブロックが左右に分かれていることに気づくかもしれません。 Colabのテキストは，左側の画面に入力を行います。 すると，図 2.9 のように右側にプレビューが現れます。 入力にはいろいろルールがあるのですが， とりあえず次の二つを覚えておくと良いでしょう。\n\n# を最初につけると「見出し」になる\n- をつけると箇条書きになる\n\n他にもいろいろルールがありますが，とりあえずはこれで十分です。 気になる人は，Markdownを調べてみてください。\n\n\n\n\n\n\n図 2.9: テキストの書き方\n\n\n\n\n\n2.3.3 エラーが出た場合\nColabでRを操作していると，エラーが出ることがあります。 普段パソコンを使っていてエラーに遭遇する機会などないですし， メッセージが英語なので驚くと思いますが， プログラミングでは英語のエラーメッセージに遭遇するのはよくあることです。 ですから，落ち着いてエラー表示を読みましょう。 「ここが間違っています」という指示が（英語で）書かれていることもしばしばありますので， その指示に従ってコードを直せば動くようになります。\n\n2.3.3.1 何も起きない\n厳密にはエラーではないのですが，「実行しても何も起きない」と混乱する方がいます。 たとえばa &lt;- 3; b &lt;- 4というコードは，[「aに3，bに4を保存する」という意味です4。 aやbに数値を保存しているだけなので，これだけでは 図 2.10 のように何も起きません。 結果を表示するには，たとえば 図 2.11 のように a + bといった指示を出す必要があるのです。 入力しても「何も起きない」という場合は，自分が結果を出力する指示をしているのかどうか 確認してみてください。\n\n\n\n\n\n\n図 2.10: 何も起きない\n\n\n\n\n\n\n\n\n\n図 2.11: 実行結果が表示される\n\n\n\n\n\n2.3.3.2 日本語が文字化けする\n初期設定のままRを使うと，図を描画した際に文字化けします。 これを防ぐには， 日本語フォントをインストールするコマンドを入力する必要があります。 以下の例では，IPA fontというフォントをColabにインストールしています。\nなお，Colabで日本語フォントを表示する方法はColabの仕様変更に伴って変わることがあります。 以下の設定をしても日本語フォントが表示されない場合は， 仕様が変わってしまったのだなあ・・・と諦めてください （著者も気づいたらできるだけ修正するようにします）。\n# 日本語フォントを導入\nsystem(\"apt-get -y install fonts-ipafont-gothic\")\n# 日本語が表示可能\ncurve(sin(x), -pi, pi, main = \"サインカーブ\")\n\n\n2.3.3.3 ランタイムがRになっていない\nコードをコピペしたはずなのに動かないという場合， ランタイムの設定がPythonのままになっていないか確認してください。 PythonとRは違う言語なので，RのコードをPythonで動かすと普通はエラーが出ます。 （ごく稀に動くこともありますが）。 ポイントは，図 2.12 のようなipython-inputというメッセージです。 Rを動かしているのですから，pythonなどというメッセージがでるはずがありません。\n\n\n\n\n\n\n図 2.12: Runtime Error\n\n\n\n\n\n2.3.3.4 対応するカッコが抜けている\nRに限らず，プログラムでは( )という表現が多用されます。 ここで(1, 2, 3のように対応するカッコが欠けている場合， 図 2.13 のようなエラーが出ます。この場合， 図 2.14 のように対応するカッコを追加すると，エラーは消えます。 なお，( )以外に[ ]や{ }も対応させないとエラーが出ます。\n\n\n\n\n\n\n図 2.13: Error in parse\n\n\n\n\n\n\n\n\n\n図 2.14: カッコを追加\n\n\n\n\n\n2.3.3.5 定義していないオブジェクト\nRでは，さまざまな情報を「オブジェクト」5と呼ばれるものに保存して利用します。 たとえば 図 2.15 では，aに1を，bに2を保存しています （&lt;-は何だ？など気になることもあるでしょうが，とりあえず説明は後回しで）。 ここで唐突に，dと入力するとエラーが出ます。 aやbは定義済みですが，dはまだ定義していないからです。 エラーメッセージにも，object 'd' not found（dが見つからない）と表示されています。\n\n\n\n\n\n\n図 2.15: オブジェクトが見つからない\n\n\n\n\n\n2.3.3.6 奥の手（AIに頼る）\nちなみにエラーが生じると，次のステップ：エラーの説明という表示が 出ることがあります。 ここをクリックするとAIがコードを分析し問題点を解説してくれます （ただし2025年1月時点では説明は英語になります）。 すべての指摘が正しいとはかぎりませんが，問題解決のヒントになることもあるので活用してください。\n\n\n\n2.3.4 その他\nColabの基本操作は，これくらいで十分です。 あとは 図 2.7 の手順で 新しいコードセルかテキストセルを追加し， レポートにまとめていきます。\nセルの上下を入れ替えたいとか， セルを削除したいといった場合は， 図 2.16 の位置にあるボタンを押すと， セルを操作することができますので試してください。\n\n\n\n\n\n\n図 2.16: セルの操作\n\n\n\nまた，作成したノートブックは， Google Driveに自動保存されています。 ファイルを探したい場合は， 「マイドライブ」の中の「Colab Notebooks」を探してみてください （図 2.17 ）。\n\n\n\n\n\n\n図 2.17: 作成したファイルの位置\n\n\n\nColabの説明は，これで終わりです。 いろいろ入力してみて，操作に慣れていってください。\n\n\n\n\n1. 杉野勇. (2017年). 入門・社会統計学: 2 ステップで基礎から【Rで】学ぶ. 法律文化社.",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R on Colab</span>"
    ]
  },
  {
    "objectID": "r_colab.html#footnotes",
    "href": "r_colab.html#footnotes",
    "title": "2  R on Colab",
    "section": "",
    "text": "より詳しく知りたい場合は， 社会調査の観点からRを扱った書籍[1]や ウェブサイトをご覧ください。↩︎\nquartoと言います。↩︎\n「パソコンにソフトをインストールせずに作業できる」くらいの意味です。↩︎\nオブジェクトをご覧ください。↩︎\nオブジェクトをご覧ください。↩︎",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R on Colab</span>"
    ]
  },
  {
    "objectID": "r_basics.html",
    "href": "r_basics.html",
    "title": "3  Rの基本操作",
    "section": "",
    "text": "3.1 四則演算\nそれでは，Rの操作を学んでいきましょう。 ここからはRのコードを示すので，その内容をColabに入力 （あるいはコピペ）してみてください。 たとえば，3 + 4というコードを入力してほしい場合， 本書では次のように書きます。\n薄い灰色の部分が入力してほしいコード（この場合は3 + 4）です。 その下の桃色の部分は，コードの実行結果（この場合は7）になります。 [1]という表示は気にしなくて構いません。\nなお，コードを描いているとエラーが表示されることがあります。 エラーがでた場合は，エラーが出た場合 の内容を思い出し，落ち着いて対処してください。\n最初に，いくつか四則演算を行ってみましょう。 いくつか例を示すので，Colabで試してみてください。\n3 + 4 # 足し算\n\n[1] 7\n\n6 - 8 # 引き算\n\n[1] -2\n\n3 * 2 # 掛け算\n\n[1] 6\n\n5 / 4 # 割り算\n\n[1] 1.25\n\n5^2 # 2乗\n\n[1] 25\nちなみに#から始まる部分はコメントで，Rに入力しても無視されます。 これを利用して，Rのコード内にメモを書くことができます。\n# ここはコメントです。# から先のコメントは実行されません。\nsqrt(4) # メモの例。sqrt()は平方根を計算します。\n\n[1] 2",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rの基本操作</span>"
    ]
  },
  {
    "objectID": "r_basics.html#オブジェクト",
    "href": "r_basics.html#オブジェクト",
    "title": "3  Rの基本操作",
    "section": "3.2 オブジェクト",
    "text": "3.2 オブジェクト\nRにかぎりませんが，プログラミングでは 同じ数値を何度も扱うことがあります。 このような場合，Rではオブジェクトと呼ばれる ものを作って情報を保存します。 オブジェクトに情報を保存することを「格納する」と言います。 Rでは，&lt;-という記号を使ってオブジェクトに情報を格納します。 なお，存在しないオブジェクトを入力すると，エラーが返ります1。\n\na &lt;- 40 # a（というオブジェクト）に40を格納\na + 10 # a + 10を計算\n\n[1] 50\n\nb # bは存在しないので，エラー（Error: object 'b' not found）が返ります。\n\nError: object 'b' not found\n\nb &lt;- 10 # bに10を格納\nb # 今度はエラーは出ません。\n\n[1] 10\n\n\nオブジェクトには，数値以外に文字を格納することもできます。 たとえば文字は，ダブルクオーテーション（\"）でくくって，\"moji\"と表現します。 ダブルクオーテーション無しにmojiと入力すると，それはmojiというオブジェクトを意味します。\n\n\"moji\" # 文字です。\n\n[1] \"moji\"\n\nmoji # mojiというオブジェクトです。存在しないのでエラーが返ります。\n\nError: object 'moji' not found\n\nmoji &lt;- \"moji\" # mojiというオブジェクトに，\"moji\"という文字を格納しています。\nmoji # \"moji\"と表示されます。\n\n[1] \"moji\"",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rの基本操作</span>"
    ]
  },
  {
    "objectID": "r_basics.html#ベクトルとリスト",
    "href": "r_basics.html#ベクトルとリスト",
    "title": "3  Rの基本操作",
    "section": "3.3 ベクトルとリスト",
    "text": "3.3 ベクトルとリスト\n続いて，ベクトルとリストという考え方を学びます。 これは複数の数値や文字をまとめて扱う方法で，Rを使った分析では頻出します。\n最初にベクトルについて説明します。 ベクトルは，c( )という記法で表現します。 たとえば，ある学級（仮にAクラスとします）の5人の児童の成績が， 40点・40点・60点・80点・80点だったとしましょう。 このときAクラスの成績をAというオブジェクトにまとめて扱うには， ベクトルを使って次のように書きます。\n\nA &lt;- c(40, 40, 60, 80, 80) # ベクトルを作成し，Aに格納。\nA # Aの中身が表示されます。\n\n[1] 40 40 60 80 80\n\n\nベクトルには，数値だけでなく文字も格納できます。 ただし数値と文字を混ぜると，すべての要素が文字に変換されてしまうので注意しましょう。\n\nB &lt;- c(\"a\", \"b\", \"c\") # 文字\"a\", \"b\", \"c\"を要素とするベクトルを作成し，Bに格納\nB # Bを表示\n\n[1] \"a\" \"b\" \"c\"\n\nC &lt;- c(1, \"a\", \"b\") # 文字と数値を混ぜたベクトル\nC # 数値1が，文字\"1\"になっています\n\n[1] \"1\" \"a\" \"b\"\n\n\nリストは，文字と数値のように種類の違うものを格納するときに使います。 リストは，list( )という記法で表現します。 リストには数値や文字だけでなく，ベクトルやリストを格納することもできます。 Rでは，複雑な計算結果をリストに格納することもあります。\n\nL1 &lt;- list(1, \"a\", 2) # 数値と文字が混ざったリスト\nL1\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1] 2\n\nL2 &lt;- list(c(1, 2, 3), \"a\", 1) # ベクトルと文字と数値を格納したリスト\nL2\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1] 1",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rの基本操作</span>"
    ]
  },
  {
    "objectID": "r_basics.html#規則的なベクトルの生成",
    "href": "r_basics.html#規則的なベクトルの生成",
    "title": "3  Rの基本操作",
    "section": "3.4 規則的なベクトルの生成",
    "text": "3.4 規則的なベクトルの生成\nRを使っていると，規則的なベクトルが欲しくなるときがあります。 たとえば， 「1から10まで1ずつ増えるベクトル」 「10から30まで5ずつ増える（あるいは減る）ベクトル」 「1から3までを3回繰り返すベクトル」 などです。 Rでは，こうした規則的なベクトルを生成することができます。\n\n1:10 # 1から10まで1ずつ増えるベクトル\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nseq(10, 30, 5) # 10から30まで5ずつ増えるベクトル\n\n[1] 10 15 20 25 30\n\nseq(30, 10, -5) # 30から10まで5ずつ減るベクトル\n\n[1] 30 25 20 15 10\n\nrep(1:3, 3) # 1から3までを3回繰り返すベクトル\n\n[1] 1 2 3 1 2 3 1 2 3",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rの基本操作</span>"
    ]
  },
  {
    "objectID": "r_basics.html#ベクトルやリストの要素にアクセスする",
    "href": "r_basics.html#ベクトルやリストの要素にアクセスする",
    "title": "3  Rの基本操作",
    "section": "3.5 ベクトルやリストの要素にアクセスする",
    "text": "3.5 ベクトルやリストの要素にアクセスする\n作成したベクトルやリストの中身（要素と言います）に アクセスしたいときは，[ ]や，[[ ]]といった記号を使います。\n\nx &lt;- 1:10\nx[3] # xの3番目の要素\n\n[1] 3\n\nx[-3] # xの3番目の要素を除いた要素\n\n[1]  1  2  4  5  6  7  8  9 10\n\nx[2:4] # xの2〜4番目の要素\n\n[1] 2 3 4\n\nx[seq(1, 5, 2)] # xの1,3,5番目の要素\n\n[1] 1 3 5\n\ny &lt;- list(1:5, 6:10, 11:15)\ny[[2]] # yの2番目の要素\n\n[1]  6  7  8  9 10\n\ny[[2]][3:4] # yの2番目の要素の中の3番目と4番目の要素\n\n[1] 8 9",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rの基本操作</span>"
    ]
  },
  {
    "objectID": "r_basics.html#条件を付けて要素にアクセスする",
    "href": "r_basics.html#条件を付けて要素にアクセスする",
    "title": "3  Rの基本操作",
    "section": "3.6 条件を付けて要素にアクセスする",
    "text": "3.6 条件を付けて要素にアクセスする\n「ベクトル内の6という要素」「ベクトル内の4以上の要素」といった 条件を付けることも可能です。 Rでは，z == 3とすると，zの要素についてそれぞれが3と一致するかどうか判定してくれます。 一致する場合はTRUE，一致しない場合はFALSEが返ってきます。 また，z &gt; 4とすると，それぞれzの要素についてそれぞれが4より上かどうか判定してくれます。 ==や&gt;以外にも，&lt;（より下）や&lt;=（以下），&gt;=（以上）といった書き方もできます。\n\nz &lt;- 1:5\nz == 3 # 要素が3と一致するかどうか\n\n[1] FALSE FALSE  TRUE FALSE FALSE\n\nz &lt; 4 # 要素が4より下かどうか\n\n[1]  TRUE  TRUE  TRUE FALSE FALSE\n\nz &gt; 4 # 要素が4より上かどうか\n\n[1] FALSE FALSE FALSE FALSE  TRUE\n\nz &lt;= 4 # 要素が4以下かどうか\n\n[1]  TRUE  TRUE  TRUE  TRUE FALSE\n\n\nさらにz[z &lt;= 2]とすると，zの要素のうち2以下のものを抽出してくれます。 ここで，z[z &lt;= 2] &lt;- 0とすれば，zの要素のうち2以下のものがすべて0に置き換わります。\n\nz[z &lt;= 2]\n\n[1] 1 2\n\nz[z &lt;= 2] &lt;- 0\nz\n\n[1] 0 0 3 4 5\n\n\nその他，「ベクトル内の2と4は0にする」といった操作も可能です。 w %in% c(2, 4)と書くと，wの要素のそれぞれが2または4と一致するかどうか判定してくれます。 そのため，w[w %in% c(2, 4)] &lt;- 0と書くことで，2か4の要素を0に変換することができます。\n\nw &lt;- c(3, 1, 4, 5, 1, 5, 5, 2, 4, 5, 2)\nw %in% c(2, 4)\n\n [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE  TRUE\n\nw[w %in% c(2, 4)] &lt;- 0\nw\n\n [1] 3 1 0 5 1 5 5 0 0 5 0\n\n\nRの基本操作は，これで終わりです。 なぜこんな機能が必要なのか，よくわからないという人も多いでしょう。 今はそれで構いません。 Rを使っていくうちに，ベクトルやリストの便利さがわかるようになってきます。 続いて，これらの機能を使い，標本調査の基礎知識を学びましょう。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rの基本操作</span>"
    ]
  },
  {
    "objectID": "r_basics.html#footnotes",
    "href": "r_basics.html#footnotes",
    "title": "3  Rの基本操作",
    "section": "",
    "text": "プログラミングでは何らかの入力に対して， 結果が「返ってくる（return）」という表現をよく使います。↩︎",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rの基本操作</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html",
    "href": "sampling_basic1.html",
    "title": "4  標本調査の基礎知識1",
    "section": "",
    "text": "4.1 母集団と標本\nLSAでは，さまざまな国や地域の学校を対象に学力調査を行います。 もっとも，すべての学校を調査していたのでは莫大な予算と時間がかかってしまいますから， 通常は一部の学校を取り出して調査を行います。 全体を知るために，一部（標本）を取り出して調査する手法のことを，標本調査と呼びます。 ここでは本書を読む上で，最低限必要な標本調査の基礎知識を説明します。 なお，標本調査に関する詳しい説明は，社会調査の入門書[1]を読むようにしてください。\n最初に，母集団と標本という言葉について説明します。 分析の対象となる集団すべてのことを「母集団」と呼びます。 たとえば日本の小学6年生の学力が知りたいのであれば， 母集団は「日本の学校に通う小学6年生全員」になるでしょう。\nただ冒頭でも述べたように，母集団をすべて調べるのはあまりに予算と時間がかかりすぎるので， 普通は母集団の一部を取り出して調査を行います。 この取り出した一部を「標本」と呼び， 母集団から標本を取り出すことを「抽出」と言います。 また，標本から母集団の特徴を予測することを「推定」と呼びます（図 4.1）。\n冒頭の例で言うと，日本全国の小学6年生（＝母集団）の学力を知るために， 母集団から「抽出」した一部の学校の小学6年生（＝標本）にテストを行います。 そして標本平均が60点だったら，母平均も60点 （あるいはそれに近い値）だろうと「推定」するわけです。\n母集団と標本に関連して，他にもいくつか重要な用語があります。 まず，「標本」に含まれる対象の数のことを標本サイズ（あるいはサンプルサイズ）と呼びます。 3000人を抽出した場合，サンプルサイズ3000ということになります。 よく似た用語として，標本数（サンプル数）という言葉がありますが， これは取り出した標本の数です。 普通，社会調査では標本を1回しか取り出さない（≒アンケートは1回しかしない）ので， サンプル数は1になります。\n次に，平均や分散といった統計量1は，母集団のそれと標本のそれを区別します。 一般に母集団のそれは母を頭につけて，母平均・母分散といった表現をします。 また，母集団の統計量を，母数と呼ぶことがあります。 母数に対し，標本の平均は標本平均というふうに標本を付けて区別します。\n一般に母数は未知ですから，手元の標本から推測することになります。 母平均と標本平均は近い値になることが期待できますが， 完全に一致するとはかぎりません。 ですから標本調査において， 「日本のPISAの数学リテラシーの標本平均が530点である」は適切な表現ですが， 「日本のPISAの数学リテラシーの母平均が530点である」は正しいとはかぎりません。\n図 4.1 の中でもっとも重要な作業が抽出です。 抽出の方法が間違えていたら，母数を推定することは困難だったり， あるいは不可能だったりします。 たとえば日本に住む人（＝母集団）が好きな野球の球団を知りたいのに， 博多駅前を通りかかった人（＝標本）に調査をするのは間違っています。 おそらく福岡ソフトバンクホークスがもっとも好きな球団になってしまうでしょう。 母集団から標本を取り出すときは，できるだけ標本が母集団の縮図になるように 努力する必要があります。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#母集団と標本",
    "href": "sampling_basic1.html#母集団と標本",
    "title": "4  標本調査の基礎知識1",
    "section": "",
    "text": "図 4.1: 母集団と標本",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#標本抽出の方法",
    "href": "sampling_basic1.html#標本抽出の方法",
    "title": "4  標本調査の基礎知識1",
    "section": "4.2 標本抽出の方法",
    "text": "4.2 標本抽出の方法\n母集団から標本を抽出する方法には，さまざまな手法がありますが， LSAを知る上で重要な方法には，次のものがあります。\n\n単純な無作為抽出\n村落抽出法\n多段抽出法\n層化抽出法\n\nそれぞれ簡単に説明すると，単純な無作為抽出（Simple Random Sampling: SRS）とは， どの対象も同じ確率で選ばれる可能性がある抽出法のことです。 あまり現実的ではありませんが，全国の小学生の名簿を用意して， そこからサイコロを振ってランダムに対象者を選ぶというのが，単純な無作為抽出になります。 サイコロという偶然に任せて対象者を決めるので， 母集団と標本の特徴は，よく似通ったものになることが想定できます。\nただ，SRSがLSAで採用されることはまずありません。 まず，全国の小学生の名簿を用意するのが大変な手間です。 仮に用意できたとしても，SRSでは離島の学校に調査対象者が1名いるといった 極端な状況が発生する可能性があります。 たった1名を調べるために遠隔地へ出向くのは費用対効果という点から見て問題があります。 さらに，一つの学校に1名しか調査を受ける子どもがいないと， 仮にその学校の学力が高かったとして， それが調査対象になった子どもの特性なのか，それとも学校の指導法に要因があるのか 分析することが困難になります。\nそこで登場するのが，対象となる子どもが通う学校名のリストを用意して， そこから学校をランダムに選び，対象になった学校の児童生徒全員を調査するというものです。 日本全国の小学6年生の学力を知りたいのであれば， まず日本の小学校の一覧を用意し，サイコロを振って調査対象となる学校を決めます。 そして選ばれた学校のすべての児童に学力調査を行うのです。 これを村落抽出法（Cluster Sampling）と呼びます。 村落抽出法は，全国学力・学習状況調査の保護者に対する調査や経年比較分析調査で利用されています2。\n調査対象となった学校から，さらに児童生徒を抽出するという方法もあります。 サイコロを振って調査対象となる学校を選んだ後で， その学校に対して小学6年生の名簿を提出してもらいます。 その上で，個々の学校の名簿についてサイコロを振って，調査の対象となる児童を決めるわけです。 これを多段抽出法（Multistage Sampling）と呼びます。 多段抽出法はPISAで採用されており， まず学校を選び，続いて各学校から生徒を抽出する多段抽出法 （学校・生徒という二段階の抽出を行うので，とくに二段抽出と呼びます）が使われています。\n村落抽出法や多段抽出法は対象者を効率よく選択できるという利点がある一方で， 精度が落ちるという欠点があります。 一般に，同じ学校に通う子どもは似た特徴を持つと考えられます。 同じ地域で育ち，同じような指導を受けてきたわけですから， 学力や考え方・行動に似た部分が出てくるだろう・・・ということです。 そのため村落抽出法や多段抽出法は，SRSに比べて得られる情報量が少なくなります。 極端な例ですが，仮に各学校の子どもの学力がまったく同じ （A校は全員50点，B校は全員40点・・・）だったとしたら， A校から10人選んでも全体の推測にはあまり役立たず， SRSで母集団から10人選んだ方が圧倒的に良いということになります。\n精度が落ちるという欠点に対処するため，村落抽出法や多段抽出法を 層化抽出法（Stratified Sampling）という方法と組み合わせることがよく行われます。 この場合，層化村落抽出法／層化多段抽出法といった呼び方がされます。\n層化とは学力に影響を与えると思われる要因で各学校をグループ（層）にまとめておき， その層の中から学校を抽出するという方法です。 一例として，都市部かそうでないかで学力実態が大きく変わることが想定できます。 であれば，事前に学校を都市部かそうでないかで二つのグループに分けておき， それぞれから学校を抽出すれば，標本には必ず都市部／それ以外の学校が混ざるので， 何も考慮しなかった場合よりも精度が上がることが期待できます。\nいろいろと述べてきましたが，実のところ，LSAを分析する際に さまざまな抽出法について知っておくことは必須ではありません。 分析者側が抽出法について知らなくても問題ないような工夫 （Replication Method）が施されているからです。 そして，いずれの抽出法を使用しているにせよ， 標本から母集団を推定する方法は，基本的にはSRSの条件下での推定の拡張です。\nそこで以下では，SRSの条件下で，どのように標本から母集団を推定すればよいのか 学んでいくことにしましょう。 なお，ここで留意すべきは，これから学ぶ方法は あくまでも「SRSの条件下」であるという点です。 すでに述べたように，LSAでSRSが採用されることはほぼありません。 ですから，SRSの方法をそのまま母集団の推定に当てはめることは，ときに誤った推測に繋がります。 SRSの理屈は学びつつ，「どこがLSAに適用できて，どこが適用できないのか」という点を 意識しておくことが重要なのです。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#変数という考え方",
    "href": "sampling_basic1.html#変数という考え方",
    "title": "4  標本調査の基礎知識1",
    "section": "4.3 変数という考え方",
    "text": "4.3 変数という考え方\n続いて「変数」という考え方について説明します。 社会調査では，さまざまな質問をします。 このとき個々の設問への回答は，変数という形でまとめられます。 「朝ごはん」変数とか，「国語の学力」変数といった具合です。 変わる数だから変数と覚えておけばいいでしょう3。\n変数にはいくつか種類がありますが， 大雑把には，足し算・引き算ができる変数（量的変数）と 足し算・引き算のできない変数（質的変数）の2種類があると思っておけば十分です。\n前者の代表は，学力テストの点数です。 国語の成績と算数の成績を足して2で割って平均を求めるといった作業が想定できます。 また，「女子の国語の点数が70点，男子の国語の点数は60点だから， 女子の方が10点成績がよい」といった引き算をすることも可能です。\n後者の代表は，よくあるアンケートの回答を想像すればいいでしょう。 たとえば「朝ごはんを食べますか？」という質問に対する， 「1:はい」「2:いいえ」といった回答です。 ここではアンケートの回答に1や2といった数値を当てはめていますが， これはたまたまそう設定しただけで， 「1:いいえ」「2:はい」でも構いません4。 また，「2:いいえ」から「1:はい」を引くと「1:はい」になるといった 引き算は（できなくはないですが），実質的な意味はありません。\n量的変数と質的変数では，適用できる統計手法が異なります。 そのため，自分が扱っている変数がいずれの種類なのか区別しておくことは重要です。 LSAでは学力という量的変数が主な関心の対象になりますから， 以下では量的変数に焦点を当て，標本から母集団を推定する方法を解説します。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#平均",
    "href": "sampling_basic1.html#平均",
    "title": "4  標本調査の基礎知識1",
    "section": "4.4 平均",
    "text": "4.4 平均\nよく使われる統計量の代表が，平均です。 \\(x_1\\), \\(x_2\\)，・・・，\\(x_i\\)，・・・\\(x_n\\)の\\(n\\)個のデータに対して， その平均\\(\\mu\\)は以下の式で定義されます。\n\\[\\mu = \\frac{1}{n}\\sum_{i=1}^nx_i\\]\n数学記号が出てきて驚くかもしれませんが， 要は「データをすべて足して，データの数で割る」ということです。 Rでは，オブジェクトに対してさまざまな操作をするコマンド （これを「関数」と呼びます）が用意されています。 たとえばベクトルの要素をすべて足す場合はsum関数が使えますし， ベクトルの要素の数はlength関数で取得できます。 また，ベクトルの平均を計算するmean関数も用意されています。\nここでは簡単のため，児童数5人の学級AとBがあると考えます。 Aクラスの5人の成績は，40点・40点・60点・80点・80点です。 Bクラスの5人の成績は，20点・20点・60点・100点・100点とします。 このとき，それぞれの平均（どちらも60点になります）は Rで以下のように計算できます。\n\n# Aクラスのベクトルを作成\nA &lt;- c(40, 40, 60, 80, 80)\n# Bクラスのベクトルを作成\nB &lt;- c(20, 20, 60, 100, 100)\nsum(A) / length(A) # Aの数値をすべて合計し，要素数（5）で割る\n\n[1] 60\n\nmean(B) # mean関数が用意されている\n\n[1] 60",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#分散",
    "href": "sampling_basic1.html#分散",
    "title": "4  標本調査の基礎知識1",
    "section": "4.5 分散",
    "text": "4.5 分散\nさて，AクラスもBクラスも平均は60点ですが， 両者は点数のばらつき具合が違います。 Aクラスは最小値40点・最大値80点に対し， Bクラスは最小値20点・最大値100点なので， 成績のばらつきは明らかにBクラスのほうが大きくなっています。\nこうしたデータのばらつきを表す統計量が分散です。 分散は，次の式で計算します。\n\\[\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2\\]\n数式では難しいかもしれないので，Rで考えてみましょう。 データのばらつきを表現する際に手っ取り早いのは， すべての要素から平均を引いてしまうことです。 Rで表現すると，次のようになります。\n\nA - mean(A)\n\n[1] -20 -20   0  20  20\n\nB - mean(B)\n\n[1] -40 -40   0  40  40\n\n\nこの結果を見ると，最小値-20・最大値20のAクラスより， 最小値-40・最大値40のBクラスの方がばらつきが大きいことは明らかです。 ただ，今回は要素が5つと少ないのでまだ良いのですが， 要素の数が多くなると全体を把握することは困難になります。 そこで，得られた結果を1つの値にまとめることを考えましょう。 手っ取り早いのは，sum関数を使って全部足してしまうことです。\n\nsum(A - mean(A))\n\n[1] 0\n\nsum(B - mean(B))\n\n[1] 0\n\n\n0になってしまいました。 プラスとマイナスの数値があるので，相殺して0になってしまうのです。 どうすればいいのでしょうか。\nこういう場合に統計学でよく使われる方法が，要素を全部2乗してしまうというものです。 2乗すればマイナス×マイナスはプラスということで，すべての値が正になります。 Rの場合，Aというベクトルの要素をすべて2乗したければ， A^2と書くだけで十分です。 今回は，A - mean(A)を2乗しなければならないので， (A - mean(A))^2とした後に，その合計（sum）を計算します。 混乱するかもしれませんが，以下のように少しずつコードを増やしていけば大丈夫です。\n\nA # Aクラスの成績\n\n[1] 40 40 60 80 80\n\nA - mean(A) # 平均を引く\n\n[1] -20 -20   0  20  20\n\n(A - mean(A))^2 # 要素を2乗\n\n[1] 400 400   0 400 400\n\nsum((A - mean(A))^2) # 合計を計算\n\n[1] 1600\n\nsum((B - mean(B))^2) # Bクラスについても同じ処理\n\n[1] 6400\n\n\nこうすることで，AよりBの方がばらつきが大きいということが， 1つの数値で表現できます5。\nただ，この数値にも問題があります。それは，要素の数が倍になると データのばらつきが変わっていないのに数値が大きくなってしまう という問題です。 今，Aが二つ合体したA2というベクトルを考えましょう。\n\nA2 &lt;- c(A, A)\nsum((A2 - mean(A2))^2)\n\n[1] 3200\n\n\nA2はAが二つくっついただけなので，ばらつきは変わらないはずですが， 計算結果は1600から3200と2倍になっています。 これは困るということで，最後に要素数\\(n\\)で割ります。\n\n(sum((A - mean(A))^2)) / length(A)\n\n[1] 320\n\n(sum((B - mean(B))^2)) / length(B)\n\n[1] 1280\n\n(sum((A2 - mean(A2))^2)) / length(A2)\n\n[1] 320\n\n\nAよりBの方がばらつきが大きく，AとA2のばらつきは同じという結果になりました。 この計算が，分散の式で行われていることです。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#分散をrの関数にまとめる",
    "href": "sampling_basic1.html#分散をrの関数にまとめる",
    "title": "4  標本調査の基礎知識1",
    "section": "4.6 分散をRの関数にまとめる",
    "text": "4.6 分散をRの関数にまとめる\nところで，毎回(sum((A - mean(A))^ 2)) / length(A)を入力するのは大変です。 Aを入力するところが3箇所もあるので，そのうち間違えそうな気がします。 そこでRの関数を自作することを考えます。 最初はなかなかピンとこないと思いますが，慣れると複雑な処理をひとまとめにして 繰り返し使うことができるので，大変便利な操作です。\n関数を自作する場合，functionという関数を使います。 先ほどの分散をまとめる処理を，新しくVARという関数にすることを考えましょう。 以下のように書くと，VARという関数を登録することができます。\n\nVAR &lt;- function(x) {\n  (sum((x - mean(x))^2)) / length(x) # 関数の処理を書く\n}\n\nVAR(A)\n\n[1] 320\n\nVAR(B)\n\n[1] 1280\n\nVAR(A2)\n\n[1] 320\n\n\nちなみにRにも分散を求める関数varが用意されています。 ただ，このvarは先ほど作ったVARとは違う結果を返します。\n\nvar(A)\n\n[1] 400\n\nvar(B)\n\n[1] 1600\n\nvar(A2)\n\n[1] 355.5556\n\n\nこれはVARが間違っているというわけではありません。 標本から母集団の分散を推定する場合，その式は，次のようになります。\n\\[\\frac{1}{n-1}\\sum_{i=1}^n(x_i - \\mu)^2\\]\n違いは\\(n\\)ではなく，\\(n-1\\)で割っているという点です。 詳しい説明は省きますが，こちらの式の方が母集団の分散を適切に推定 できることがわかっています。 Rに用意されているvarは，この式を実装したものです。 そのため，varで計算した値に，\\(\\frac{n-1}{n}\\)をかけると， VARの値と一致します。\n\nvar(A) * (length(A) - 1) / length(A)\n\n[1] 320\n\nvar(B) * (length(B) - 1) / length(B)\n\n[1] 1280\n\nvar(A2) * (length(A2) - 1) / length(A2)\n\n[1] 320",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#標準偏差",
    "href": "sampling_basic1.html#標準偏差",
    "title": "4  標本調査の基礎知識1",
    "section": "4.7 標準偏差",
    "text": "4.7 標準偏差\n先ほど計算した分散は，都合上，途中で数値を2乗していました。 そのため，もとのデータと比べると単位がズレています6。 ここで，分散の平方根を取ると，単位が揃います。 これを標準偏差と呼びます。 次の章で扱いますが， 標準偏差はいろいろと便利な性質を持つので，よく使われます。\nなお分散と同じく，標本の分散VARなのか， 標本から母集団を推定した分散varなのかによって， 標準偏差も微妙に値が変わります。\n\nsqrt(VAR(A))\n\n[1] 17.88854\n\nsqrt(VAR(B))\n\n[1] 35.77709\n\nsqrt(VAR(A2))\n\n[1] 17.88854\n\nsqrt(var(A))\n\n[1] 20\n\nsqrt(var(B))\n\n[1] 40\n\nsqrt(var(A2))\n\n[1] 18.85618\n\n\nRには，母集団の標準偏差を推定するための関数sdが用意されています。 これは，sqrt(var(x))と同じ値を返します。\n\nsd(A)\n\n[1] 20\n\nsd(B)\n\n[1] 40\n\nsd(A2)\n\n[1] 18.85618",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#最大値最小値中央値",
    "href": "sampling_basic1.html#最大値最小値中央値",
    "title": "4  標本調査の基礎知識1",
    "section": "4.8 最大値・最小値・中央値",
    "text": "4.8 最大値・最小値・中央値\n平均・分散・標準偏差以外に登場するものとして， 最大値，最小値，中央値といった値があります。 中央値は，データを順に並べたときの真ん中の値のことです。 もし真ん中の値が二つある場合は，その平均が中央値になります。 ちなみに，データを順に並べたときに前から\\(\\frac{1}{4}\\)を第1四分位， 前から\\(\\frac{3}{4}\\)を第3四分位と呼びます。\nRでは，summary関数を使って，これらの値を計算することができます。 また，median，max，minといった関数を使うことでも算出できます。\n\nx &lt;- c(30, 40, 50, 60, 70)\nsummary(x) # Min:最小値，1st Qu:第1四分位，Median:中央値，3rd Qu:第3四分位，Max:最大値\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n     30      40      50      50      60      70 \n\nmax(x) # 最大値\n\n[1] 70\n\nmin(x) # 最小値\n\n[1] 30\n\nmedian(x) # 中央値\n\n[1] 50\n\n\n\n\n\n\n1. 伊達平和・高田聖治. (2020年). 社会調査法. 学術図書出版社.",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic1.html#footnotes",
    "href": "sampling_basic1.html#footnotes",
    "title": "4  標本調査の基礎知識1",
    "section": "",
    "text": "平均や分散については，後半で説明します。↩︎\n令和3年度の抽出法について，国立教育政策研究所のウェブサイトに 資料が載っています。↩︎\n厄介なことに，Rのオブジェクトも「変数」と呼ぶことがあります。 混乱すると思うので，本書でRの説明をするときは「変数」という言葉を使っていません。↩︎\nアンケートの回答は，数値にして管理することが一般的です。 もし「はい」「いいえ」といった文字のまま管理したら， 打ち間違いが発生する危険があります （コンピュータは融通がききませんので，「はい」「はぃ」「ハイ」はすべて違う意味になります）。 また，回答が長い場合（たとえば「いつもある」「ときどきある」「あまりない」「まったくない」など）， 分析時に非常に扱いづらくなります。↩︎\nこの辺まで来るとベクトルのありがたさがわかるようになります。 この計算をベクトルを使わずやろうと思うと， sum(((40 - 60)^2 + (40 - 60)^2 + (60 - 60)^2 + (80 - 60)^2 + (80 - 60)^2)) となってしまいます。 今は要素が5つですからなんとか計算できますが， 要素が1000や2000になったらもう手に終えません。 ベクトルを使えば，Aの要素が1000になっても2000になっても， sum((A - mean(A))^2)は変わらないのです。↩︎\n仮にもとの単位が\\(m\\)（メートル）だったとすると， 途中で2乗しているので\\(m^2\\)（平方メートル）になっています。↩︎",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>標本調査の基礎知識1</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html",
    "href": "sampling_basic2.html",
    "title": "5  標本調査の基礎知識2",
    "section": "",
    "text": "5.1 確率分布とシミュレーション\nこの章では，標本から母集団を推定する方法について学びます。 かなり難しいので，理解できなくても構いません。 とりあえず流し読みして次の章へ進み， 必要になったら戻ってくるという方針でよいと思います。\n社会調査に限らず，統計学ではデータが何らかの規則に従っていると考えます。 たとえば20歳男性の身長を考えてみましょう。 政府統計によると， 20歳男性の身長はだいたい170cmです。 ですから，全国からランダムに選んだ20歳の男性の身長は170cm付近の人がもっとも多いと考えられます。 さらに平均身長から\\(x\\)cm低い人・\\(x\\)cm高い人の割合はほぼ同じと考えても支障はないでしょう。 ここでRを使って，20歳男性の身長のばらつきを視覚的に表現してみます。\nなお，ここからRで図を書く機会が増えますが， 初期設定のままcolabで図を書くと，日本語が文字化けします。 日本語を表示するための設定を行ってから， 以下のコードを実行してください。\nsimdata &lt;- rnorm(10000, 170, 7)\nhist(simdata, main = \"身長のヒストグラム\", xlab = \"身長\", ylab = \"度数\")\nabline(v = 170, col = \"red\")\n\n\n\n\n\n\n\n図 5.1\n図 5.1 はrnormという関数を使い， 仮想の20歳男性の身長のデータを作成して描いた図です。 rnormは正規分布と呼ばれる規則に従って，ランダム1にデータを生成する関数です。 正規分布は 図 5.1 のような山形のデータの散らばり方を表現したもの（≒分布）で， いろいろと便利な性質を持つので統計学ではよく使われます。 正規分布以外にもベルヌーイ分布や二項分布といったさまざまな形の分布があり， これらを総称して確率分布と呼びます。 本書では正規分布を主に使いますが，統計の入門書では 正規分布以外の確率分布もしばしば登場します。\nさてRの話に戻ると，rnormのカッコの中の10000・170・6の数値は， 順に生成するデータの数（10000個）・平均（170）・標準偏差（7）を意味します。 日本の20歳男性の身長は，だいたい平均170cm・標準偏差7cmなので， その情報に従って正規分布からデータを生成したのです。 生成したデータは，simdataというオブジェクトに格納しています。\n次にhistは，ヒストグラムを書くための関数です。 histのカッコの中のmain・xlab・ylabは， それぞれ，グラフのタイトル（身長のヒストグラム），x軸のタイトル（身長）， y軸のタイトル（度数）を意味します。 いずれも，\"\"を付けて文字にしていることに注意してください。 なお，度数は統計でよく使う用語で，「データの出現した回数」という意味です。\n最後に，ablineという関数は，赤い縦線を引くための関数です。 ablineの中のv・colは，縦に線を引く位置（今回は170のところに線を引く） ・線の色（redは赤色）を意味します。\nなお，関数のカッコの中の情報を，引数（ひきすう）と呼びます。 rnorm関数であれば，「生成するデータの数・平均・標準偏差を引数として設定する」わけです。 Rに限らず，プログラミングでは「引数を設定する」といった表現を使うので， 覚えておくとよいでしょう。\n以上の手続きで，20歳男性の身長の分布を示すグラフが書けました。 もちろんこれは，「身長が正規分布という規則に従う」という仮定を置いて 描いたグラフですから，現実の身長の分布とは違っている可能性もあります。 ただ，このような仮定を置くと，仮のデータを生成し，いろいろな実験をすることが可能になります。 これをシミュレーションと呼びます。\n今度は，学力テストの点数（平均50・標準偏差10）が正規分布に従うと仮定してみましょう。 先ほどと同じく，Rでrnorm(30, 50, 10)とすると， 30人分の点数を得ることができます。 ただ，rnorm関数で作成した数値は小数点以下も出力されるので， これをroundという関数を使って整数にしておきます。\nrnormで作成したデータはランダムに生成されていますから，実行するたびに結果が変わります。 これでは困る（≒私の手元で実行した値と，皆さんが手元で実行した値が違ってしまう）ので， 今回は生成される値を固定します。 それが，set.seedという関数です。set.seed(123)という具合に使います。 カッコの中の数値は何でも構いません。 私は123を指定します。皆さんも123と指定すれば，以下の出力と同じ値が得られるはずです。 違う値を指定すれば（あるいはset.seedを省略すると）結果が変わってきますので，確認してみてください。\nset.seed(123)\nsimscore &lt;- round(rnorm(30, 50, 10))\nsimscore\n\n [1] 44 48 66 51 51 67 55 37 43 46 62 54 54 51 44 68 55 30 57 45 39 48 40 43 44\n[26] 33 58 52 39 63\n\nmean(simscore)\n\n[1] 49.56667\n今回得られた標本の平均点は，約49.6点でした。 ここで考えてみたいのは， 「ランダムに各学級に30人を配置したら，それぞれの学級の平均点はどのくらいばらつくのだろうか」 ということです。 ランダムに生成したデータですから，その平均は毎回変わります。 もちろん平均50・標準偏差10という縛りがありますから， あまり50点から離れた値にはならないでしょうが， ランダムに生成しているので，稀には55点や45点といった値もでる気がします。\nそこでデータを100回生成して，その平均点がどうなるか観察してみましょう。 ただ，rnorm(30, 50, 10)を100回も入力するのは大変です。 せっかくプログラミングをしているのですから，もっとスマートにやってみましょう。\nここで登場するのが，sapplyという関数です。 sapplyは，「与えたリスト（あるいはベクトル）に対して同じ処理を繰り返す」 関数になります。 親戚としてlapply関数があり，lapplyはリストを返し， sapplyはベクトルを返す2点が違います。 ちょっと難しいので，簡単な例を出しましょう。 今，lisというリストを考えます。 このリストの要素について平均をとることを考えましょう。\nlis &lt;- list(c(20, 30), c(30, 40), c(40, 50))\n# lisの要素（20と30，30と40，40と50）のそれぞれについて平均を計算\nsapply(lis, mean)\n\n[1] 25 35 45\n\n# lapplyはリストを返す\nlapply(lis, mean)\n\n[[1]]\n[1] 25\n\n[[2]]\n[1] 35\n\n[[3]]\n[1] 45\nlisは簡単なリストなので，あまりありがたみがわからないでしょうが， リストが複雑になればなるほど，sapplyやlapplyの有用性が活きてきます。\n次に，numというベクトルを考えます。このベクトルの要素に， すべて2を足す（x + 2）ことを考えましょう。 ここではplusという「与えた数（x）に2を足す」という新しい関数を作って， それをsapplyに与えています3。\nnum &lt;- c(1, 3, 5, 100)\nplus &lt;- function(x) {\n  x + 2\n}\nsapply(num, plus)\n\n[1]   3   5   7 102\nただ，いちいちplusという関数を作るのは面倒なので， function以下を，そのままsapplyに与えても構いません。\nsapply(num, function(x) {\n  x + 2\n})\n\n[1]   3   5   7 102\nこれを応用すると，先ほどの課題 （データを100回生成して，その平均を計算する） がクリアできます。sapplyに，「データを100回生成し，その平均を計算する」という処理を functionを使って与えればよいのです。 100回の生成を行い，その平均をヒストグラムにする処理は，以下のようになります。\nset.seed(1234)\nsim &lt;- sapply(1:100, function(x) {\n  simscore &lt;- round(rnorm(30, 50, 10))\n  mean(simscore)\n})\nhist(sim, main = \"100学級の平均点のばらつき\", xlab = \"平均点\", ylab = \"度数\")\n\n\n\n\n\n\n\n図 5.2\n図 5.2 を見ると，ランダムに30人を各学級に配置したとき， 学級の平均点が48点や52点になることは珍しくないということがわかります。 中には54点や46点に近い値になる学級もあるようです。 それ以上に大きな（あるいは小さな）値がでることは稀ですが， 図 5.2 でも44点が1回出ています。\nここからわかることは，学力テストの平均点が3〜4点程度違っても， それは教員の指導力を反映したものではない（かもしれない） ということです。 仮に一人ひとりの子どもの成績が平均50・標準偏差10の正規分布に従うのであれば， 30人の学級の平均点は3〜4点程度は簡単に変動するのです。\nもちろんこのシミュレーションは， 点数が平均50・標準偏差10の正規分布に従うという前提を置いた上での結果です。 ですから点数が正規分布以外の分布に従っていたり，正規分布の平均や標準偏差が違ったりすれば， また違った結果になることが予想できます。 気になる人は，rnorm関数の引数を変更して，いろいろ調べてみるとよいでしょう。\nここで重要なことは，シミュレーションの前提を明らかにしておけば， 誰でも同じような結果を導くことができるという点です。 さらに，その結果をもとに私たちは 「たった3〜4点の平均点の差で教員の良し悪しを判断するのは危険ではないか」といった議論や， 「正規分布の標準偏差が大きい場合はさらに学級の平均点がばらつくのではないか」といった議論が できるようになります。 これが統計学の力の一つと言えるでしょう。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html#大数の法則",
    "href": "sampling_basic2.html#大数の法則",
    "title": "5  標本調査の基礎知識2",
    "section": "5.2 大数の法則",
    "text": "5.2 大数の法則\n標本から母集団を予測するときに重要な理論として， 大数の法則というものがあります。 ざっくり言うと，「標本サイズ\\(n\\)の標本調査を行ったとき， \\(n\\)が大きくなれば，標本の平均値は母集団の平均値に近づく」 というものです。 たとえば全国の小学6年生（＝母集団）の国語の平均点を考えてみましょう。 大数の法則が意味するのは， 「母平均が60点だったとすると， 標本のサンプルサイズが大きければ標本平均も60点に近づく」ということです。 直感的には当たり前と思うかもしれませんが， これが統計的な推測を行う上で重要な定理になります。\n大数の法則をRで確認しておきましょう。 母集団において，国語の平均点は平均60・標準偏差10の正規分布に従うと仮定します。 ここでrnorm関数を使い，生成するデータの数（＝サンプルサイズ）を 10から2000まで10ずつ増やしていきます。 結果を図示するには，plotという関数を使います。 ここでは，plotの引数としてtype = lを与えることで， 折れ線グラフを描いています。\n\nset.seed(12345) # 再現性のための乱数シード\n\nsamp_size &lt;- seq(10, 2000, 10) # サンプルサイズ（10から2000まで10ずつ増やす）\nsamp_mean &lt;- sapply(samp_size, function(n) {\n  x &lt;- rnorm(n, 60, 10) # 平均60・標準偏差10の正規分布からn個を取り出す\n  mean(x) # xの平均を計算\n})\n\n# 結果のプロット\nplot(samp_size, samp_mean,\n  type = \"l\", col = \"blue\",\n  xlab = \"サンプルサイズ\", ylab = \"標本平均\",\n  main = \"大数の法則\"\n)\nabline(h = 60, col = \"red\") # 母集団の平均を示す線\nabline(h = 61, col = \"red\", lty = 2) # 母集団の平均を示す線\nabline(h = 59, col = \"red\", lty = 2) # 母集団の平均を示す線\nabline(v = 200, col = \"green\", lty = 2) # サンプルサイズ200の位置を示す線\n\n\n\n\n\n\n\n図 5.3\n\n\n\n\n\n図 5.3 を見ると サンプルサイズが200以下のあたりでは， ブレが大きく63や58といった標本平均が得られることもありますが， サンプルサイズが200を超えるとそのような外れた標本平均は珍しくなることがわかります。 サンプルサイズがどの程度あればよいのかというのは難しい問題ですが， 図 5.3 を見るかぎり，今回の例（母平均60・母標準偏差10）であれば， 200程度のサンプルサイズが確保できれば十分（≒1点前後のズレに収まる）でしょう。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html#中心極限定理",
    "href": "sampling_basic2.html#中心極限定理",
    "title": "5  標本調査の基礎知識2",
    "section": "5.3 中心極限定理",
    "text": "5.3 中心極限定理\n標本から母集団を推定する際にもう一つ重要な理論が，中心極限定理です。 これは，「平均\\(\\mu\\)・分散\\(\\sigma^2\\)の母集団からn個の標本を抽出したとき， nが十分に大きければ，\\(\\bar{x}\\)の分布は 平均値\\(\\mu\\)・標準偏差\\(\\frac{\\sigma}{\\sqrt{n}}\\)の 正規分布に近づく」というものです。\nこれでは何のことかわからないでしょうから， 具体例として，保護者の世帯年収を考えてみましょう。 年収がきわめて高い人が一定数存在するために， 世帯年収は正規分布と異なる形状になります。 Rでは，rlnormという関数を使い対数正規分布という確率分布からデータを生成できるので， これを利用して世帯年収のグラフを描いてみましょう。 なお，対数正規分布はここでしか使わないので，覚える必要はありません。\n\nset.seed(123)\nn &lt;- 1000 # サンプルサイズ\nmedian_income &lt;- 400 # 中央値（400万円）\nsd_log &lt;- 0.8 # 対数正規分布の標準偏差\n\n# 対数正規分布に基づく年収データを生成\nincome_data &lt;- rlnorm(n, meanlog = log(median_income), sdlog = sd_log)\n\n# データの概要を表示\nhist(income_data,\n  breaks = 50, main = \"年収の分布\",\n  xlab = \"世帯年収（万円）\", ylab = \"度数\"\n)\n\n\n\n\n\n\n\n図 5.4\n\n\n\n\n\n図 5.4 を見ると，今回作成した対数正規分布は， 正規分布と異なり右側に裾野が広い分布になっていることがわかります。 実際，summary関数で最小値（Min），最大値（Max），平均値（Mean），中央値（Median）等を 表示してみると，平均と標準偏差が大きく異なっています。\n\nsummary(income_data)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  42.25  241.97  402.96  557.05  680.72 5347.03 \n\n\nここで，世帯年収の母平均を標本から推測することを考えます。 図 5.4 で確認したように，世帯年収の分布は正規分布とは異なっています。 このような場合（＝母集団の分布が正規分布と異なっていても）でも， 標本平均を計算して標本平均の分布を調べてみると 正規分布になっているというのが，中心極限定理です。\nなお，標本平均の分布を調べると言いましたが， 普通の調査では標本は1度しか取り出しません。 そのため何度も標本抽出をして，標本平均の分布を調べるということ自体が 常識から外れた作業なのですが， そのことにはとりあえず目をつぶっておいてください。\nここでは，先ほどの対数正規分布から5000回標本を取り出すことを考えましょう。 この作業は少し難しいので，自分でできなくても構いません。 Rのコードは示しておきますので，興味がある方は自分で検討してみてください。\n\n\nコード\n# パラメータの設定\nn_smp &lt;- 5000 # 抽出回数\nm_log &lt;- log(400) # 対数正規分布の中央値を400に設定\ns_log &lt;- 0.8 # 対数正規分布の標準偏差\nsizes &lt;- c(10, 30, 100, 1000) # サンプルサイズ\n\n# 標本ごとの平均を算出\nget_means &lt;- function(size) {\n  replicate(n_smp, mean(rlnorm(size, meanlog = m_log, sdlog = s_log)))\n}\n\n# 標本平均のリストを作成\nmeans_lst &lt;- lapply(sizes, get_means)\nnames(means_lst) &lt;- paste(\"Size\", sizes)\n\n# ヒストグラムのプロット関数\nplot_hist &lt;- function(means, size) {\n  hist_range &lt;- range(means) # 標本平均の最小値と最大値を取得\n  margin &lt;- diff(hist_range) * 0.1 # 範囲の10%を余白として追加\n  xlim &lt;- c(hist_range[1] - margin, hist_range[2] + margin) # 余白を含めた範囲を計算\n\n  hist(means,\n    breaks = 50, probability = TRUE,\n    main = paste(\"標本の大きさ =\", size),\n    xlab = \"平均値\", col = \"skyblue\", xlim = xlim\n  )\n}\n\n# 正規分布の曲線を重ねる関数\nadd_norm &lt;- function(means) {\n  curve(dnorm(x, mean = mean(means), sd = sd(means)),\n    col = \"red\", lwd = 2, add = TRUE\n  )\n}\n\n# グラフを2行2列で表示するための「おまじない」\npar(mfrow = c(2, 2))\n\n# ヒストグラムと正規分布のプロット\nfor (i in seq_along(sizes)) {\n  means &lt;- means_lst[[i]]\n  plot_hist(means, sizes[i]) # ヒストグラムをプロット\n  add_norm(means) # 正規分布を重ねる\n}\n\n# 「おなじない」を解除\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\n\n図 5.5\n\n\n\n\n\n図 5.5 は， 標本の大きさ（サンプルサイズ）が10・30・100・1000のそれぞれで， 標本平均の分布が正規分布とどう異なるか示しています。 青色のヒストグラムが標本平均の分布を示し， 赤色の線が正規分布を示しています。 標本の大きさが10や30の場合は， 標本平均の分布と赤色で示した正規分布にはズレが存在します。 一方で標本の大きさが100や1000になると， 標本平均の分布は赤色で示した正規分布とほぼ重なっていることがわかります。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html#標準誤差",
    "href": "sampling_basic2.html#標準誤差",
    "title": "5  標本調査の基礎知識2",
    "section": "5.4 標準誤差",
    "text": "5.4 標準誤差\n中心極限定理の性質を利用すると， 標本平均と母平均のズレ（≒誤差）を考えることができるようになります。 中心極限定理から，サンプルサイズが大きければ， 母集団の分布がなんであれ標本平均の分布は正規分布に近づきます。\n今，母平均は60・標準偏差は10とし， そこからサンプルサイズ100の標本を取り出したとしましょう。 このとき中心極限定理から，その標本平均の分布は， 平均60・標準偏差1（\\(\\frac{\\sigma}{\\sqrt{n}} = \\frac{10}{\\sqrt{100}} = 1\\)）の正規分布に近づきます。\nここで，正規分布の便利な特性を活かします。 正規分布には，「データの約95%が平均±2標準偏差のあいだに入る」という 特性があります4。 冒頭で取り上げた20歳男性の身長（平均170cm・標準偏差7cm）の話に戻ると， 身長の分布が正規分布に従うなら 「約95%の20歳男性の身長は170±2×7cmのあいだにある」ということです。\nさて正規分布の性質から，母平均60・母標準偏差10の母集団から標本を抽出すると， 「約95%の標本の標本平均は60±2×1のあいだにある」ということになります。 図 5.6 は，標本平均の分布を図示したもので， 仮に母集団から100回標本を取り出して標本平均を計算すると， 100の内95個は標本平均が60±2×1のあいだにある， すなわち58点から62点のあいだに収まります。\n\n\nコード\n# パラメータ設定\nmean &lt;- 60 # 母平均\nsd &lt;- 1 # 標準偏差\n\n# x軸の範囲設定\nx &lt;- seq(mean - 4 * sd, mean + 4 * sd, length.out = 1000)\n\n# 正規分布の確率密度関数\ny &lt;- dnorm(x, mean = mean, sd = sd)\n\n# プロット\nplot(x, y,\n  type = \"l\", lwd = 2, col = \"blue\",\n  main = \"標本平均の分布\", xlab = \"値\", ylab = \"密度\"\n)\n\n# ランダムな点を生成（1つは±2SDの外、2つは±2SDの内）\nset.seed(456) # 再現性のための乱数シード\npoints_x &lt;- c(\n  runif(2, min = mean - 2 * sd, max = mean + 2 * sd),\n  runif(1, min = mean + 2 * sd, max = mean + 3 * sd)\n)\npoints_y &lt;- dnorm(points_x, mean = mean, sd = sd)\n\n# 標本平均を描画\npoints(points_x, points_y, pch = 19, col = \"red\")\n\n# 各標本平均から±2SDの矢印を描画\nfor (i in 1:3) {\n  arrows(points_x[i], points_y[i],\n    points_x[i] - 2 * sd, points_y[i],\n    length = 0.1, col = \"darkgreen\"\n  )\n  arrows(points_x[i], points_y[i],\n    points_x[i] + 2 * sd, points_y[i],\n    length = 0.1, col = \"darkgreen\"\n  )\n  text(points_x[i], points_y[i] + 0.01,\n    paste0(\"標本平均 \", i),\n    pos = 3, col = \"darkgreen\"\n  )\n}\n\n# ±2SDの縦線を追加\nabline(v = mean - 2 * sd, col = \"red\", lty = 2)\nabline(v = mean + 2 * sd, col = \"red\", lty = 2)\n\n# 母平均に線を追加\nabline(v = mean, col = \"purple\", lty = 2)\n\n\n\n\n\n\n\n\n図 5.6\n\n\n\n\n\nここで発想を変えて，取り出した標本の標本平均について±2×1の範囲を考えてみます。 図 5.6 では例として，3つの標本の平均（標本平均1・標本平均2・標本平均3）を図示しています。 緑の矢印は±2×1の範囲です。 母平均60に注目すると，標本平均1と標本平均2は矢印の範囲に母平均を含みます。 他方，標本平均3は含んでいません。\nここで思い出してほしいのですが，標本平均の分布は正規分布なので， 約95%の標本の標本平均は58から62の範囲にあります。 ですから，58から62の範囲に標本平均を持つ（標本平均1や標本平均2のような）標本であれば， 緑の矢印の範囲を計算すれば，その範囲のどこかに母平均を含みます。\nここで私たちの手元にある標本が，標本平均1や標本平均2のような 緑の矢印の範囲に母平均を含む標本だと「信じましょう」。 もちろん標本平均3のような標本が得られてしまった可能性もあるのですが， そのことについては一旦脇に置いておくのです。 手元にある標本が緑の矢印の範囲に母平均を含むと信じるなら， 得られた標本について標本平均±2×標本平均の標準偏差を計算すれば， その範囲に母平均があることになります。 ただし，標本平均の標準偏差（中心極限定理から\\(\\frac{\\sigma}{\\sqrt{n}}\\)になります） を計算するには，\\(\\sigma\\)（母分散の平方根）が必要になります。 普通は母数は未知なので，標本から計算した分散5で代用します。\nこれで，私たちは標本から母平均を予測することができるようになりました。 もちろん私たちの手元にある標本が標本平均3のような「ハズレ」である可能性はあるのですが， そのリスクには目をつぶるのです6。\nここで，「標本平均の標準偏差」は標準誤差（Standard Error: SE）と呼ばれます。 計算式は，\\(SE=\\frac{sd}{\\sqrt{n}}\\)です。 ここで\\(sd\\)は標本から計算された標準偏差（※\\(n-1\\)で割る方なので注意），\\(n\\)はサンプルサイズになります。 そして，標本平均±2×SEの範囲を（約）95%信頼区間と呼びます。 95%信頼区間という考えを使うことで，標本平均から母平均を予測するというのが， 社会調査における推測の基本になります。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html#信頼区間",
    "href": "sampling_basic2.html#信頼区間",
    "title": "5  標本調査の基礎知識2",
    "section": "5.5 95%信頼区間",
    "text": "5.5 95%信頼区間\nそれにしても，本当に（約）95%信頼区間を計算すると， その範囲に母平均があるのでしょうか。 このことをRで確認してみましょう。\nここでは母平均60・母標準偏差10として， サンプルサイズ100の標本を100回生成し，標本平均±2×標準誤差の範囲を描画します。 さらに，母平均を含む場合は灰色・含まない場合は青色にしてみます。\n\n\nコード\n# パラメータ設定\npop_mean &lt;- 60      # 母平均\npop_sd   &lt;- 10      # 母標準偏差\nn        &lt;- 100     # サンプルサイズ\nnum_samples &lt;- 100  # 標本の数\n\n# シミュレーション結果を格納するデータフレーム\nset.seed(12)  # 再現性のための乱数シード\nresults &lt;- data.frame(\n  sample_id = 1:num_samples,\n  lower = numeric(num_samples),\n  upper = numeric(num_samples),\n  outside = logical(num_samples)\n)\n\n# 標本を取り出して信頼区間を計算\nfor (i in 1:num_samples) {\n  sample_data &lt;- rnorm(n, mean = pop_mean, sd = pop_sd)\n  sample_mean &lt;- mean(sample_data)\n  sample_se &lt;- pop_sd / sqrt(n)  # 標準誤差\n  ci_lower &lt;- sample_mean - 2 * sample_se\n  ci_upper &lt;- sample_mean + 2 * sample_se\n  results$lower[i] &lt;- ci_lower\n  results$upper[i] &lt;- ci_upper\n  results$outside[i] &lt;- !(pop_mean &gt;= ci_lower & pop_mean &lt;= ci_upper)\n}\n\n# 信頼区間プロット\nplot(1:num_samples, rep(pop_mean, num_samples),\n  type = \"n\", ylim = range(c(results$lower, results$upper)),\n  xlab = \"標本番号\", ylab = \"値\", main = \"100の標本と95%信頼区間\"\n)\nabline(h = pop_mean, col = \"red\", lty = 2)  # 母平均の水平線\n\n# 各標本の信頼区間を描画\nfor (i in 1:num_samples) {\n  if (results$outside[i]) {\n    lines(c(i, i), c(results$lower[i], results$upper[i]),\n          col = \"blue\", lwd = 2)  # 母平均を含まない信頼区間\n  } else {\n    lines(c(i, i), c(results$lower[i], results$upper[i]),\n          col = \"gray\", lwd = 2)  # 母平均を含む信頼区間\n  }\n}\n\n\n\n\n\n\n\n\n図 5.7\n\n\n\n\n\n図 5.7 を見ると，100の標本の内， 標本平均±2標準誤差の範囲に母平均を含まない標本は4つという結果になりました。 この結果を見ると，95%信頼区間を計算すれば母平均を予測できるという考え方は， それほど的を外した発想ではなさそうです。 もちろん手元にある標本が「ハズレ」である可能性は常にありますから， そのリスクは念頭に置いておく必要があります。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html#大規模学力調査の分析に向けて",
    "href": "sampling_basic2.html#大規模学力調査の分析に向けて",
    "title": "5  標本調査の基礎知識2",
    "section": "5.6 大規模学力調査の分析に向けて",
    "text": "5.6 大規模学力調査の分析に向けて\nここまでに説明してきた考え方（母集団と標本，95%信頼区間）を使えば， LSAを分析し，その結果を読み解くことが可能になります。 ただし，ここで注意すべき点が二つあります。\n一つは，ここまでの説明が単純な無作為抽出を前提にしたものであるという点です。 LSAでは，層化多段抽出法や層化村落抽出法といった複雑な抽出法が採用されています。 そのため母数の推定方法が変わってきます。 とくに問題になるのが標準誤差の推定で，一般論としてLSAの方が 単純な無作為抽出に比べて標準誤差が大きくなる傾向が見られます。 標準誤差が大きくなるということは，単純な無作為抽出に比べて 95%信頼区間が大きくなるということです。\nもう一つは，LSAで議論の対象になるのは，学力という目に見えないものだという点です。 目に見えない学力をテストで測る場合，これまで扱ってきた標本抽出に伴う誤差 （これを標本誤差と呼びましょう）に， 測定の誤差（これを測定誤差と呼びましょう）が加わってきます。 詳しくは理論編で説明しますが， LSAにおける標準誤差は，標本誤差と測定誤差の両方を併せたものになります。 つまり95%信頼区間は，ここまでに学んだものより更に大きくなるということです。\n以上の2点を頭に入れておかないと，誤った推定をしてしまう危険があります。 標準誤差が大きくなるということは，（約）95%信頼区間も大きくなるということです。 これは，「母平均は49点から51点のあいだにある！」と思っていたら， 正しく標準誤差を推定すると「実は48点から52点のあいだだった」といった事態が発生することを意味します。 学力が上がった（あるいは下がった）という議論をしているときに標準誤差を見誤ると影響が大きいので， LSAの標準誤差の算出法については，この後の章の内容を踏まえて議論する必要があります。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html#統計的検定について",
    "href": "sampling_basic2.html#統計的検定について",
    "title": "5  標本調査の基礎知識2",
    "section": "5.7 統計的検定について",
    "text": "5.7 統計的検定について\n本書は，多くの社会調査の入門書で扱われている統計的検定を扱っていません。 検定が必要ないというわけではありません。 さまざまな判断をする際に，検定は有益なツールです。 報告書や論文を書く際にも，統計的検定が必要です。\nただ一方で検定はその考え方を理解することが難しく， どうしても安易な理解（p値が0.05を超えればよいなど）に流れがちです。 それよりは（約）95%信頼区間の考え方を使い， その範囲内でLSAの結果を読み解いた方が，初学者には有益だと判断しました。 統計的検定について知りたい方は，社会調査の入門書などを参照してください。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "sampling_basic2.html#footnotes",
    "href": "sampling_basic2.html#footnotes",
    "title": "5  標本調査の基礎知識2",
    "section": "",
    "text": "ランダムですから，私が作成した 図 5.1 と皆さんが作成する図は微妙に違う可能性があります。↩︎\n実はsapplyは行列（matrix）やリストも返しますが，詳細は省略します。↩︎\n実はRの場合，num + 2と書くだけでokです。↩︎\n「平均±1.96×標準偏差のあいだに95%のデータが入る」がより正しい表現ですが， 1.96だと計算が面倒なので，ざっくり2にしています。↩︎\nここで使うのは，\\(n-1\\)で割った方の分散です。↩︎\nそんなリスクは許せないという場合は，±3×標本平均の標準偏差まで 緑の矢印を広げるとよいでしょう。この場合，99%の標本は緑の矢印の範囲に母平均を含みます。 ただ，あまり範囲を広げると「母平均は90点から50点のどこかにあります」といった， 「ハズレもしないが役に立たない」予測になってしまいます。 あるいは，サンプルサイズ\\(n\\)を増やすのもよいでしょう。 この場合，標本平均の標準偏差が小さくなりますのでリスクを減らすことができます。 ただし今度は調査対象が増えますので，調査にかかる経費や手間が増加することになります。↩︎",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>標本調査の基礎知識2</span>"
    ]
  },
  {
    "objectID": "dataframe.html",
    "href": "dataframe.html",
    "title": "6  データフレーム",
    "section": "",
    "text": "6.1 データフレームとは\nここまでは，Rのベクトル・リストの機能を使って学んできました。 ただ，本格的に社会調査のデータを扱うには，この二つだけでは力不足です。 社会調査の分析では， さまざまな情報（ID・性別・学力etc）を格納したベクトルを生成し， それらをまとめて扱う必要があるからです。\nここで必要になるのが，データフレームという機能です。 学力調査の場合，少なくとも次のような変数をまとめて扱う必要があります。\n今，id・成績（score）・性別（gender）という変数が含まれた 仮の学力調査のデータを考えましょう。 簡単のため，idは「1番から7番」， 成績は「50点・55点・60点・65点・70点・欠測・欠測」， 性別は「女子・女子・女子・欠測・男子・男子・男子」とします。 欠測というのは，何らかの理由でたまたまデータが得られなかった箇所のことです。\nRでは，data.frameという関数を使ってデータフレームを作成します。 以下の例では，id，score，genderという3つのベクトルを作成し， その結果をdata.frame関数で1つにまとめています。\nちなみに欠測の箇所は，999という値を入れています。 これは社会調査の慣例で，欠測には99や999といった 「ありえない」数値を入れることでデータが存在しないことを示しているのです。\nid &lt;- 1:7 # 出席番号\nscore &lt;- c(50, 55, 60, 65, 70, 999, 999) # 成績。999は欠測\ngender &lt;- c(1, 1, 1, 99, 2, 2, 2) # 性別。1が女子，2が男子\n\ndat &lt;- data.frame(id, score, gender)",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "dataframe.html#データフレームとは",
    "href": "dataframe.html#データフレームとは",
    "title": "6  データフレーム",
    "section": "",
    "text": "ID: 生徒一人ひとりの番号。出席番号など\n成績: 一人ひとりの成績\n個々人の情報: たとえば性別やアンケートに対する回答など",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "dataframe.html#データフレームの取り扱い",
    "href": "dataframe.html#データフレームの取り扱い",
    "title": "6  データフレーム",
    "section": "6.2 データフレームの取り扱い",
    "text": "6.2 データフレームの取り扱い\nさて，データフレーム（今回はdatというオブジェクト）の扱い方を考えてみましょう。 たとえばnames関数を使うと，データフレーム内の変数名を知ることができます。 また，head関数を使うと，データフレームの上6行の情報を得ることができます。 上から何行の数値がほしいかは，head関数の引数にn = 4といった形で指定することができます。\n\nnames(dat)\n\n[1] \"id\"     \"score\"  \"gender\"\n\nhead(dat)\n\n  id score gender\n1  1    50      1\n2  2    55      1\n3  3    60      1\n4  4    65     99\n5  5    70      2\n6  6   999      2\n\nhead(dat, n = 4) # 上から4行を表示\n\n  id score gender\n1  1    50      1\n2  2    55      1\n3  3    60      1\n4  4    65     99\n\n\nデータフレーム内の変数にアクセスする場合は，$マークを使います。 datの成績（score）が見たい場合は，dat$scoreかdat[[\"score\"]]と入力します。 あるいは，成績は前から2列目に格納されているので，dat[, 2]としても構いません。 ちなみにdat[, 2]はデータフレームの前から2列目を意味します。 dat[3, ]とすると3行目ですし，dat[2, 2]とすると2行目の2列目の数字（55）が返ってきます1。\ndat$scoreもdat[[\"score\"]]もdat[, 2]も同じ情報が返ってきます2。 この中では，$を使う方法がもっとも簡単です。 試しにdat$と入力してみると，その理由がわかるかもしれません。\n\ndat$score\n\n[1]  50  55  60  65  70 999 999\n\ndat[[\"score\"]]\n\n[1]  50  55  60  65  70 999 999\n\ndat[, 2] # 2列目\n\n[1]  50  55  60  65  70 999 999\n\ndat[3, ] # 3行目\n\n  id score gender\n3  3    60      1\n\ndat[2, 2] # 2列目の2行目（55）\n\n[1] 55\n\n\nデータフレーム内の特定の値を修正したいという場合もあるかもしれません。 たとえば，「本当は1人目の成績は40点だったのに間違えて50点と入力してしまった！」といった場合です。 こういう場合は，次のような方法を使います。 まず1人目の成績は，dat$score[1]とすることで表示できます。 ここで，dat$score[1] &lt;- 40とすると，1人目の成績が40に置き換わります。 ちなみにdat[2, 2]のように行と列を指定しても構いません。\n\ndat$score[1]\n\n[1] 50\n\ndat$score[1] &lt;- 40\ndat$score\n\n[1]  40  55  60  65  70 999 999\n\ndat[2, 2] &lt;- 60 # 2行2列（＝2人目の成績）を指定しても可\ndat$score\n\n[1]  40  60  60  65  70 999 999",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "dataframe.html#欠測値の扱い方",
    "href": "dataframe.html#欠測値の扱い方",
    "title": "6  データフレーム",
    "section": "6.3 欠測値の扱い方",
    "text": "6.3 欠測値の扱い方\nデータフレームを作ったら，最初に正しく作成できているかどうか確認したほうがよいでしょう。 たとえばtableという関数を使うと，ベクトル内の要素を数えることができます。 これを度数分布と呼びます。 度数（データの数）という言葉はよく使うので，覚えておくとよいでしょう。 以下ではtable関数を使って，別変数（gender）の度数分布を作成してみます。\n\ndat$gender\n\n[1]  1  1  1 99  2  2  2\n\ntable(dat$gender)\n\n\n 1  2 99 \n 3  3  1 \n\n\n1が男子・2が女子・99は欠測ですから， 順に3・3・1で適切に入力できているようです。 一方で，成績変数（score）はこのままでは少々問題があります。 たとえば，成績の平均を計算することを考えましょう。 今のままでは，おかしな平均値が算出されてしまいます。\n\ndat$score\n\n[1]  40  60  60  65  70 999 999\n\nmean(dat$score)\n\n[1] 327.5714\n\n\n326という平均が出力される理由は，欠測の部分に 999を入力しているからです。 Rは999が欠測ということがわかりませんから，999点だと思って平均を計算してしまい， 数値がおかしくなっているのです。 これを防ぐには，Rにscoreの999は欠測であり，平均を計算するときは省いてほしい旨を 伝える必要があります。\nただ，この処理は少々面倒です。 まず，dat$scoreの999の箇所を特定する必要があります。 ここで条件を付けて要素にアクセスする 方法を思い出してみてください。 dat$score == 999と入力すれば，dat$scoreというベクトルの中の999の要素の位置を特定できます。 そのため，dat$score[dat$score == 999]とすることで999の要素を特定できるのでした。 後は，ここにRで欠測を意味するNAという値を格納すれば， Rにデータに欠測があることを伝えられます。\n\ndat$score[dat$score == 999]\n\n[1] 999 999\n\ndat$score[dat$score == 999] &lt;- NA\ndat$score\n\n[1] 40 60 60 65 70 NA NA\n\n\nではもう一回，平均を計算してみましょう。 今度はNAになるはずです。欠測が含まれているものに対して平均を計算することはできませんので， これは当然と言えば当然です。 そこで，欠測の箇所は除いて平均を計算するように伝えます。 これは，mean関数の引数に，na.rm = TRUEを与えることで実現できます。\n\nmean(dat$score)\n\n[1] NA\n\nmean(dat$score, na.rm = TRUE)\n\n[1] 59\n\n\nこれでようやく，成績の平均を計算することができました。 ちなみに，男女別の平均を計算することも可能です。 Rでは，tapplyという関数を使うことで，グループごとに処理が可能です。 tapplyの引数には，順に「処理したい値」「個々の属するグループ」 「行いたい処理」を与えます。 今回は男女別の成績の平均を計算したいので，順にscore, gender, meanを与えることになります。 欠測を無視するために，最後にna.rm = TRUEも与える必要があります。\n\ntapply(dat$score, dat$gender, mean, na.rm = TRUE)\n\n       1        2       99 \n53.33333 70.00000 65.00000",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "dataframe.html#lsaのデータファイルを扱う",
    "href": "dataframe.html#lsaのデータファイルを扱う",
    "title": "6  データフレーム",
    "section": "6.4 LSAのデータファイルを扱う",
    "text": "6.4 LSAのデータファイルを扱う\nここまでは説明のために，自分で作成したデータフレームを使っていました。 しかし実際の分析では， すでに用意されたデータをデータフレームとして読み込むことが一般的です。\n\n6.4.1 データの読み込み\n以下では，PISA2012の日本のデータをRに読み込むことを考えます。 普通は自分のPCに保存されているデータを使うのですが， そのためにはフォルダやパスといった概念を知っておく必要があります。 フォルダやパスの説明は少し大変なので， 本書では，私がウェブ上に用意したcsvファイルをRに読み込むことにします。 ここで言うcsvファイルとは，カンマ（,）で項目を区切ったデータのことで， 社会調査ではよく使われます。\nRにcsvファイルを読み込む際は，read.csvという関数を使います。 今回はウェブ上にあるcsvファイルを読み込むので， csvファイルのある場所（url）をread.csvの引数に設定します。 読み込んだデータは，jpn2012というデータフレームに格納しています。\n\nurl &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012stuJPN.csv\"\njpn2012 &lt;- read.csv(url)\n\n\n\n6.4.2 データフレームの確認1\n先ほど読み込んだjpn2012の中身を，names関数やhead関数を使って確認してみましょう。 かなりデータファイルが大きいので，ここでは最初の10列だけ表示しています。\n\nnames(jpn2012)[1:10] # names関数。変数名を出力\n\n [1] \"CNT\"      \"SUBNATIO\" \"STRATUM\"  \"OECD\"     \"NC\"       \"SCHOOLID\"\n [7] \"StIDStd\"  \"ST01Q01\"  \"ST02Q01\"  \"ST03Q01\" \n\nhead(jpn2012, 10)[, 1:10] # head関数。最初の10人分のデータを出力\n\n   CNT SUBNATIO STRATUM OECD    NC SCHOOLID StIDStd ST01Q01 ST02Q01 ST03Q01\n1  JPN  3920000 JPN0101    1 39200        1       1      10       1       9\n2  JPN  3920000 JPN0101    1 39200        1       2      10       1      12\n3  JPN  3920000 JPN0101    1 39200        1       3      10       1       4\n4  JPN  3920000 JPN0101    1 39200        1       4      10       1       6\n5  JPN  3920000 JPN0101    1 39200        1       5      10       1      12\n6  JPN  3920000 JPN0101    1 39200        1       6      10       1       4\n7  JPN  3920000 JPN0101    1 39200        1       7      10       1      11\n8  JPN  3920000 JPN0101    1 39200        1       8      10       1       8\n9  JPN  3920000 JPN0101    1 39200        1       9      10       1      10\n10 JPN  3920000 JPN0101    1 39200        1      10      10       1       1\n\n\n$を使って，個々の変数にアクセスすることも可能です。 たとえば，ST03Q01変数（これは生まれ月の変数です）を見てみます。 すべて表示すると数千人分のデータになるので，ここでは最初の12人分だけ表示します。\n\njpn2012$ST03Q01[1:12] # $を使ってデータにアクセス\n\n [1]  9 12  4  6 12  4 11  8 10  1  6  1\n\n\nPISA2012は，日本では高校1年生（正確には学校に通う15歳）を対象に実施されています。 高校1年生の生まれ月はどのように分布しているのでしょうか。 table関数を使うことで，標本となった人たちの生まれ月の度数分布を確認します。\n\ntable(jpn2012$ST03Q01)\n\n\n  1   2   3   4   5   6   7   8   9  10  11  12 \n521 456 501 532 533 521 574 560 541 547 510 555 \n\n\n多少のばらつきはありますが，特定の誕生月の子どもが多いということはなさそうに思えます。 パーセント表示にしたほうが見やすいかもしれません。 table関数の出力を，prop.table関数の引数にすることで割合を表示することができます。 ただ，素の表示は見づらいので100倍して100分率にし， さらにround関数を使って小数桁数を制御したほうがよいでしょう。\n\ntb &lt;- table(jpn2012$ST03Q01)\nprop.table(tb)\n\n\n         1          2          3          4          5          6          7 \n0.08203433 0.07179972 0.07888521 0.08376634 0.08392379 0.08203433 0.09037947 \n         8          9         10         11         12 \n0.08817509 0.08518344 0.08612817 0.08030231 0.08738781 \n\n# 100倍する\nprop.table(tb) * 100\n\n\n       1        2        3        4        5        6        7        8 \n8.203433 7.179972 7.888521 8.376634 8.392379 8.203433 9.037947 8.817509 \n       9       10       11       12 \n8.518344 8.612817 8.030231 8.738781 \n\n# round関数で小数桁数を1桁に限定\nround(prop.table(tb) * 100, 1)\n\n\n  1   2   3   4   5   6   7   8   9  10  11  12 \n8.2 7.2 7.9 8.4 8.4 8.2 9.0 8.8 8.5 8.6 8.0 8.7 \n\n\nどの生まれ月の人も，だいたい7%から9%となっています。 多少の増減はありますが，特定の月が極端に多いということはなさそうです。\nさらに，生まれ月を男女別に集計したいということもあるかもしれません。 table関数は，複数の引数を設定することで，男女別の集計にも対応できます。 これをクロス集計と呼びます。\n\ntable(jpn2012$ST04Q01, jpn2012$ST03Q01)\n\n   \n      1   2   3   4   5   6   7   8   9  10  11  12\n  1 263 225 226 249 268 247 263 264 249 275 226 266\n  2 258 231 275 283 265 274 311 296 292 272 284 289\n\n\nパーセント表示がしたいという場合は，先ほどと同じくprop.table関数を使います。 引数の1は，横方向に100%にしてほしいという意味です。 2に設定すると，縦方向に100%で表示されます。\n\ntb &lt;- table(jpn2012$ST04Q01, jpn2012$ST03Q01)\nprop.table(tb, 1)\n\n   \n             1          2          3          4          5          6\n  1 0.08705727 0.07447865 0.07480967 0.08242304 0.08871235 0.08176101\n  2 0.07747748 0.06936937 0.08258258 0.08498498 0.07957958 0.08228228\n   \n             7          8          9         10         11         12\n  1 0.08705727 0.08738828 0.08242304 0.09102946 0.07480967 0.08805031\n  2 0.09339339 0.08888889 0.08768769 0.08168168 0.08528529 0.08678679\n\n\nこちらもround関数に渡すことで桁数を抑制できます。 次の例では数値を100倍したあとに，小数桁数を1桁に設定しています。\n\nround(prop.table(tb, 1) * 100, 1)\n\n   \n      1   2   3   4   5   6   7   8   9  10  11  12\n  1 8.7 7.4 7.5 8.2 8.9 8.2 8.7 8.7 8.2 9.1 7.5 8.8\n  2 7.7 6.9 8.3 8.5 8.0 8.2 9.3 8.9 8.8 8.2 8.5 8.7\n\n\n男女によって多少のズレはありますが，女子だから（あるいは男子だから）といって 特定の出生月に偏るといったことはなさそうに思えます。\n\n\n6.4.3 データフレームの確認2\n続いて，成績の変数も確認してみましょう。 PISAは読解リテラシー・数学リテラシー・科学リテラシーという3領域を調査しています。 ここでは，読解リテラシーの成績が格納されたPV1READという変数を見てみます。 PV1が何かは今は気にしなくて構いません （PVについては，推算値法の章で扱います）。\n最初に，summary関数を使って，最大値・最小値・平均値などを確認しましょう。\n\nsummary(jpn2012$PV1READ)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  101.8   473.9   545.1   537.8   606.1   904.8 \n\n\nhist関数を使うと成績の分布を視覚的に確認することができます。\n\nhist(jpn2012$PV1READ, main = \"読解リテラシーのヒストグラム\", xlab = \"スコア\", ylab = \"度数\")\n\n\n\n\n\n\n\n\n場合によっては，読解リテラシーと数学リテラシーの関係を確認したいということもあるでしょう。 この場合は，plotという関数が使えます。 ここでは，読解（PV1READ）と数学（PV1MATH）の関係を見てみましょう。\n\nplot(jpn2012$PV1READ, jpn2012$PV1MATH, xlab = \"読解リテラシー\", ylab = \"数学リテラシー\")\n\n\n\n\n\n\n\n\n読解リテラシーは男女によって差があるのではないか，と思う人もいるかもしれません。 こういう場合，たとえば箱ひげ図が使えます。 Rでは，boxplotという関数を使うことで，箱ひげ図が描けます。\n\nboxplot(jpn2012$PV1READ ~ jpn2012$ST04Q01, xlab = \"男女（1:女子，2:男子）\", ylab = \"読解リテラシー\")\n\n\n\n\n\n\n\n\nわずかですが，女子のほうが読解リテラシーが高い傾向があるようです。 先ほど紹介したtapply関数を使えば，男女の平均値の差を示すことも可能です。\n\ntapply(jpn2012$PV1READ, jpn2012$ST04Q01, mean)\n\n       1        2 \n548.8090 527.7306 \n\n\n女子（1）が548.8に対し，男子（2）が527.7点なので，女子のほうが20ポイントほど読解リテラシーが高いようです。\n\n\n6.4.4 データフレームの確認3\n読み込んだデータに欠測値がある場合も珍しくありません。 たとえばPISA2012のESCSという変数を見てみます。 ESCS はEconomic Social and Cultural Statusの略で， 子どもの家庭環境を示す変数です。 ESCSは，子どもに「お父さんやお母さんの学歴」 「お父さんやお母さんの職業」「家庭のある本の冊数」などを尋ね， その回答をもとに作成されています。 数値は調査に参加したOECD加盟国の平均が0・標準偏差1に調整されていますので， 0だと平均的な家庭の子ども，2だと相当に恵まれた家庭に育った子ども， -2だと厳しい状況にある子ども・・・といった解釈ができるでしょう。\nさて，PISA2012のESCS変数では9999が欠測値になっています。 お父さんやお母さんの職業・学歴を答えたくないという子もいますから， 欠測があることは珍しいことではありません。 ただ，欠測をそのままにしておくと，平均や標準偏差の計算結果がおかしくなります。 実際，summary関数を使うと，中央値と平均値が大きくズレるなど， おかしなデータになっていることが確認できます。 ヒストグラムを見ても，0付近にほとんどのデータが固まっているのに 10000付近に僅かにデータが存在するなど，変なグラフになってしまいます。\n\nsummary(jpn2012$ESCS)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  -2.35   -0.61   -0.06  261.27    0.53 9999.00 \n\nhist(jpn2012$ESCS, main = \"\", xlab = \"ESCS\", ylab = \"度数\")\n\n\n\n\n\n\n\n\nこのままでは分析に支障がでるので，9999が欠測であることをRに伝えましょう。\n\njpn2012$ESCS[jpn2012$ESCS == 9999] &lt;- NA\n\n欠測値をNAに指定すると，summary関数やhist関数の出力が適切なものに修正されます。\n\nsummary(jpn2012$ESCS)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-2.35000 -0.63000 -0.09000 -0.07668  0.48000  2.04000      166 \n\nhist(jpn2012$ESCS, main = \"\", xlab = \"ESCS\", ylab = \"度数\")\n\n\n\n\n\n\n\n\n読み込んだデータに欠測値がある場合，気づかないまま分析すると誤った結果につながりかねません。 データを読み込んだときは，tableやsummaryあるいはhistといった関数を使い， おかしなデータが含まれていないか確認する習慣を付けたほうがよいでしょう。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "dataframe.html#footnotes",
    "href": "dataframe.html#footnotes",
    "title": "6  データフレーム",
    "section": "",
    "text": "行と列がよくわからないという人は，「行列で縦か横か迷ったら」をご覧ください。↩︎\nなぜ同じことをする方法がいくつもあるのかと思う人もいるでしょうが， それぞれ異なった使い道があるのです。 本書では，Replication Methodで具体例を示します。↩︎",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>データフレーム</span>"
    ]
  },
  {
    "objectID": "stat_basics.html",
    "href": "stat_basics.html",
    "title": "7  相関係数と回帰分析",
    "section": "",
    "text": "7.1 相関係数\nここではLSAの分析で頻出する統計技法として， 相関係数と回帰分析を扱います。 基本的な考え方を説明するだけにとどめますので， 詳しいことは入門書や専門書を読んで勉強してください。\n二つの量的変数1の関連性を知りたいときに， 相関係数という，量的変数同士の直線的な関連の強さを示す指標を使うことがあります。 相関係数\\(r\\)は，次の式で求められます。\n\\[r = \\frac{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}\n{\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\bar{x})^2}\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2}}\\]\n今，図 7.1 のような国語の成績と数学の成績を考えましょう。 簡単のため，平均はいずれも60点とします。\njp &lt;- c(25, 70, 60, 65, 80)\nmt &lt;- c(45, 30, 60, 70, 95)\nplot(jp, mt, xlim = c(20, 100), ylim = c(20, 100))\nabline(v = mean(jp), col = \"gray\", lty = 2)\nabline(h = mean(mt), col = \"gray\", lty = 2)\n\n\n\n\n\n\n\n図 7.1\n図 7.1 を見ると，2人目（国語70点，数学30点）を除けば， 国語の成績と数学の成績には直線関係があります。 この直線関係の強さを，一つの数字で表現することを考えます。 具体的な手順は，以下のとおりです。\nまず，国語と数学の個々の点数から平均を引きます。 その上で，国語と数学の点数を掛け合わせます。 Rで表現すると，次のようになります。\njp - mean(jp)\n\n[1] -35  10   0   5  20\n\nmt - mean(mt)\n\n[1] -15 -30   0  10  35\n\n(jp - mean(jp)) * (mt - mean(mt))\n\n[1]  525 -300    0   50  700\nここで，(jp - mean(jp)) * (mt - mean(mt))の値は， 「国語も数学も平均より低い人（1番目）」あるいは「国語も数学も平均より高い人（4番目・5番目）」はプラスになります。 他方， 「国語か数学の一方は平均より高いが，もう一方は平均より低い人（2番目）」はマイナスになります。 いずれも平均と同じ人（3番目）は0です。\nここで，(jp - mean(jp)) * (mt - mean(mt))の合計値を考えると， 国語と数学のあいだに関連がある場合（国語が高い人は数学も高い， あるいは逆に国語が高い人は数学が低い）は， (jp - mean(jp)) * (mt - mean(mt))の値がプラス（またはマイナス）に偏る人が多くなりますので， 合計値は大きくプラス（あるいはマイナス）になります。 国語と数学のあいだに関連がない場合，プラスの人とマイナスの人のいずれもが現れますので， (jp - mean(jp)) * (mt - mean(mt))の合計値はゼロに近づきます。\nただ，このままだと人数が増えれば増えるほど， あるいは単位が大きくなればなるほど極端な値が生じる可能性がありますので， 合計値を人数と単位で割って調整する必要があります。 これが分子の\\(\\frac{1}{n}\\)と相関係数の分母の意味です （よく見ると分母は，\\(x\\)と\\(y\\)の標準偏差の積になっています）。\nRで計算すると，次のようになります。 なお，標準偏差には\\(n\\)で割る場合と\\(n-1\\)で割る場合がありますが， 相関係数の場合，いずれを採用しても同じ（分母と分子に\\(n\\)または\\(n-1\\)が含まれるので， 割ると両者が消えてしまう）になります。 ここでは簡単のためRのsd関数を使うので，分子を\\(n-1\\)で割っています。\n# 分子\ncov_num &lt;- sum((jp - mean(jp)) * (mt - mean(mt))) / (length(jp) - 1)\n# 分母\ncov_den &lt;- sd(jp) * sd(mt)\n# 相関係数\ncov_num / cov_den\n\n[1] 0.4708717\nなお，Rには相関係数を出力する関数corがありますので， こちらを使えば容易に相関係数が出力されます。\ncor(jp, mt)\n\n[1] 0.4708717\n0.47という相関係数がどの程度かわからないという人も多いでしょう。 ここでは参考までに，\\(x\\)と\\(y\\)の相関係数が0.9・0.5・0.2・-0.2・-0.5・-0.9のそれぞれで， データの分布がどう変わるか示した 図 7.2 を載せておきます2。 相関係数が0.9や-0.9だと\\(x\\)が高いと\\(y\\)も高い（あるいは\\(x\\)が高いと\\(y\\)が低い）と言えますが， 0.5や-0.5程度だと「まあ関係あるかな？」といった程度です。 0.2や-0.2となるとほとんど関係は見いだせません。\nコード\n# 相関係数\ncorrs &lt;- c(0.9, 0.5, 0.2, -0.2, -0.5, -0.9)\n\n# 平均と標準偏差\nmeans &lt;- c(60, 60)\nsds &lt;- c(10, 10)\nn &lt;- 100 # サンプルサイズ\n\n# レイアウト設定\npar(mfrow = c(3, 2)) # 3行2列のレイアウト\nfor (r in corrs) {\n  # 共分散行列\n  covm &lt;- matrix(c(\n    sds[1]^2, r * sds[1] * sds[2],\n    r * sds[1] * sds[2], sds[2]^2\n  ), nrow = 2)\n\n  # データ生成\n  set.seed(1234) # 再現性を確保\n  data &lt;- MASS::mvrnorm(n = n, mu = means, Sigma = covm)\n\n  # プロット\n  plot(data[, 1], data[, 2],\n    main = paste(\"相関係数: \", r),\n    xlab = \"X\", ylab = \"Y\", col = \"blue\", pch = 19,\n    xlim = c(means[1] - 4 * sds[1], means[1] + 4 * sds[1]),\n    ylim = c(means[2] - 4 * sds[2], means[2] + 4 * sds[2])\n  )\n}\n\n\n\n\n\n\n\n\n図 7.2\nちなみにPISA2012のデータを使い， 読解リテラシーと数学リテラシーの相関係数 を計算すると次のようになります。\nurl &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012stuJPN.csv\"\njpn2012 &lt;- read.csv(url)\n\ncor(jpn2012$PV1READ, jpn2012$PV1MATH)\n\n[1] 0.8665053\n相関係数は0.867ですので，読解リテラシーが高い人は数学リテラシーも高い傾向があり， しかもそれはかなりはっきりした傾向であると言って良さそうです。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関係数と回帰分析</span>"
    ]
  },
  {
    "objectID": "stat_basics.html#回帰分析",
    "href": "stat_basics.html#回帰分析",
    "title": "7  相関係数と回帰分析",
    "section": "7.2 回帰分析",
    "text": "7.2 回帰分析\n\n7.2.1 単回帰分析\n教育研究では，学力\\(y\\)と何らかの要因\\(x\\)のあいだに 直線の関係があると仮定して， \\(x\\)が1変化したときの\\(y\\)の変化量（ここでは\\(\\beta_1\\)とします）を 求めたいということがあります。 式でいうと，以下のような状態です。\n\\[y = \\beta_0 + \\beta_1 x + \\epsilon\\]\nここで，\\(\\beta_1\\)と\\(\\beta_0\\)の値を求める分析法を， 回帰分析（regression analysis）といいます。 一般に\\(\\beta_1\\)は回帰係数，\\(\\beta_0\\)は切片と呼ばれます。 もちろん個々人の成績を完璧に予測することはできませんので， 一人ひとりの得点には式からのズレ（誤差）が生じます。 これが，\\(\\epsilon\\)の項（誤差項）です。 また，\\(y\\)を被説明変数（従属変数），\\(x\\)を説明変数（独立変数）と呼ぶことがあります。 とくに， \\(y = \\beta_0 + \\beta_1 x + \\epsilon\\)のような 説明変数が1つだけのモデルを，単回帰分析と呼びます。\n回帰分析の何が嬉しいかというと， 仮に勉強時間（\\(x\\)）と学力（\\(y\\)）のあいだに \\(y=10 + 1.5x\\)という関連があるなら， 勉強時間を1時間伸ばせば成績が1.5点上がる効果が期待できる といった主張が可能になる点です。 勉強時間以外にも，保護者が大卒（\\(x=1\\)）と保護者が非大卒（\\(x=0\\)）の場合に， 学力（\\(y\\)）との関連を検討し\\(y=50 + 10x\\)という関係が見られたなら， 保護者が大卒かどうかで学力に10点の差があるといった分析も可能になります。\n\\(\\beta_0\\)，\\(\\beta_1\\)の計算方法はやや面倒なので省略します。 理屈としては，個々のデータ\\(y_i\\)と\\(\\beta_0 x + \\beta_1\\)で予測される値の差が 最小になるような\\(\\beta_0\\)，\\(\\beta_1\\)を求めるということになります。 これは，\\(\\sum_{i=1}^n(y_i - (\\beta_0 + \\beta_1 x_i))^2\\)を最小にする \\(\\beta_0\\)，\\(\\beta_1\\)を求めることと同義です。 これを最小2乗法と呼びます。 回帰分析の係数の求め方は他にもありますが，とりあえずは 最小2乗法の理屈を知っておけば十分です。\nRでは，lm関数で回帰分析を行うことができます。 先ほどの国語と数学の5人のデータに，回帰分析を行ってみましょう。\n\nm1 &lt;- lm(mt ~ jp)\nprint(m1)\n\n\nCall:\nlm(formula = mt ~ jp)\n\nCoefficients:\n(Intercept)           jp  \n    26.5714       0.5571  \n\nplot(jp, mt)\nabline(m1)\n\n\n\n\n\n\n\n\nRの出力のうち，Interceptが切片（\\(\\beta_0\\)），jpが国語の回帰係数（\\(\\beta_1\\)）を 示しています。それぞれ26.6と0.56ですので，国語と数学の成績のあいだに \\(数学の点数=26.6 + 0.56 \\times 国語の点数\\)という関係があることになります。 国語の点数が60点だったら，数学の点数は\\(26.6 + 0.56\\times60 = 60.2\\)なので， だいたい60点くらいになるということです。\n続いて実際のデータに回帰分析を適用してみます。 ここでは，PISA2012の日本の読解リテラシーと ESCSの関係を見てみましょう。\n\njpn2012$ESCS[jpn2012$ESCS == 9999] &lt;- NA # 欠測の処理\nm2 &lt;- lm(jpn2012$PV1READ ~ jpn2012$ESCS)\nm2\n\n\nCall:\nlm(formula = jpn2012$PV1READ ~ jpn2012$ESCS)\n\nCoefficients:\n (Intercept)  jpn2012$ESCS  \n      543.86         39.94  \n\nplot(jpn2012$ESCS, jpn2012$PV1READ, xlab = \"ESCS\", ylab = \"PV1READ\")\nabline(m2, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n図 7.3\n\n\n\n\n\nlm関数の出力を見るとjpn2012$ESCSの係数は39.94ですから， ESCSが1単位変化すると39.9ポイント読解リテラシーが変化することがわかります。 ESCSは子どもの家庭背景を示す指標ですから， 家庭背景が恵まれている子の方が読解リテラシーが高いということです。\nもっともこれは，直線関係を仮定すると読解リテラシーとESCSの あいだに関係が見えるということに過ぎません。 図を描いてみるとわかるのですが，ESCSが高くても成績の低い生徒はいますし， 逆にESCSが低くても成績の高い子もいます（図 7.3）。 PISA2012のデータから読み溶ける読解リテラシーとESCSの関係は， 「ESCSが高い子はすべて読解リテラシーが高い」といった絶対的なものではなく， あくまで「ESCSが高い子の方が読解リテラシーが高い傾向にある」というレベルに留まっているのです。 ですから回帰分析をした際は，数値を解釈するだけでなくplotなどを使って 変数間の関連を図で把握することを心がけるようにしましょう。\n\n\n7.2.2 回帰分析の標準誤差\n回帰分析の係数についても，標準誤差を出力することが可能です。 Rでは，summary関数を使うことで標準誤差が出力されます。\n\nsummary(m2)\n\n\nCall:\nlm(formula = jpn2012$PV1READ ~ jpn2012$ESCS)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-367.33  -59.40    5.58   64.92  363.74 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   543.863      1.190  456.92   &lt;2e-16 ***\njpn2012$ESCS   39.944      1.658   24.09   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 93.07 on 6183 degrees of freedom\n  (166 observations deleted due to missingness)\nMultiple R-squared:  0.08577,   Adjusted R-squared:  0.08562 \nF-statistic: 580.1 on 1 and 6183 DF,  p-value: &lt; 2.2e-16\n\n\nいろいろ出力があって見づらいですが，Std. Errorの列が標準誤差です。 この場合，切片（Intercept）の推定値が543.863・標準誤差が1.190， ESCSの回帰係数（jpn2012$ESCS）の推定値が39.944・標準誤差が1.658ということになります。\n回帰分析の係数の標準誤差の解釈は，平均値の標準誤差とほぼ同じです。 つまり母集団において回帰分析を行うと， 切片の値は543.863±2×1.190， ESCSの回帰係数の値は39.944±2×1.658のどこかにある（と信じましょう）ということになります。\n特にESCSの回帰係数は重要で，最低でも39.944 - 2×1.658 ≒ 36.6ですから， 低めに見積もっても「ESCSが1単位増えると読解リテラシーの得点が36.6点高まる」と考えられると いうことになります。 データフレームの確認3で見たように， ESCSはだいたい2から-2程度の値を取る数値でした。 ということは，ESCSが高い子どもと低い子どもでは，4×36.6≒146で100ポイントを超える差が つくということになります。 これを大きいと見るかどうかは人によるでしょうが， 少なくとも学力と家庭環境の関連を数値化して議論できるという点で， 回帰分析は重要な分析技法と言えるでしょう。 なお，ここで行った分析は標準誤差を小さく見積もりすぎています。 より適切な標準誤差を得るための方法については， Replication Methodの章を読むようにしてください。\n\n\n7.2.3 重回帰分析\n単回帰分析は説明変数が一つだけでしたが， 学力に影響を及ぼす要因は一つだけとはかぎりません。 こうした複数の説明変数を同時に考慮したい場合に利用される方法が， 重回帰分析です。 たとえば3個の説明変数を持つ重回帰分析は， 次の式で表されます （なお，\\(x\\)の係数である\\(\\beta_1\\)や\\(\\beta_2\\)は偏回帰係数と呼ばれます）。\n\\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\epsilon\\]\n単回帰分析と違い，重回帰分析の偏回帰係数の解釈は面倒です。 今，被説明変数を学力（\\(y\\)）とし， 説明変数を保護者の学歴（\\(x_1\\)：保護者が大卒のとき1・非大卒のとき0）， 勉強時間（\\(x_2\\)：単位は時間）としましょう。 分析の結果，\\(y=50 + 10x_1 + 5x_2\\)という関連があったとします。 このとき\\(x_2\\)の偏回帰係数の解釈は， 「勉強時間（\\(x_2\\)）が1時間増えると学力（\\(y\\)）が5上がる」ではありません。 \\(x_2\\)以外に保護者の学歴（\\(x_1\\)）が存在しますので， 「保護者の学歴が大卒（\\(x_1=1\\)）の人同士を比べると，勉強時間（\\(x_2\\)）が1時間増えると学力（\\(y\\)）が5上がる」 ，あるいは 「保護者の学歴が非大卒（\\(x_1=0\\)）の人同士を比べると，勉強時間（\\(x_2\\)）が1時間増えると学力（\\(y\\)）が5上がる」になります。 前半は似たようなことを言っていますから，まとめて 「保護者の学歴が同じ人同士を比べると，勉強時間（\\(x_2\\)）が1時間増えると学力（\\(y\\)）が5上がる」でよいでしょう。 要するに重回帰分析における\\(x_1\\)の偏回帰係数\\(\\beta_1\\)は， 「\\(x_1\\)以外の説明変数（\\(x_2\\)や\\(x_3\\)）が同じ対象を比較したときに，\\(x_1\\)が1単位変化したときの\\(y\\)の変化量」になります。\n重回帰分析の利点は，「よく似たものを比べる」ことを可能にしてくれる点です。 この意義を，PISA2012のデータを使い「ひとり親家庭の低学力問題」を例に考えてみましょう。 PISA2012では，調査対象になった子どもに「一緒に住んでいる人」を尋ねています。 ここで子どもが，「お父さん」あるいは「お母さん」のみと一緒に暮らしていると回答した場合， その子は「ひとり親」であると判定できます。 PISA2012のデータセットでは，FAMSTRUCという変数に子どもの回答結果が格納されています。 このデータを使って，ひとり親家庭とそうでない家庭の学力を考えてみましょう。\n最初にFAMSTRUC変数から，「ひとり親家庭」と「それ以外の家庭」を示す変数を作ります。 FAMSTRUC変数には4つの値があり，1がひとり親（お父さん，あるいはお母さんとのみ住んでいる）， 2が二人親（お父さん・お母さんと住んでいる），3がそれ以外，9が欠測となっています。 ここでは分析のために，ひとり親を1・それ以外を2とするsingleという新しい変数を作成します。 また，欠測はNAに変換します3。\n\n# table関数でFAMSTURCの度数分布を表示\ntable(jpn2012$FAMSTRUC)\n\n\n   1    2    3    9 \n 740 5269   58  284 \n\n# single変数を作成\njpn2012$single &lt;- jpn2012$FAMSTRUC\njpn2012$single[jpn2012$single == 1] &lt;- 1\njpn2012$single[jpn2012$single %in% c(2, 3)] &lt;- 0\njpn2012$single[jpn2012$single == 9] &lt;- NA\n# single変数の度数分布\ntable(jpn2012$single)\n\n\n   0    1 \n5327  740 \n\nprop.table(table(jpn2012$single))\n\n\n        0         1 \n0.8780287 0.1219713 \n\n\n標本の約12%が「ひとり親」と判定されるという結果になりました。\nそれでは新しく作ったsingle変数を使い，回帰分析をしてみましょう。 最初に単回帰分析を行います。 式にすると，\\(PV1READ = \\beta_0 + \\beta_1 single\\)ということです。\n\nlm(jpn2012$PV1READ ~ jpn2012$single)\n\n\nCall:\nlm(formula = jpn2012$PV1READ ~ jpn2012$single)\n\nCoefficients:\n   (Intercept)  jpn2012$single  \n        545.83          -30.52  \n\n\njpn2012$singleの値が-30.5なので， 「ひとり親」の子どもと「それ以外」の子どもの読解リテラシーには， 約30ポイントの差があることがわかります。 係数がマイナスですから，「ひとり親」（\\(x=1\\)）の方が読解リテラシーが低いということです。\nこれは重要な発見ですが，ここで考えたいことは， 「ひとり親」と「それ以外」の家庭では，そもそも家庭の経済状態などに差があるのではないかということです。 実際，家庭の状況を示すESCS変数を「ひとり親」と「それ以外」で見てみると， 前者のほうが低い傾向があります。\n\ntapply(jpn2012$ESCS, jpn2012$single, summary)\n\n$`0`\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-2.35000 -0.55000 -0.01000 -0.01012  0.55000  2.04000       52 \n\n$`1`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n-2.1600 -0.9700 -0.5500 -0.4844  0.0300  1.2600      11 \n\n\nひとり親とESCSの関係を踏まえると，「ひとり親」の方が経済的に課題を抱えやすい世帯が多いと思われますから， 単純に「ひとり親」と「それ以外」を比べると， 「経済状態などによる不利」と「ひとり親家庭であることによる不利」の両方の影響を捉えていることになります。 「経済状態などによる不利」の影響は除いたうえで，「ひとり親家庭であることによる不利」を捉えるには どうすればいいのでしょうか。\nここで使われるのが重回帰分析です。 すでに指摘したように重回帰分析を使うと，「同じような人同士」を比べることが可能になるのでした。 つまり，\\(PV1READ = \\beta_0 + \\beta_1 single + \\beta_2 ESCS\\)として推定すれば， 「ESCSが同じ人同士でPV1READを比べたときに， ひとり親家庭とそうでない家庭でどの程度PV1READが違うのか」を調べることができます。\n\nlm(jpn2012$PV1READ ~ jpn2012$single + jpn2012$ESCS)\n\n\nCall:\nlm(formula = jpn2012$PV1READ ~ jpn2012$single + jpn2012$ESCS)\n\nCoefficients:\n   (Intercept)  jpn2012$single    jpn2012$ESCS  \n        546.84          -12.96           37.85  \n\n\njpn2012$singleの偏回帰係数は，-12.96になっています。 これは，「ESCSが同じ人同士で比べると，ひとり親家庭のほうが読解リテラシーが13ポイント低い」という意味になります。 単回帰分析ではjpn2012$singleの係数は-30.52でしたから，だいぶ値が小さくなっていることになります。 ESCSが同じ人同士で比べたことにより，「経済状態などによる不利」は除いたうえで， 「ひとり親家庭であることによる不利」を捉えることができたと考えられます。\n\n\n7.2.4 回帰分析の留意点\n回帰分析の係数を解釈するうえで注意してほしいことに， 「（偏）回帰係数は因果関係を示すとは限らない」というものがあります。 たとえば先ほど，ひとり親家庭のほうが読解リテラシーの点数が30ポイントほど低いという話をしました。 これは単に， 「「ひとり親」の子どもと「それ以外」の子どもを集めてきて 平均点を比べると，前者が後者より30ポイント低かった」ということに過ぎません。 「「ひとり親」になると成績が30ポイント下がる」という意味ではありませんので注意してください。\nなお，より精緻な分析を行えば回帰分析から「ひとり親家庭になると成績が◯ポイント下がる」といった 主張を導くことも可能です4。 ただしその場合でも，その結果はあくまで「ひとり親家庭になった子どもを集めてくると成績が◯ポイント下がる傾向がある」 ということを意味するに過ぎません。 「ひとり親家庭になった子どもは一人残らず成績が下がる」といった強い主張をすることは， （少なくとも現時点では）ほぼ不可能に近いということは覚えておいた方がよいでしょう。",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関係数と回帰分析</span>"
    ]
  },
  {
    "objectID": "stat_basics.html#footnotes",
    "href": "stat_basics.html#footnotes",
    "title": "7  相関係数と回帰分析",
    "section": "",
    "text": "変数という考え方を確認してください。なお，ここで説明する相関係数を質的変数に適用すると偏りが生じる場合があります。↩︎\nmvrnormを使った乱数の生成が難しいので，このコードは理解できなくて構いません。↩︎\n素のRで変数を作成するのは手間ですが，さまざまな追加パッケージを使えば効率化できます。 追加パッケージの使い方は後で説明します。↩︎\n因果関係を分析したい方は，統計的因果推論について調べてみるとよいでしょう。↩︎",
    "crumbs": [
      "導入",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>相関係数と回帰分析</span>"
    ]
  },
  {
    "objectID": "sampling_weight.html",
    "href": "sampling_weight.html",
    "title": "8  標本ウェイト",
    "section": "",
    "text": "8.1 標本ウェイトの概要\n大規模学力調査を分析する際には， 標本ウェイト（sampling weight）という 考え方を知っておく必要があります1。 今，生徒数の異なる4つの学校（仮にA校からD校とします）から 20人ずつを抽出したとします（表 8.1）。 抽出された20人の平均点を学校ごとに計算すると， 順に50点・60点・70点・80点だったとしましょう。 ここで，全体の平均点を推定することを考えます。\n単純に4校の成績を平均するのは間違いです。 人数の多いA校も人数の少ないD校も同じように扱ってしまっては， C校やD校の成績が強く反映されてしまい， 実際よりも高めの数値が出てしまうでしょう。\n(50 + 60 + 70 + 80) / 4 # 間違い\n\n[1] 65\n4校の平均点を計算するという方法の問題点を， 平均の計算式（全員のデータを足して人数で割る）から考えてみましょう。 分子は全員の点数の合計ですから， 50 * 20 + 60 * 20 + 70 * 20 + 80 * 20になります。 分母は80人ですから80です。 要するに先ほどの計算は，標本の平均点を計算してしまっているのです。\n# 標本の80人の平均点を計算している\n(50 * 20 + 60 * 20 + 70 * 20 + 80 * 20) / 80\n\n[1] 65\n全体の平均を推定するには，各学校の生徒数を考慮しなければなりません。 たとえばA校の生徒は150人ですから，そこから選ばれた20名の平均点は， 20人ではなく150人分の情報となります。 同様にB校は100人分，C校は50人分です。 ですから平均を計算する際の分子は， 50 * 150 + 60 * 100 + 70 * 50 + 80 * 20なのです。 分母は全体の生徒数である320になります。\n(50 * 150 + 60 * 100 + 70 * 50 + 80 * 20) / 320\n\n[1] 58.125\n以上を踏まえたうえで，標本ウェイトの話に入ります。\n標本ウェイトとは，標本から得られる情報を 母集団の特性に近づけるために利用される手法です。 標本ウェイトを計算するには，最初に一人ひとりの抽出確率を計算します。 たとえばA校の場合は，150人から20人を選んでいますから， 抽出確率は\\(20 \\div 150 = \\frac{20}{150}\\)になります。 同様にC校の場合は，抽出確率は\\(20 \\div 50 = \\frac{20}{50}\\)になります。 抽出確率の大きさは，調査に選ばれる可能性を意味します。 A校の生徒は選ばれにくいし，C校の生徒は選ばれやすいということです （そして，D校の生徒は100%選ばれます）2。\nここで標本ウェイトは，抽出確率の逆数になります。 すなわちA校の場合は，\\(\\frac{20}{150}\\)の逆数ですから\\(\\frac{150}{20}=7.5\\)になりますし， C校の場合は，\\(\\frac{20}{50}\\)の逆数で\\(\\frac{50}{20}=2.5\\)になります。 A校の場合は，抽出された1人の点数は7.5人分として考える必要があるし， C校の場合は，抽出された1人の点数は2.5人分として考える必要があるということです。 たとえばA校の平均点（50点）は7.5人分のデータですから， 50 * 7.5のように7.5倍して利用するのです。 全体の平均の分子は， 50 * 7.5 * 20 + 60 * 5 * 20 + 70 * 2.5 * 20 + 80 * 1 * 20 になります。 分母は7.5 * 20 + 5 * 20 + 2.5 * 20 + 1 * 20 = 320です。 計算結果は58.125になり，先ほどの計算と一致します。\n(50 * 7.5 * 20 + 60 * 5 * 20 + 70 * 2.5 * 20 + 80 * 1 * 20) / 320\n\n[1] 58.125",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>標本ウェイト</span>"
    ]
  },
  {
    "objectID": "sampling_weight.html#標本ウェイトの概要",
    "href": "sampling_weight.html#標本ウェイトの概要",
    "title": "8  標本ウェイト",
    "section": "",
    "text": "表 8.1: 標本抽出の例（各校から20人）\n\n\n\n\n\n学校名\n生徒数\n平均点\n抽出確率\n標本ウェイト\n\n\n\n\nA校\n150人\n50点\n\\(\\frac{20}{150}\\)\n\\(\\frac{150}{20}=7.5\\)\n\n\nB校\n100人\n60点\n\\(\\frac{20}{100}\\)\n\\(\\frac{100}{20}=5.0\\)\n\n\nC校\n50人\n70点\n\\(\\frac{20}{50}\\)\n\\(\\frac{50}{20}=2.5\\)\n\n\nD校\n20人\n80点\n\\(\\frac{20}{20}\\)\n\\(\\frac{20}{20}=1.0\\)\n\n\n全体\n320人\n？点",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>標本ウェイト</span>"
    ]
  },
  {
    "objectID": "sampling_weight.html#大規模学力調査における標本ウェイト",
    "href": "sampling_weight.html#大規模学力調査における標本ウェイト",
    "title": "8  標本ウェイト",
    "section": "8.2 大規模学力調査における標本ウェイト",
    "text": "8.2 大規模学力調査における標本ウェイト\nLSAにおける標本ウェイトの使い道について，もう少し紹介しておきましょう。 たとえば私立学校と公立学校の学力実態を比べることを考えます。 小学校の場合，私立学校は約200校であり，その割合は 日本の小学校全体（約20000校）の約1%に過ぎません。 ですから母集団から小学校を100校選ぶと，そこに含まれる私立学校の数は せいぜい1〜2校（あるいは0校）になってしまいます。 これでは私立学校の実態を知ることができません。\nそこでたとえば公立学校は100校・私立学校は20校を選ぶことにしましょう。 私立学校を過剰に抽出していますので，これを過剰抽出 （oversampling）と呼んだりします。 この場合，公立学校の抽出確率は\\(\\frac{100}{20000}\\)で0.5%ですが， 私立学校の抽出確率は\\(\\frac{20}{200}\\)で10%になります。 これは，「私立学校は公立学校の20倍選ばれやすい」ことを意味します。 当然，私立学校の児童も公立学校の児童の20倍選ばれやすくなります。 この状況で単純に標本で得られた成績のスコアを平均を計算してしまうと， 私立学校の児童の成績を過剰に反映してしまいます。 そこで私立学校の児童には10（0.1の逆数）， 公立学校の児童には200（0.005の逆数）のウェイトを与えれば， 母集団の平均を適切に推定できます。\n偏ってしまった標本を母集団に近づけるためにウェイトを利用することも可能です。 たとえば標本抽出の結果，まったくの偶然で， 標本は男子が80人・女子が20人になってしまったとしましょう3。 これでは男子の情報を強く反映しすぎる可能性が高いので， 母集団の男女比（おそらく1対1）を考慮して，ウェイトを作成します。 この場合は，80 * 1 = 20 * 4なので，男子に1・女子に4のウェイトを与えれば， より適切に母集団の状態を把握できると考えられます。\nその他，調査では何らかの理由で学校や生徒が調査に参加できないとか， 一部の設問に回答しないとかいった事態は珍しくありませんが， ウェイトはこうした事態（≒データの欠測）の対処にも使えます。 保護者の年収を例に取ると，極端に年収の高い （あるいは低い）人は年収を尋ねる設問には回答しない傾向があるかもしれません。 もしそうであれば，年収の高い人と低い人の標本に高めのウェイトを与えることで， より適切に母集団における保護者の年収を推定できる可能性があります。\n以上のように，標本ウェイトにはさまざまな使い道があります。 一般的なLSAのデータセットに含まれている標本ウェイトは， これらさまざまな事情で作成されたウェイトを掛け合わせたウェイトになっています。 普通，ウェイトの作成方法は調査の技術概要書（Technical Report）でその手続きが示されるだけで， 詳細はわからないことが多いようです。 ここには，詳細な手続きを示してしまうと調査対象となった個人や学校が特定されかねない という事情があると思われます。\nPISAの場合，個々人のウェイトはW_FSTUWTという変数に格納されています。 分析の際は，このウェイトを使って推定値を算出する必要があります。 以下では，PISA2012の日本のデータを例に，W_FSTUWTとその利用法を見てみましょう。\n最初に，W_FSTUWTがどのような変数なのか確認するために， 10人分のウェイトを表示してみます。\n\nurl &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012stuJPN.csv\"\njpn2012 &lt;- read.csv(url)\njpn2012$W_FSTUWT[1:10] # 標本ウェイト。最初の10個のみ表示\n\n [1] 179.3596 179.3596 179.3596 188.3276 179.3596 179.3596 179.3596 188.3276\n [9] 179.3596 188.3276\n\n\n順に179.35，179.35・・・と数値が続いているのがわかります。 要は1人目のデータは179.35人分，2人目のデータは179.35人分・・・と解釈していくということです。\nちなみにウェイトを合算すると，PISA調査で対象となった母集団の人数 （約100万人）になります。\n\nsum(jpn2012$W_FSTUWT) # ウェイトを合計すると，日本の15歳の人数になる\n\n[1] 1128179\n\n\nウェイトを使って平均を計算する場合は，weighted.mean関数を利用します。 ここでは，読解リテラシーの平均PV1READを計算してみましょう。 参考までにウェイトを利用しない場合の推定値も計算しておきます。\n\n# PV1READの平均\nweighted.mean(jpn2012$PV1READ, jpn2012$W_FSTUWT)\n\n[1] 538.1164\n\n# ウェイトなし\nmean(jpn2012$PV1READ)\n\n[1] 537.757\n\n\nPISA2012の日本のデータの場合，ウェイトを利用してもしなくても， それほど大きな差は生じません。 ただ，データによっては大きな差が生じるケースもある4ので， 標本ウェイトは常に利用しておいたほうがよいでしょう。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>標本ウェイト</span>"
    ]
  },
  {
    "objectID": "sampling_weight.html#lsaを分析する際に重要なこと",
    "href": "sampling_weight.html#lsaを分析する際に重要なこと",
    "title": "8  標本ウェイト",
    "section": "8.3 LSAを分析する際に重要なこと",
    "text": "8.3 LSAを分析する際に重要なこと\nLSAの分析者が標本ウェイトについて知っておくべきことは，次の2点です。\n一つは，分析を行う際は適切なウェイトを利用するということです。 LSAのデータセットには調査設計を反映した複数のウェイトが含まれていることが珍しくありません。 当然ですが，誤ったウェイトを利用すると間違った推定に繋がります。 ですから，個々のウェイトが作成された大まかな経緯と， それぞれのウェイトの使い方を把握しておく必要があります。 こうした情報は，個々のデータセットの利用方法を示した文書に記載されていることが多いので， データを利用する前に目を通しておく必要があります。\nもう一つは，適切なソフトウェアを使って分析を行うということです。 世間にはさまざまな統計解析のためのソフトウェアがありますが， そこには標本ウェイトを扱えないものも存在します。 たとえば社会科学で有名なソフトウェアの一つであるSPSSは， Baseパッケージだけでは標本ウェイトを扱えません5。 自身が利用しているソフトウェアが標本ウェイトを扱えるかどうか， 事前に確認しておくことが必要です。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>標本ウェイト</span>"
    ]
  },
  {
    "objectID": "sampling_weight.html#footnotes",
    "href": "sampling_weight.html#footnotes",
    "title": "8  標本ウェイト",
    "section": "",
    "text": "たんにウェイトと呼ばれることもあります。↩︎\n実際のLSAでは，所属する子どもの人数に応じて学校の抽出確率が変動する 確率比例抽出（Probabilities Proportional to their Size: PPS）という手法が利用されますので， 個々の生徒の抽出確率はほぼ等しくなります。↩︎\n性別が重要な変数であるなら，このような結果にならないように， 事前に男女で層化しておくことが必要でしょう。↩︎\n本書で扱うデータの範囲では，TIMSSの教員票に注意が必要です。↩︎\nComplex Samplesを利用する必要があります。 なお，Baseパッケージにある「ケースの重み付け」は標本ウェイトを扱うための設定ではありません。↩︎",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>標本ウェイト</span>"
    ]
  },
  {
    "objectID": "replication.html",
    "href": "replication.html",
    "title": "9  Replication Method",
    "section": "",
    "text": "9.1 複雑な調査設計における標準誤差\nここまでの説明は，単純な無作為抽出（SRS）を前提にしていました。 しかしLSAで単純な無作為抽出が採用されることはまずありません。 そのため，ここまで説明してきた母集団の推定方法をそのままLSAに適用することはできないのです。 とくに問題になるのが，標準誤差の算出です。 一般的な傾向として，LSAで利用されている標本抽出法で得られた標本に対して， SRSを前提とした標準誤差を算出すると小さめの値が得られます。 この問題に対処するため，LSAではReplication Method（反復法）と総称される技術が採用されます。\n最初に複雑な調査設計における標準誤差の問題を理解するため， 2段階抽出で100校からそれぞれ20人の生徒を抽出し，生徒の学力を調べたという状況を シミュレーションしてみましょう。 ここでは，各学校の平均点は平均50・標準偏差10の正規分布から抽出したランダムな値とします。 また，各学校の生徒の成績はその学校の平均点に，平均0・標準偏差5の正規分布から抽出した ランダムな値を加えたものとします。 なお，母集団における学校数・各校の生徒数を無限とするなら，母平均は50になります1。\n# シミュレーションの設定\nset.seed(1234)\nn_sch &lt;- 100 # 学校数\nn_std &lt;- 20 # 各学校の生徒数\nmean_s &lt;- 50 # 学校の平均点\nsd_sch &lt;- 10 # 学校の平均点の標準偏差\nsd_std &lt;- 5 # 生徒の成績の標準偏差\n\n# データ生成\nsch_score &lt;- rnorm(n_sch, mean_s, sd_sch) # 学校平均\nsch_id &lt;- rep(1:n_sch, n_std) # 学校のID\nstd_err &lt;- rnorm(n_sch * n_std, 0, sd_std) # 学校平均に加える生徒の得点\n\n# 生徒のスコアを計算\nscore &lt;- sch_score[sch_id] + std_err\n\n# データフレームの作成\ndata &lt;- data.frame(\n  sch_id = sch_id,\n  score = score\n)\n得られた標本から，SRSを仮定した平均と標準誤差を計算してみます。 標準誤差を忘れてしまった人は， 標本調査の基礎知識2を読んでみましょう。\nmean(data$score) # 平均\n\n[1] 48.45531\n\nsd(data$score) / sqrt(nrow(data)) # 標準誤差\n\n[1] 0.2502844\n平均48.45・標準誤差は0.25になりました。 （約）95%信頼区間を考えてみると， 48.45±2×0.25≒48.9〜47.95で，母平均（=50）を捉えそこねています。\n次に，各学校ごとに平均点が異なるという設定を踏まえて標準誤差を算出してみましょう。 ここでは，マルチレベルモデルという統計技法を利用して標準誤差を算出します。 マルチレベルモデルは難しいので，覚える必要はありません。 なお，Colabでマルチレベルモデルをするには，以下のコマンドを実行する必要があります。 コマンドの意味については，intsvyを使うで解説します。\n# R on Colab上でlme4を使う\n# ダウンロード\nsystem(\"curl -L -o library.tar.gz https://github.com/kawa5902/LSAdata/raw/refs/heads/main/202502library.tar.gz\")\n# 解凍\nsystem(\"tar -xzf /content/library.tar.gz -C /content\")\n.libPaths(\"library\")\nmod &lt;- lme4::lmer(score ~ 1 + (1 | sch_id), data = data)\nsummary(mod)$coefficients[\"(Intercept)\", c(\"Estimate\", \"Std. Error\")]\n\n  Estimate Std. Error \n 48.455310   1.013182\n平均は同じく48.45ですが，標準誤差は1.01と4倍以上の値になっています。 （約）95%信頼区間を考えると， 48.45±2×1.01≒50.45〜46.45なので，こちらは母平均を捉えています。\nSRSが標準誤差を過小評価する理由は， 標本抽出の方法で指摘した 「個々の学校から抽出された生徒は似ている」ことを踏まえていないからです。 今回利用したデータは， 個々の学校の平均点に差がある（≒平均点の高い学校の生徒はおしなべて成績がよい） という状況のもとで生成されています。 そのため個々の学校の生徒の成績が似通っており， SRSが仮定するほど多くの情報量が得られない（≒標準誤差が大きくなる）のです。\n加えて本書では詳しく解説しませんが， 通常の社会調査において母集団は有限であり， さらに母集団から抽出した個体を母集団に戻す（≒調査対象になった個体を 再び調査対象に選ぶこと。復元抽出と言います）こともありません。 このような状況下（有限母集団かつ非復元抽出）では 標準誤差の算出はさらに複雑になります2。\n適切な標準誤差を得るには，母集団情報と 標本抽出法も踏まえた標準誤差の算出が必要です3。 ただ，この方法は標本抽出に詳しく， かつ詳細な調査設計を知る人間でないと設定することが困難です。 加えて詳細な調査設計を公開してしまうと， 調査対象となった学校や個人が特定されてしまう危険も生じます。 そこでLSAで利用されている方法が，Replication Methodです。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Replication Method</span>"
    ]
  },
  {
    "objectID": "replication.html#replication-methodとは",
    "href": "replication.html#replication-methodとは",
    "title": "9  Replication Method",
    "section": "9.2 Replication Methodとは",
    "text": "9.2 Replication Methodとは\nReplication Methodとは，標本から新たな標本を複数回サンプリング（＝リサンプリング）し， 各回で得られた推定値から母集団の推定値を求めようとする方法の総称です。 もっとも有名な手法はブートストラップ法（Bootstrap method）だと思いますが， 本書で紹介するLSAでは，BRR法（Balanced Repeated Replication method）や JK法（JackKnife method）といったReplication Methodが利用されています。\nここではシンプルなReplication Methodの例として， 層化抽出でない場合のジャックナイフ法（JK1法）による 標準誤差の算出法を紹介します。 JK1法では「標本を一つずつ順に除外する」ことで新たな標本を生成します。 先ほどの例のように，学校ごとに生徒を抽出していた場合は 「標本の学校を1つずつ順に除外する」という手順で標本を作成します。 標準誤差は，以下の式で算出されます。 \\[JK法の標準誤差 = \\sqrt{(\\frac{作成した標本数-1}{作成した標本数}) * \\sum{(作成した標本の推定値 - 標本の推定値) ^ 2}}\\]\n\n# JK1で標準誤差を計算\n# 標本の平均を計算\nall_mean &lt;- mean(data$score)\n\n# 学校を1つずつ除外して平均を計算\n# unique関数はベクトル内にある学校IDを数える\njk_mean &lt;- sapply(unique(data$sch_id), function(id) {\n  mean(data$score[data$sch_id != id])\n})\n\n# ジャックナイフ標準誤差の計算\nse &lt;- sqrt(\n  (length(jk_mean) - 1) / length(jk_mean) * sum((jk_mean - all_mean)^2)\n)\n\n# 平均と標準誤差\nc(mean = all_mean, se = se)\n\n     mean        se \n48.455310  1.013182 \n\n\n先ほどのマルチレベルモデルと同じ推定値が得られています。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Replication Method</span>"
    ]
  },
  {
    "objectID": "replication.html#replication-weightsとは",
    "href": "replication.html#replication-weightsとは",
    "title": "9  Replication Method",
    "section": "9.3 Replication Weightsとは",
    "text": "9.3 Replication Weightsとは\nReplication Methodでは， 先ほど紹介したJK1法のように何らかのルールに従って標本の一部を除外したり， あるいは逆に標本を2倍にしたりといった方法を使って新たな標本を作成します。 ここで標本の一部を除外する， あるいは標本を2倍にするといった作業は， 個々の標本のウェイトを0にする，あるいはウェイトを2にすることと同義です。 そしてウェイトを使えば，個々の標本のウェイトを0.5にするといった， さらに複雑な標本作成も可能です。\nこの発想を利用して， LSAでは新たな標本の作成法と作成回数をウェイトで表現します。 このとき利用されるウェイトを，Replication Weightsと呼びます。 Replication Weightsを利用すれば，Replication Methodの詳細は知らなくても 標準誤差が算出できます。\nたとえばPISAは，FayのBRRというReplication Methodが採用され， 標準誤差の算出の際は80個の標本を作ることになっています4。 ただ，分析者がBRR法に詳しい必要はありません。 PISAのデータセットにはW_FSTR1からW_FSTR80という80個のReplication weightsが存在し， 分析者はこれを使って標本を作成することができるからです。\nPISA2012のデータを使い， Replication Weightsの利用方法を見てみましょう。 具体的には，読解リテラシーPV1READの平均を計算することを考えます。 平均と標準誤差を計算する場合は， 最初に標本ウェイトW_FSTUWTを使った推定値を計算します。 これがPV1READの平均値となります。 その後に，Replication Weightsを使った推定値を計算します。 PISAの場合は80個のReplication weightsが存在するので，80回の計算が必要になります。\n\nurl &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012stuJPN.csv\"\njpn2012 &lt;- read.csv(url)\n\nfin_m &lt;- weighted.mean(jpn2012$PV1READ, jpn2012$W_FSTUWT) # 最終的な標本ウェイト\nfin_m\n\n[1] 538.1164\n\nweighted.mean(jpn2012$PV1READ, jpn2012$W_FSTR1) # 1個目の標本作成\n\n[1] 535.6107\n\nweighted.mean(jpn2012$PV1READ, jpn2012$W_FSTR2) # 2個目の標本作成\n\n[1] 540.2332\n\n\n上記の例ではW_FSTR1とW_FSTR2だけを計算してみましたが， Replication weightsを使った推定値を一つずつ計算していくのは明らかに手間です。 せっかくコンピュータを使っているので，計算を簡略化することを考えましょう。\nここで注目したいことは， PISAのReplication Weightsの変数名は W_FSTR1からW_FSTR80であるという点です。 最初のW_FSTRは共通していますから，これを利用します。 データフレームの取り扱いで触れたように， データフレームの変数にアクセスする方法は$を使う方法だけでなく， [[ ]]を使う方法もあります。 つまり，jpn2012$W_FSTR1とjpn2012[[\"W_FSTR1\"]]は同じ意味です。\nさらにRのpaste0関数を利用します。 paste0は引数とした文字を結合する関数で， paste0(\"W_FSTR\", 1)は\"W_FSTR1\"となります。\n以上の知識を使うと，次の3つは同じことになります。\n\nsummary(jpn2012$W_FSTR1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   53.7    86.8   133.3   176.0   262.1   664.8 \n\nsummary(jpn2012[[\"W_FSTR1\"]])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   53.7    86.8   133.3   176.0   262.1   664.8 \n\nsummary(jpn2012[[paste0(\"W_FSTR\", 1)]])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   53.7    86.8   133.3   176.0   262.1   664.8 \n\n\nさて，paste0(\"W_FSTR\", 1)は数値1を含んでいます。 ですから，iが1から80まで変わるとき， weighted.mean(jpn2012$PV1READ, jpn2012[[paste0(\"W_FSTR\", i)]]) の値がどう変わるか計算すれば， 80個のReplication weightsを使った推定値を一気に得ることができます。 この計算をsapplyを使って書くと，次のようになります。 計算結果は，rep_mというオブジェクトに保存しました。\n\nrep_m &lt;- sapply(1:80, function(i) {\n  weighted.mean(jpn2012$PV1READ, jpn2012[[paste0(\"W_FSTR\", i)]])\n})\nrep_m\n\n [1] 535.6107 540.2332 536.7174 537.9878 538.8330 539.0987 539.6143 538.8335\n [9] 536.2007 535.7566 536.4589 538.5516 539.7910 538.2296 538.8830 541.0062\n[17] 538.8288 541.0334 539.8467 538.1659 540.1042 536.1702 538.3406 538.8405\n[25] 538.3669 541.0299 537.2255 541.2987 534.4808 537.5720 541.3658 535.1992\n[33] 536.9183 540.1074 537.6273 536.8477 535.9422 540.0844 537.4468 539.0120\n[41] 542.1695 536.2355 539.2325 538.5105 540.1844 540.2069 537.5594 538.2596\n[49] 534.3702 534.5011 537.5606 537.9362 537.6198 539.8877 538.9771 536.9501\n[57] 536.9441 536.7234 535.3349 536.8783 540.1027 539.0737 539.7849 537.9357\n[65] 537.0259 536.7660 537.6697 537.3701 537.4929 538.3618 538.2748 538.0726\n[73] 542.6754 533.4231 538.8171 539.3094 537.5407 539.0051 540.1229 538.9998\n\n\nPISAで利用されているBRR法において， 標準誤差は以下の式で算出されます。\n\\[最終的な標準誤差 = \\sqrt{\\frac{1}{20}\\sum_{i=1}^{80}((\\hat{\\theta}_i - \\hat{\\theta}) ^ 2)}\\]\nここで\\(\\hat{\\theta}\\)は最終的な推定値， \\(\\hat{\\theta_i}\\)は\\(i\\)番目のReplication weightsを使った推定値です。 Rで次のように計算すれば，PV1READの平均値の標準誤差が得られます。\n\nc(Mean = fin_m, SE = sqrt(sum((rep_m - fin_m)^2) / 20))\n\n      Mean         SE \n538.116436   3.666172 \n\n\nちなみに，単純な無作為抽出を前提に PV1READの標準誤差を計算すると1.25になり， 本来の推定値（3.67）に比べ過小になります。\n\n# 単純な無作為抽出を前提に計算した標準誤差\nsd(jpn2012$PV1READ) / sqrt(nrow(jpn2012))\n\n[1] 1.25302\n\n\nPV1READの分散や分散の標準誤差も，ウェイトを使って計算します。 以下では，ウェイトを考慮した分散を計算するweighted.var関数を自作し， Replication Weightsと組み合わせて，PV1READの分散とその標準誤差を算出しています。\n\nweighted_var &lt;- function(x, w) {\n  sum(w * (x - weighted.mean(x, w))^2) / sum(w)\n}\n\nfin_s &lt;- sqrt(weighted_var(jpn2012$PV1READ, jpn2012$W_FSTUWT))\nrep_s &lt;- sapply(1:80, function(i) {\n  sqrt(weighted_var(jpn2012$PV1READ, jpn2012[[paste0(\"W_FSTR\", i)]]))\n})\n\nc(SD = fin_s, SE = sqrt(sum((rep_s - fin_s)^2) / 20))\n\n       SD        SE \n99.196401  2.294498 \n\n\nここまでの説明を聞くと非常に煩雑な操作だと思うでしょうが，実際に分析を行う際は intsvyという パッケージを使えば容易に計算できます。\n\n# intsvyを使った場合のPV1READの平均と分散の推定値（標準誤差を含む）\nintsvy::pisa.mean(\"PV1READ\", data = jpn2012)\n\n  Freq     Mean     s.e.      SD      s.e\n1 6351 538.1164 3.666172 99.1964 2.294498\n\n\n出力が，これまで計算してきた推定値と一致していることを確認してください。 intsvyについては，intsvyを使うで解説します。\n\n\n\n\n1. 伊達平和・高田聖治. (2020年). 社会調査法. 学術図書出版社.\n\n\n2. 袰岩晶・篠原真子・篠原康正. (2019年). PISA調査の解剖ー能力評価・調査のモデル. 東信堂.",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Replication Method</span>"
    ]
  },
  {
    "objectID": "replication.html#footnotes",
    "href": "replication.html#footnotes",
    "title": "9  Replication Method",
    "section": "",
    "text": "普通は学校数・生徒数ともに有限ですから， 標本ウェイトで説明したように， 学校・生徒の抽出確率を考慮して母平均（及び母分散）を推定する必要があります。↩︎\n詳しくは標本調査の入門書[1]を参考にしてください。 なお初学者向けの入門書では， 簡単のため無限母集団かつ復元抽出を前提に説明が行われていることもあります。↩︎\nRでこの作業を行うには，survey というパッケージが必要になります。↩︎\n実際はFayのBRRをさらに修正した手法が利用されています[2]が， 本書の範囲を超えるので省略します。↩︎",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Replication Method</span>"
    ]
  },
  {
    "objectID": "irt.html",
    "href": "irt.html",
    "title": "10  項目反応理論",
    "section": "",
    "text": "10.1 古典的テスト理論の課題\nPISAに限らず，現代のテストでは項目反応理論 （Item Response Theory: IRT）というテスト理論が使われています。 ここでは，その概要を説明しておきましょう。\n実のところ，一般的なLSAではIRTを利用したスコアは算出済みであり， 分析者がIRT分析を行う必要はありません。 とは言え，ある程度の知識がないと誤った解釈をする危険もあります。 そこで以下では，最低限知っておいたほうがよい点をポイントを絞って解説します。\nなお，本章では教育測定の流儀に倣い，以下の用語を使います。\nまた，この章ではIRT分析用のRパッケージ（Mirt・TAM）を利用します。 ColabにはMirt・TAMは含まれていませんので，下記のコマンドを実行するようにしてください。 これは，ColabでIRTを行うための「裏技」です。 コマンドの意味については，intsvyを使うで解説します。\n本書では，MIRTやTAMの細かい使い方は解説しません。 一般的なLSAでは受検者の能力値は算出済みであり，分析者がIRTを実行する必要はほとんどないからです。 関心のある方は，IRTの入門書を参照してください。\nなお本書でMIRTやTAMに含まれる関数を使う際は， TAM::tam.wleといった具合に関数の前にTAM::あるいはMIRT::を付け， どのパッケージに含まれる関数なのか明示しています。\nIRTの特徴は，古典的テスト理論（Clasical Test Theory: CTT）との対比で 説明されることが多いようです。 CTTに基づいたテストでは， 受検者がテスト項目に何問正解したか（≒正答率）を，受検者の能力と捉えます。 わかりにくい人は，いわゆる「100点満点のテスト」を想像すればよいでしょう。\nさて，CTTの課題は「受検者の能力とテストの難易度が分離できない」という点です。 「100点満点のテスト」を全国の小学6年生を対象に実施したとき， ある年度のテストの平均点が60点，次の年度が70点だったとしましょう。 このとき，受検者（＝小学6年生）の学力は向上したと考えてよいでしょうか？ 答えはNoです。受検者の能力が向上したのではなく， テストが簡単になっただけかもしれません。 もちろん，まったく同じテストを用意すればCTTでも能力の変化を 測ることはできます。 ただ普通は，まったく同じテストを出題していたらテスト対策が行われ， 受検者の能力が変わらなかったとしても，次第に正答率は向上していくでしょう。\nとくにメディアの発達した現代社会では， 一度出題したテストの項目を秘匿することはなかなか困難です。 そのためCTTでは， 受検者の能力やその変化を捉えることが難しく， それに代わるテスト理論が求められるようになってきたのです。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>項目反応理論</span>"
    ]
  },
  {
    "objectID": "irt.html#項目反応理論とは",
    "href": "irt.html#項目反応理論とは",
    "title": "10  項目反応理論",
    "section": "10.2 項目反応理論とは",
    "text": "10.2 項目反応理論とは\n先のCTTの課題（受検者の能力とテストの難易度が分離できない）を解決したテスト理論がIRTです。 IRTでは，受検者の能力（一般に\\(\\theta\\)で表現されます）と， 項目の難易度（一般に\\(b\\)で表現されます。要は個々の項目の難しさです）を別々に考えます。 この発想により，まったく異なる項目から構成されたテストであっても， その得点を比較できるようになります。\n簡単に説明すると，これは次のようなロジックです。 たとえば，ほぼ同じ「易しい」難易度の二つの項目があるとしたら， その項目は相互に入れ替え可能です。 同様に同じ難易度の項目同士を入れ替えていけば， まったく異なる項目から構成されているにもかかわらず，同じ難しさのテストが作成できます。 これで冒頭のような問い（小学6年生の学力は上がったのか？）にも答えられるようになります。\nただしIRTも万能ではありません。 ここでは，日本の学校教育にIRTを使ったテストが普及していく上での課題を3つ挙げておきます。\n第一に，IRTを活用するためには事前に難易度の判明した項目が多数用意されている必要があります。 項目がたくさん集められている（≒プールされている）ので， これを項目プールと呼んだりします。 項目プールがないと，同じ難易度のテストを構成するといった作業はできません。 項目プールを作るには，多数の設問を作成し，その難易度を調べる予備調査が必須です。 これには膨大な手間がかかります。\n第二に，IRTでは個々の項目は基本的に秘匿されていることが前提です。 仮に「難しい」とされている項目であっても，それが広く公開されてしまえばテスト対策が行われ， 「易しい」項目に変わってしまう危険があるからです。 大学入学共通テストのように， 日本ではテストをした直後に項目を公開することが広く行われていますが， IRTを前提にしたテストでは項目の公開は基本的にご法度です。\n第三に，IRTによる能力推定は相当に煩雑です。 本書ではごく簡単に説明しますが，IRTで受検者の能力を求めるには， 「項目の難易度などを推定する作業」と 「推定された項目の難易度をもとに受検者の能力を推定する作業」が必要です。 そして，それぞれの作業に複数の異なるモデルや推定法が提案されています。 どのモデル・推定法を採用するかによって，受検者の能力は変わってきます。 これは日本の人たちが慣れ親しんでいる「10問中5問正解したから50点」といった 点数の算出方法に比べ明らかに複雑で，理解するには専門的な知識が必要です。 適切な理解を欠いていると，せっかく学力調査にIRTを導入しても 誤った結論しか得られないということにもなりかねません。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>項目反応理論</span>"
    ]
  },
  {
    "objectID": "irt.html#項目反応理論のモデル",
    "href": "irt.html#項目反応理論のモデル",
    "title": "10  項目反応理論",
    "section": "10.3 項目反応理論のモデル",
    "text": "10.3 項目反応理論のモデル\nそれではIRTによる能力推定法の概要と， その留意点について簡単にまとめておくことにしましょう。 先ほど述べたように， 一般的なIRTによる能力推定では， 最初に困難度・識別力といった項目パラメータを推定します。 その上で，受検者の回答パターンをもとに受検者の能力を推定します。\n最初の項目パラメータの推定では， 項目への正答確率（\\(P\\)）と 受検者の能力（\\(\\theta\\)）・項目の難易度（\\(b\\)）などのあいだに 何らかの関係を仮定して，\\(b\\)などの値を推定していきます。 一例として，次のようなモデルを考えてみましょう。\n\\[P_j(\\theta) = \\frac{1}{1+exp(-Da_j(\\theta - b_j))}\\]\n式中の記号の意味は，次の通りです。\n\n\\(P_j\\)：項目\\(j\\)に対する正答確率（0は100%誤答，1は100%正答になります）\n\\(\\theta\\)：受検者の能力（0が平均で偏差値で言うと50に相当します。1は偏差値60です）\n\\(b\\)：項目困難度（項目の難しさです）\n\\(a\\)：項目識別力（説明は後述）\n\\(D\\)：尺度因子（通常1.7です。気にしなくて構いません）\n\nこの式では何のことかわからないと思いますので， 横軸に受検者の能力（\\(\\theta\\)），縦軸に正答確率（\\(P\\)）をとった グラフを描いてみましょう。 Rのコードはわかりにくいので，覚えなくて構いません。\n\n\nコード\nicc &lt;- function(params, tr = c(-4, 4), np = 100) {\n  # 引数チェック\n  if (!is.list(params) || !all(c(\"a\", \"b\") %in% names(params))) {\n    stop(\"`params` must be a list with named elements `a` and `b`.\")\n  }\n  if (length(params$a) != length(params$b)) {\n    stop(\"`params$a` and `params$b` must have the same length.\")\n  }\n\n  # 正答確率関数\n  p2pl &lt;- function(t, a, b) {\n    1 / (1 + exp(-1.7 * a * (t - b)))\n  }\n\n  # 能力範囲を生成\n  t_vals &lt;- seq(tr[1], tr[2], length.out = np)\n\n  # プロットの初期化\n  plot(NULL,\n    xlim = tr, ylim = c(0, 1), type = \"n\",\n    xlab = \"θ\", ylab = \"正答確率\",\n    main = \"ICC\"\n  )\n  grid()\n\n  # 各項目の特性曲線を描画\n  for (i in seq_along(params$a)) {\n    a &lt;- params$a[i]\n    b &lt;- params$b[i]\n    p_vals &lt;- p2pl(t_vals, a, b)\n    lines(t_vals, p_vals, lwd = 2, col = i) # 番号を色に対応\n    abline(v = b, col = i, lty = 2) # 困難度のライン\n  }\n\n  # 凡例を追加\n  legend(\"bottomright\",\n    legend = paste(\"a =\", params$a, \", b =\", params$b),\n    col = seq_along(params$a), lwd = 2, bg = \"white\"\n  )\n}\n\nparams1 &lt;- list(\n  a = c(0.7, 0.9, 0.5),\n  b = c(-1, 0, 1)\n)\n\nicc(params1)\n\n\n\n\n\n\n\n\n図 10.1\n\n\n\n\n\n図 10.1 は3つの項目（黒・赤・緑）を例に，受検者の能力と正答確率の関係を図示したものです。 いずれの項目も受検者の能力（\\(\\theta\\)）が高いほど（＝右へ行くほど）正答確率が上昇しており， \\(\\theta\\)が4ともなれば，どの項目もほぼ100%正答になることを示しています。 逆に\\(\\theta\\)が低いほど（＝左へ行くほど）正答確率は下がり， \\(\\theta\\)が-4の人はどの項目も正答確率はほぼ0%です。 図中の縦線は，正答確率がちょうど50%になるときの\\(\\theta\\)の値を示した線です。\nここで，\\(b\\)は困難度・\\(a\\)は識別力と呼ばれるパラメータです。 図 10.1 を見ると，\\(b\\)の高い項目ほど正答確率が50%になるために 必要な\\(\\theta\\)が高いことがわかると思います。 要は\\(b\\)が高いほうが「難しい」項目だということです。 \\(a\\)はわかりにくいかもしれませんが，\\(a\\)が高い項目ほど 曲線の立ち上がりが急激である（≒能力が上昇したときに正答確率が大きく上がる） ことに気づくと思います。\nたとえば，赤の曲線（\\(a\\)が0.9）は\\(\\theta\\)が-1のときは正答確率が20%程度ですが， \\(\\theta\\)が0で50%，\\(\\theta\\)が1で80%程度と，大きく正答確率が上昇しています。 他方，緑の曲線（\\(a\\)が0.5）は\\(\\theta\\)が-1のときの正答確率は20%程度で， \\(\\theta\\)が3になっても正答確率が80%程度と，正答確率の上昇が緩やかです。\n要は\\(a\\)が高い項目のほうが， 受検者の能力を区別することができる（≒識別できる）ということです。 \\(a\\)が極端に低い項目は，受検者の能力が高かろうが低かろうが正答確率が変わらないわけで， 受検者の能力を知るという観点からは，あまり出題する意味がない（≒「悪問」）ということになります。\nここまで見てきたような「個々の項目に困難度と識別力というパラメータがある」ことを想定するモデルは， 2PL（2パラメータ・ロジスティックモデル）と呼ばれます。 他にも識別力を考えない1PLや，偶然に正解する確率を考慮する3PLなど， いくつかのモデルが存在します。 さらに今回のモデルは，正答と誤答しか考えていませんが， 部分正答を考える部分得点モデル（Partial Credit Model: PCM）というモデルも存在します。 IRTを利用したテストでは，こうしたモデルからいずれかを設定し（あるいは複数を採用し）， \\(b\\)や\\(a\\)などのパラメータを推定していくことになります。\nパラメータが推定されたら，次は受検者の回答をもとに能力推定を行います。 ここでも複数の能力推定法があり，それぞれ異なる特性を持ちます。 有名な推定法には，MLE（最尤推定）やEAP（期待事後確率）があります。 PISAでは，WLE（重み付け最尤推定）という推定法も使われています。 これら能力推定法を大雑把に分類すると， 受験者の能力分布について仮定を置かないもの（MLEやWLE）と 正規分布などの仮定を置くもの（EAP）に分けられます。 個々の推定法の説明は，かなり難しいので本書では扱いません。 興味のある方は，参考文献[1–3]で勉強してみてください。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>項目反応理論</span>"
    ]
  },
  {
    "objectID": "irt.html#重複テスト分冊法",
    "href": "irt.html#重複テスト分冊法",
    "title": "10  項目反応理論",
    "section": "10.4 重複テスト分冊法",
    "text": "10.4 重複テスト分冊法\nIRTの利点は，受検者が異なるテストを受検しても能力推定が可能であるという点でした。 LSAでは，こうしたIRTの利点を活かした手法が採用されています。 ここではその代表例として，重複テスト分冊法（Matrix Sampling Design）を紹介します。\n\n\n\n表 10.1: 重複テスト分冊法の例\n\n\n\n\n\n\n\n\n\n\n\n\n\n分冊 ID\nBlock 1（10項目）\nBlock 2（10項目）\nBlock 3（10項目）\nBlock 4（10項目）\nBlock 5（10項目）\n\n\n\n\n分冊 1\n○\n○\n✗\n✗\n✗\n\n\n分冊 2\n✗\n○\n○\n✗\n✗\n\n\n分冊 3\n✗\n✗\n○\n○\n✗\n\n\n分冊 4\n✗\n✗\n✗\n○\n○\n\n\n分冊 5\n○\n✗\n✗\n✗\n○\n\n\n\n\n\n\nLSAで受検者の能力を適切に測定するには，できるだけ多くの項目を出題する必要があります。 項目数が少ないと幅広く学力を調べることができず，たまたま得意な問題だった（あるいは苦手な問題だった） という事態が起こりえます。 こうなると，せっかく全国の子どもを調査する意味が薄れます。 その一方，出題する項目数が増えると，今度は受検者の負担が大きくなります。 そこで，幅広い項目を出題しつつ受検者の負担は減らすために， LSAでは項目をいくつかの分冊（分冊）に分けて， 個々の受検者に異なる設問を出題するという手法が取られています。 これを重複テスト分冊法と呼びます。\n表 10.1が，その概要です。 Block 1からBlock 5は，項目のグループだと思ってください。 仮に1つのBlockで10項目を出題したとすると，全体で見れば50項目が出題できるというわけです。 もちろんBlockの数を増やせば，さらに多くの項目を出題できます。 ただ，そのままだとBlock 1とBlock 2を受検した受検者の能力を比べることはできません。 Block 1の項目とBlock 2の項目が同じ難しさかどうかわからないからです。 事前に個々のBlockの難易度を完全に同じに保つことができればよいのですが， 項目数が少ないこともあってなかなかに困難です。\nそこで表 10.1のように， Block 1とBlock 2を分冊1，Block 2とBlock 3を分冊2・・・といった具合に， 個々のBlockを対にして分冊を作成します。 そして，この分冊を個々の受検者に配布します。 こうすると分冊1と分冊2を受検した受検者たちは，いずれもBlock 2の項目に回答していますから， Block 2の項目への回答状況を手がかりに， 相互に比較可能な形でBlock 1・Block 2・Block 3の項目の難易度を推定することができます。 Block 1・Block 2・Block 3の項目の難易度がわかれば， 分冊1と分冊3を受検した受検者の能力を比べることもできるというわけです。\n分冊1と分冊3の受検者は重複していませんが， 分冊1と分冊2，分冊2と分冊3にはそれぞれ重複（Block 2とBlock 3）がありますので， まずBlock 1とBlock 2の難易度を比べ，それからBlock 2とBlock 3，Block 3とBlock 4の難易度を比べることで， 相互に比較可能なBlock 1からBlock 4までの難易度を推定することができます。 こうなれば，分冊1と分冊3を受検した受検者の能力を比較することが可能です。\n重複テスト分冊法を利用すれば，幅広い項目を出題しつつ，受検者の負担を抑えることが可能です。 先の例で言うと，個々の受検者は20問しか受検していませんので，個々人の能力推定は正確なものにはなりません （＝測定誤差が大きくなる）。 ただ全体としてみれば100問が出題できていますので，その国（あるいは地域）の子どもの得意・不得意はよくわかります。\nちなみに，近年のLSAではCBTが導入されるようになってきています。 CBTの利点はいくつかありますが，その一つに受検者の能力をより正確に測定できるというものがあります。 紙のテストでは，どうしてもテストが受検者にとって簡単すぎる／難しすぎるということが起こります。 そこで最初に標準的な設問で構成されたBlockを出題しておき， その反応をもとに能力の高い受検者には難しいBlockを，逆に低い受検者には簡単なBlockを割り当てることで， より正確に受検者の能力を知ることができるようにしているのです。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>項目反応理論</span>"
    ]
  },
  {
    "objectID": "irt.html#異なるサイクル間での能力比較",
    "href": "irt.html#異なるサイクル間での能力比較",
    "title": "10  項目反応理論",
    "section": "10.5 異なるサイクル間での能力比較",
    "text": "10.5 異なるサイクル間での能力比較\n多くのLSAでは，異なる年度で実施されたテストであっても，その得点を直接に比較し， 学力が上がった／下がったという判断を下すことができます。 ここにもIRTの技術が使われています。\n\n\n\n表 10.2: 異なるサイクル間の比較\n\n\n\n\n\nYear\nblock A\nblock B\nblock C\nblock D\n\n\n\n\n2010年調査\n○\n○\n✗\n✗\n\n\n2015年調査\n✗\n○\n○\n✗\n\n\n2020年調査\n✗\n✗\n○\n○\n\n\n\n\n\n\n能力の変化を捉えるための調査デザインは，基本的には重複テスト分冊法の発想と同じです。 たとえば5年おきに実施されるLSAがあったとしましょう。 ここでテスト項目のBlock（A〜D）を表 10.2のように配置すれば， 2010年・2015年・2020年の調査の成績を直接に比較できるようになります。 たとえば2010年調査と2015年調査の比較であれば， 両者に共通するBlock Bの項目の難易度を手がかりに， Block Aの項目とBlock Cの項目の難易度を比べることができ， 2010年度調査の受検者と2015年度調査の受検者の能力も比べることができるようになるというわけです。\nここで重要なことは，Block BやBlock Cのような共通の項目の情報が，受検者に秘匿されていることです。 仮に2010年調査でBlock Bの項目の内容が漏洩してしまったとすると， 2010年調査の受検者にとってのBlock Bの難易度と，2015年調査の受検者にとってBlock Bの難易度が変わってしまいます （おそらく，2015年調査の受検者は2010年調査の受検者に比べ，Block Bを易しく感じるでしょう）。 この場合，2010年調査と2015年調査の得点を調整する作業は失敗します。 PISAやTIMSSでは，調査項目の一部が公開されていますが， これはBlock Aのような今後の調査ではもう使わない項目が対象になっているのです。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>項目反応理論</span>"
    ]
  },
  {
    "objectID": "irt.html#rによる推定",
    "href": "irt.html#rによる推定",
    "title": "10  項目反応理論",
    "section": "10.6 Rによる推定",
    "text": "10.6 Rによる推定\n最後に，Rを利用してIRTを行う例を紹介しておきます。 素のRでIRTを行うのは難しいので， mirtとTAMというパッケージ1を利用しました。 IRTの分析は難しいので，以下のコードは理解できなくても構いません。 ここでは，受検者のサンプルサイズが4000，項目数は20問のテストを想定しています。 IRTのモデルは2PL，項目の困難度は-3から3のあいだで均等に分布し， 項目の識別力は0.9としました。\n最初に，受検者の反応パターン（20項目に対する正誤）のデータを生成します。 データの生成は，mirtのsimdata関数を使っています。\n\n# パラメータの定義\nset.seed(123)\nsize &lt;- 4000 # サンプルサイズ\nitem_n &lt;- 20 # 項目数\n\nb &lt;- seq(-3, 3, length.out = item_n) # 項目困難度\na &lt;- 0.9 # 項目識別度\n\n# theta\ntheta &lt;- rnorm(size, 0, 1)\n\n# 反応パターンを生成\nresp &lt;- mirt::simdata(\n  a = rep(1.7 * a, item_n),\n  d = -b * 1.7,\n  Theta = theta,\n  itemtype = \"2PL\"\n)\n\n続いて，2PLによる分析を行います。 ここでは，TAMのtam.mml.2pl関数による推定を行っています。 引数のverbose = FALSEは出力を抑制する設定です。\n\nmod &lt;- TAM::tam.mml.2pl(resp, verbose = FALSE)\n\nTAMで困難度と識別力を出力するのはやや面倒で， 以下のような手順を踏む必要があります。 Colabだと出力が見づらいので，as.data.frameという関数を使い， 出力をデータフレームに変換しています。\n\n# 識別力\na_param &lt;- mod$B[, 2, 1] / 1.7\nas.data.frame(round(a_param, 2))\n\n        round(a_param, 2)\nItem_1               0.88\nItem_2               0.84\nItem_3               0.95\nItem_4               0.92\nItem_5               0.82\nItem_6               0.96\nItem_7               0.95\nItem_8               0.91\nItem_9               0.95\nItem_10              0.90\nItem_11              0.88\nItem_12              0.82\nItem_13              0.90\nItem_14              0.93\nItem_15              0.85\nItem_16              0.93\nItem_17              0.84\nItem_18              0.83\nItem_19              0.95\nItem_20              0.96\n\n# 困難度\nb_param &lt;- mod$xsi[, 1] / mod$B[, 2, 1]\nas.data.frame(round(b_param, 1))\n\n        round(b_param, 1)\nItem_1               -3.3\nItem_2               -3.1\nItem_3               -2.6\nItem_4               -2.3\nItem_5               -2.1\nItem_6               -1.5\nItem_7               -1.2\nItem_8               -0.9\nItem_9               -0.5\nItem_10              -0.2\nItem_11               0.2\nItem_12               0.6\nItem_13               0.9\nItem_14               1.2\nItem_15               1.6\nItem_16               1.9\nItem_17               2.3\nItem_18               2.8\nItem_19               2.9\nItem_20               3.2\n\n\n続いて，受検者の能力推定を行います。 ここでは，EAP・MLE・WLEによる推定方法を示しています。\n\neap &lt;- mod$person$EAP #EAP\nmle &lt;- TAM::tam.wle(mod, progress = FALSE, WLE = FALSE)$theta # MLE\nwle &lt;- TAM::tam.wle(mod, progress = FALSE)$theta #WLE\n\n得られた能力値を，真の能力値と比べてみましょう。 ここではMLEを例に， 真の能力（\\(\\theta\\)）と推定された能力をplotで散布図にしてみましょう。 ついでに，cor関数で相関係数も算出します。\n\nplot(theta, mle, xlab = \"真の能力\", ylab = \"MLE推定値\")\n\n\n\n\n\n\n\ncor(theta, mle)\n\n[1] 0.8976524\n\n\n散布図や相関係数を見ると，確かに関連は強いのですが， それでも完全に一致するわけではないことがわかります。 もっとも直感的にはこれは当然で， たった20問のテストですから 1〜2問程度はたまたまできた（あるいは間違えた）項目が存在し， 結果として真の能力と推定された学力に差が生じるということです。\nただ，このズレが母集団を推定するときには問題になります。 今，MLE，WLE，EAPの各推定値を使い，母集団の平均と分散を計算してみましょう。\n\nstat &lt;- function(x) round(c(mean = mean(x), var = var(x)), 2)\n\nlapply(list(theta = theta, mle = mle, wle = wle, eap = eap), stat)\n\n$theta\nmean  var \n0.01 0.99 \n\n$mle\nmean  var \n0.00 1.26 \n\n$wle\nmean  var \n0.00 1.23 \n\n$eap\nmean  var \n0.00 0.81 \n\n\n平均値（mean）はどの推定法も0.0なので，真の値（0.01）とほとんど同じです。 問題は分散（var）で，真の値（theta）が0.99に対し， いずれの推定法にもズレが生じています。 傾向として，MLEとWLEは過大推定，EAPは過小推定しているようです 分散の推定値がズレるということは，標準誤差にズレが生じます。 そして標準誤差がズレると，母集団に対する誤った推測に゙繋がります。 推算値法では，この問題を改善する方法を解説します。\n\n\n\n\n1. 光永悠彦. (2017年). テストは何を測るのか—項目反応理論の考え方. ナカニシヤ出版.\n\n\n2. 加藤健太郎・山田剛史・川端一光. (2014年). Rによる項目反応理論. オーム社.\n\n\n3. 袰岩晶・篠原真子・篠原康正. (2019年). PISA調査の解剖ー能力評価・調査のモデル. 東信堂.",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>項目反応理論</span>"
    ]
  },
  {
    "objectID": "irt.html#footnotes",
    "href": "irt.html#footnotes",
    "title": "10  項目反応理論",
    "section": "",
    "text": "分析のために作成した関数をまとめたものです。 世界中のRユーザによって開発されたパッケージがインターネット上に公開されており， その中から必要なものを選んで使うことができます。↩︎",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>項目反応理論</span>"
    ]
  },
  {
    "objectID": "pvs.html",
    "href": "pvs.html",
    "title": "11  推算値法",
    "section": "",
    "text": "11.1 MLEやEAPの課題\n前の章で見たように， IRTの能力推定法としてよく利用されるMLEやEAPには， 母集団の能力推定に利用すると推定値が偏るという欠点があります。 なぜ偏りが生じるか，簡単に説明しておきましょう。\n無限に項目を用意できれば別ですが，普通はテストに出題できる項目数には限りがあります。 そのためテストの結果から推定された能力値には，必ず受検者の真の能力値（\\(\\theta\\)）とのズレ（＝測定誤差）があります。 MLEやWLEによって推定された個人の能力値\\(\\hat{\\theta}_i\\)は， 真の能力値\\(\\theta_i\\)に測定誤差\\(\\epsilon_i\\)を加えたもの （\\(\\hat{\\theta}_i = \\theta_i + \\epsilon_i\\)）になっていると考えられます1。 このとき，母集団における能力の分散は， 個々人の能力の分散に測定誤差の分散を加えたものとして推定されます。 つまり，\\(Var(\\hat{\\theta}_i) = Var(\\theta_i) + Var(\\epsilon_i)\\)なので， MLEやWLEで推定された能力値の分散は，実際の分散より大きくなってしまうのです。\nEAPはどうかというと， 前の章で少し触れたように，EAPは受検者の能力分布に正規分布などの分布を仮定します。 事前に能力分布を仮定しているので分散が過大推定されることはないのですが， 今度は事前に想定した分布に推定された能力値が引き寄せられます。 一般的には，測定誤差が大きいほどEAPは母集団の分散を過小推定するそうです[1]。\n以上のような現象は測定誤差の問題なので，項目数を増やしていけば， いずれの推定法も同じような推定値に近づいていきます。 先行研究によると，だいたい180項目ほど出題すれば，MLE・WLE・EAPの差は無視できるそうです[1]。 ただ180項目というのは相当な量で，あまり現実的ではありません。\n要するに，MLEやEAP（あるいはWLE）といった能力推定法では， 母集団の特性を適切に推定することは難しいということです。 ここで登場する手法が，推算値（Plausible Values: PVs）です。\nPVsは，あらかじめ受検者の能力値に正規分布などの分布を仮定します。 その意味では，EAPとよく似た手法と言えます。 PVsとEAPの違いは， EAPが唯一の受検者の能力を推定するのに対し， PVsは推定された受検者の能力分布から無作為に受検者の「あり得る能力」を抽出するという点です。 PISAやTIMSSでは，個々人の受検者に対して5個（PISAは2015以降は10個）の能力値が推定されています。\n欠測値の処理に詳しい方の中には，多重代入法（Multiple Imputation: MI）[2]という手法をご存じの方もいるでしょう。 MIは，データに含まれる欠測に伴う推定の偏りを補正するため， 欠測データの分布から無作為に複数の値を取り出し欠測値を置き換えるという手法です。 ここで重複テスト分冊法を思い出してほしいのですが， LSAでは受検者は出題された一部の項目にしか答えていません。 つまり全体としてみれば，個々の受検者の回答データは多数の欠測を含んだ不完全なものになっています。 ここで受検者の能力\\(\\theta\\)を推定しようという試みは， 多数の欠測を含んだデータから適切な推定値を得ようとする試みと同義です。 受検者の能力分布から複数の「あり得る能力」を抽出するというPVsの考え方は， 欠測データを処理するためのMIの枠組みを教育測定に応用したものなのです。\nなお，PVsが有効なのは重複テスト分冊法のように，受検者のデータが多数の欠測を含む場合に限りません。 テストの項目数が少ない場合や，テストの難易度が受検者の能力値に対して低すぎる（あるいは高すぎる） ような場合であっても，PVsを使うことで母集団の特性を適切に推定できることが明らかになっています[3]。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>推算値法</span>"
    ]
  },
  {
    "objectID": "pvs.html#rによる確認",
    "href": "pvs.html#rによる確認",
    "title": "11  推算値法",
    "section": "11.2 Rによる確認",
    "text": "11.2 Rによる確認\n実際にPVsが有効かどうか，シミュレーションで確認してみましょう。 最初に仮の受検者の回答データとして，respを作成します。 母集団における能力値の分布は，実際の学力調査を意識して，以下のような複雑な状況を設定します。 まず，受検者のサンプルサイズは4000とし，うち男子2000名・女子2000名とします。 さらに能力値の平均と分散は男女で違い， 男子は平均-0.2・分散1に対し，女子は平均0.2・分散1になっています。 また能力値以外にSESという変数があると仮定し， 能力値とSESの相関係数は，男子0.5，女子0.4としています。 状況設定が複雑なので，コードは閉じています。\nなお，コード実行のためにはMIRTやTAMが必要です。 インストールしていない場合は，項目反応理論の章を参考に設定を済ませてください。\n\n\nコード\nset.seed(123)\n\n# sample size\nsize &lt;- 4000\n# Item parameters\nitem_n &lt;- 20\nb &lt;- seq(-3, 3, length.out = item_n)\na &lt;- 0.9\n# Population parameters\nsig1 &lt;- matrix(c(1.0, 0.4, 0.4, 1.0), nrow = 2)\nsig2 &lt;- matrix(c(1.0, 0.5, 0.5, 1.0), nrow = 2)\nsex &lt;- c(rep(1, size / 2), rep(-1, size / 2))\nsim1 &lt;- mvtnorm::rmvnorm(n = size / 2, mean = c(0.2, 0), sigma = sig1)\nsim2 &lt;- mvtnorm::rmvnorm(n = size / 2, mean = c(-.2, 0), sigma = sig2)\nsim &lt;- rbind(sim1, sim2)\ntheta &lt;- sim[, 1]\nses &lt;- sim[, 2]\n\n# resp pattern\nresp &lt;- mirt::simdata(\n  a = rep(1.7 * a, item_n),\n  d = -b * 1.7 * a,\n  Theta = theta,\n  itemtype = \"2PL\"\n)\n\n\nそれでは生成したrespに対して，TAMで能力値を推定してみましょう。 Rのコードは，次のようになります。 なお，通常はPVsは複数の値を生成するのですが， 処理が重くなるのでここでは1つの値だけを生成（nplausible = 1）しています。\n\n# estimation\nmod &lt;- TAM::tam.mml.2pl(resp, verbose = FALSE)\n\n# ability estimation\nmle &lt;- TAM::tam.wle(mod, progress = FALSE)$theta\neap &lt;- mod$person$EAP\npv &lt;- TAM::tam.pv(mod, nplausible = 1, verbose = FALSE)$pv$PV1.Dim1\n\n# 能力推定\nability &lt;- list(\n  \"theta\" = theta,\n  \"MLE\" = mle,\n  \"EAP\" = eap,\n  \"PV\" = pv\n)\n\n続いて，TAMを使って推定した能力値が， 適切に母集団の値を復元しているかどうか検討してみましょう。 最初に，母集団の平均と分散を見てみます。 なお以下の出力では， thetaが真の値，MLE・EAP・PVはそれぞれの推定法による推定値を示します。\n\n# 平均値\nround(sapply(ability, mean), 2)\n\ntheta   MLE   EAP    PV \n 0.01  0.00  0.00  0.01 \n\n# 分散\nround(sapply(ability, var), 2)\n\ntheta   MLE   EAP    PV \n 1.01  1.21  0.82  0.96 \n\n\n先の章と同じく，MLEやEAPの推定値は，平均は適切に推定していますが， 分散を過大推定しています。 これに対してPVの推定値は，やや過小推定（0.96）ではあるものの， MLEやEAPに比べればthetaに近い分散を推定しています。\n続いて，男女別の平均と分散，そして能力値とSESの相関を検討してみましょう。\n\n# 男女別のスコア，SESとの相関を計算する関数\ncalc_stats &lt;- function(ability, stat) {\n  if (identical(stat, cor)) {\n    sapply(ability, function(x) {\n      cor(x, ses)\n    })\n  } else {\n    sapply(ability, function(x) {\n      tapply(x, sex, stat)\n    })\n  }\n}\n\nround(calc_stats(ability, mean), 2)\n\n   theta   MLE   EAP    PV\n-1 -0.20 -0.21 -0.17 -0.16\n1   0.21  0.21  0.17  0.17\n\nround(calc_stats(ability, var), 2)\n\n   theta  MLE  EAP   PV\n-1  0.97 1.16 0.79 0.93\n1   0.96 1.18 0.80 0.93\n\nround(calc_stats(ability, cor), 2)\n\ntheta   MLE   EAP    PV \n 0.42  0.38  0.38  0.34 \n\n\n男女別の能力値の平均を見てみると，MLEはthetaとほぼ同じ（男子-0.21・女子0.21）値になっています。 他方，EAPとPVはいずれもthetaと値がズレています。\n分散の推定値については，母集団の推定と同じく， MLEは過大推定，EAPは過小推定の傾向が見られます。 PVsは0.93とやや過小推定ですが，それでも比較的thetaに近い値が得られています。\n相関係数については，thetaの値が0.42に対し， MLEとEAPは0.38でやや過小推定になっています。 PVsは0.34で更に過小推定であり，母集団の特性を適切に推定しているとは言えません。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>推算値法</span>"
    ]
  },
  {
    "objectID": "pvs.html#推算値の条件付",
    "href": "pvs.html#推算値の条件付",
    "title": "11  推算値法",
    "section": "11.3 推算値の条件付",
    "text": "11.3 推算値の条件付\n先ほどのシミュレーションから言えることは， PVsは母集団の特性を適切に推定するわけではないということです。 分散はわずかに過小推定するにとどまっていますが， 男女の平均や相関係数の偏りなど，MLEやEAPと比べてPVsが優れているとは言えません。\nそれではなぜLSAではPVsが有効だと言われるのでしょうか。 実は先ほどのシミュレーションで推定したPVsが偏った推定値を返したのは， 母集団の能力値の分布について誤った仮定をおいていたからです。 すでに述べたように，EAPやPVsでは事前に母集団の能力分布について， 正規分布などの仮定を起きます。 しかし先のシミュレーションのように，男女で能力値の平均が異なるといった状況はありえます。 この場合，母集団の能力分布は，異なる2つの正規分布が重なった分布になっており， 単純な正規分布とは異なる形状になっています。\nLSAでPVsを利用する場合，性別やSESのような母集団の能力分布に影響を与えるであろう要因を 事前に考慮して能力分布を設定し，項目パラメータや能力値の推定を行わなければなりません。 こうした母集団の要因を考慮することを，一般に「条件づけ（Conditioning）」と呼びます。 なお，LSAのようにサンプルサイズが大きいデータに対して，条件付けを行った推定を行うと， 長い時間がかかったり，推定がうまくいかない場合があります。 そこで一般的なLSAでは，いったん条件付けを行わずに項目パラメータを推定し， そこで得られた推定値を利用しつつ条件付けを行った能力推定を行うという 2段階の推定法が採用されています[4]。 2段階の推定は，RのTAMパッケージに実装されており，tam.latreg関数を使うことで実行可能です。\n以下では，条件付けを行って推定したPVs（PV2とします）を使い， 母集団の推定を行ってみましょう。 最初に，母集団の平均と分散を確認します。\n\nlikeli &lt;- CDM::IRT.likelihood(mod)\nmod2 &lt;- TAM::tam.latreg(likeli, Y = cbind(sex, ses), verbose = FALSE)\n# 後で使うのでPVを5つ生成し，そのうち1つだけを利用\npvs &lt;- TAM::tam.pv(mod2, nplausible = 5, verbose = FALSE)\npv2 &lt;- pvs$pv$PV1.Dim1\n\nability2 &lt;- c(ability, list(\"PV2\" = pv2))\n\n# 平均値\nround(sapply(ability2, mean), 2)\n\ntheta   MLE   EAP    PV   PV2 \n 0.01  0.00  0.00  0.01  0.00 \n\n# 分散\nround(sapply(ability2, var), 2)\n\ntheta   MLE   EAP    PV   PV2 \n 1.01  1.21  0.82  0.96  1.02 \n\n\n母集団の平均・分散ともに，PV2がthetaに非常に近い値を返していることがわかります。 同様に，男女別の平均と分散，SESとの相関係数も検討してみましょう。\n\nround(calc_stats(ability2, mean), 2)\n\n   theta   MLE   EAP    PV   PV2\n-1 -0.20 -0.21 -0.17 -0.16 -0.21\n1   0.21  0.21  0.17  0.17  0.20\n\nround(calc_stats(ability2, var), 2)\n\n   theta  MLE  EAP   PV  PV2\n-1  0.97 1.16 0.79 0.93 0.98\n1   0.96 1.18 0.80 0.93 0.97\n\nround(calc_stats(ability2, cor), 2)\n\ntheta   MLE   EAP    PV   PV2 \n 0.42  0.38  0.38  0.34  0.41 \n\n\nいずれの値も，PV2がもっともthetaと近い値を返しています。",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>推算値法</span>"
    ]
  },
  {
    "objectID": "pvs.html#推算値の使い方",
    "href": "pvs.html#推算値の使い方",
    "title": "11  推算値法",
    "section": "11.4 推算値の使い方",
    "text": "11.4 推算値の使い方\nここまでの分析では，簡単のためにPVsは1つだけを生成していました。 シミュレーションの結果からもわかるように，条件づけたPVsは1つの値しか生成しなくても 母集団の推定には有効です。 ただ，より正確な推定のためには複数の値を生成し，それぞれで得られた推定値を合成する必要があります。\nPVsを使った推定値を合成する際は，Rubinのルールと呼ばれる方法を使います。 今，PVsの数を\\(M\\)，\\(i\\)番目のPVを使った推定値を\\(\\theta_i\\)，\\(i\\)番目のPVを使った推定値の分散を\\(V_i\\)とすると， PVsを使った推定値（\\(\\theta\\)），及びその分散（\\(V\\)）は，以下の式になります。\n\\[\\theta = \\frac{1}{M}\\sum_{i=1}^M{\\theta_i}\\]\n\\[V = U + (1 + \\frac{1}{M})B_m\\] \\[U = \\frac{1}{M}\\sum_{i=1}^M{V_i} \\qquad B_m = \\frac{1}{M-1}\\sum_{i=1}^M(\\theta_i - \\theta) ^ 2\\]\nこれでは何のことかわからないと思いますが， まず最終的な推定値（\\(\\theta\\)）は，単純に個々のPVで得られた推定値（\\(\\theta_i\\)）の平均です。 推定値の分散（つまり標準誤差の2乗）は，個々のPVで得られた推定値の分散（\\(V_i\\)）の平均（これが\\(U\\)です）に， \\((1+\\frac{1}{M})B_m\\)を足したものになります。 \\(B_m\\)は個々のPVごとの推定値のばらつきを示し， PVが受検者の能力分布から得られたランダムな値であることによる推定値のブレを考慮しています。\nPISA2012を例に，Rubinのルールを使った推定の例を見ておきましょう。 ここでは読解リテラシー（PV1READからPV5READ）の平均値を考えます。\n\nurl &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012stuJPN.csv\"\njpn2012 &lt;- read.csv(url)\n\npv1 &lt;- intsvy::pisa.mean(\"PV1READ\", data = jpn2012)\npv2 &lt;- intsvy::pisa.mean(\"PV2READ\", data = jpn2012)\npv3 &lt;- intsvy::pisa.mean(\"PV3READ\", data = jpn2012)\npv4 &lt;- intsvy::pisa.mean(\"PV4READ\", data = jpn2012)\npv5 &lt;- intsvy::pisa.mean(\"PV5READ\", data = jpn2012)\n\nest &lt;- c(pv1$Mean, pv2$Mean, pv3$Mean, pv4$Mean, pv5$Mean)\n# s.e.なので注意。s.eは分散の標準誤差\nse &lt;- c(pv1$s.e., pv2$s.e., pv3$s.e., pv4$s.e., pv5$s.e.)\n\nround(est, 3) # 5つの推定値\n\n[1] 538.116 537.872 538.473 538.064 537.732\n\nround(se^2, 3) # 推定値の分散\n\n[1] 13.441 13.372 13.082 13.344 13.742\n\n\n5つのPVの推定値は，estおよびseに格納されています。 これを使って最終的な推定値を計算します。 なお，結果の解釈に必要なのは推定値の分散ではなく標準誤差の方ですので， 最後にvの平方根を取って標準誤差を算出しています。\n\nf_est &lt;- mean(est)\nu &lt;- mean(se^2)\nb &lt;- var(se^2)\nv &lt;- u + (1 + 1 / 5) * b\nround(c(mean = f_est, var = v), 2)\n\n  mean    var \n538.05  13.46 \n\nround(c(mean = f_est, se = sqrt(v)), 2)\n\n  mean     se \n538.05   3.67 \n\n\n得られた推定値（平均538.05，標準誤差3.67）が， PISAの報告書にも記載されている適切な推定値です。 ここでは平均値を例に紹介しましたが，分散や回帰分析の係数など， 他の推定値であっても同じようにRubinのルールを適用して推定値を得ることができます 2。\nさて，こうして得られた最終的な推定値（日本のPISA2012の読解リテラシーの平均値）を PV1READから得られた値と比べてみると，実はほとんど違いがありません。 PVを5回も計算するのが面倒だという場合は， とりあえずPV1のみを使って分析を行っても，深刻な解釈ミスにつながることはないと考えられます3。\n\npv1 # 最終的な推定値とあまり変わらない\n\n  Freq     Mean     s.e.      SD      s.e\n1 6351 538.1164 3.666172 99.1964 2.294498\n\n\n5回もPVを計算するのは面倒だという人も多いでしょうが， 実際は，intsvyを使うことでPVの処理も自動化できます。 intsvyを使った自動化については，後の章で扱います。\n\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:5, \"READ\"), data = jpn2012)\n\n  Freq   Mean s.e.    SD  s.e\n1 6351 538.05 3.67 98.69 2.27\n\n\nなお，PVsを使うときに複数のPVを個人レベルで平均してはいけません。 PVsを個人レベルで平均すると，その値はEAPに近いものになります。 以下では，生成した5つのPVsをを個人レベルで平均したもの（PV3）を使った例を示します。 推定結果を見ると，PV3はEAPと同じように母集団の分散を過小推定していることがわかります4。\n\n# 5つのPVsをlistに変換\npvs_list &lt;- TAM::tampv2datalist(pvs)\n# 5つのPVsを個人レベルで平均\npv3 &lt;- Reduce(\"+\", lapply(1:5, function(i) pvs_list[[i]]$PV.Dim1)) / 5\nability3 &lt;- c(ability2, list(\"PV3\" = pv3))\n\n# 平均値\nround(sapply(ability3, mean), 2)\n\ntheta   MLE   EAP    PV   PV2   PV3 \n 0.01  0.00  0.00  0.01  0.00  0.00 \n\n# 分散\nround(sapply(ability3, var), 2)\n\ntheta   MLE   EAP    PV   PV2   PV3 \n 1.01  1.21  0.82  0.96  1.02  0.86 \n\n# 男女別の平均値\nround(calc_stats(ability3, mean), 2)\n\n   theta   MLE   EAP    PV   PV2   PV3\n-1 -0.20 -0.21 -0.17 -0.16 -0.21 -0.21\n1   0.21  0.21  0.17  0.17  0.20  0.20\n\n# 男女別の分散\nround(calc_stats(ability3, var), 2)\n\n   theta  MLE  EAP   PV  PV2  PV3\n-1  0.97 1.16 0.79 0.93 0.98 0.82\n1   0.96 1.18 0.80 0.93 0.97 0.82\n\n# SESとの相関係数\nround(calc_stats(ability3, cor), 2)\n\ntheta   MLE   EAP    PV   PV2   PV3 \n 0.42  0.38  0.38  0.34  0.41  0.44 \n\n\n\n\n\n\n1. 袰岩晶・篠原真子・篠原康正. (2019年). PISA調査の解剖ー能力評価・調査のモデル. 東信堂.\n\n\n2. 高橋将宜・渡辺美智子. (2017年). 欠測データ処理. 共立出版.\n\n\n3. Wu, M. (2005年). The role of plausible values in large-scale surveys. Studies in educational Evaluation, 31(2-3), 114–128.\n\n\n4. Zheng, X. (2024年). On generating plausible values for multilevel modelling with large-scale-assessment data. British Journal of Mathematical and Statistical Psychology, 77(1), 212–236.",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>推算値法</span>"
    ]
  },
  {
    "objectID": "pvs.html#footnotes",
    "href": "pvs.html#footnotes",
    "title": "11  推算値法",
    "section": "",
    "text": "推定された能力値なので\\(\\theta\\)ではなく，\\(\\hat{\\theta}\\)としています。↩︎\nRubinのルールには，推定値の分布が正規分布であるという前提があるため， たとえば相関係数には適用できません[2]。 ただLSAの場合はサンプルサイズが大きいこともあって，相関係数（を含むその他の分析）についても Rubinのルールを適用することが一般的です。↩︎\nLSAの分析はReplication MethodとPVsを使うので，それなりに時間がかかります。 たとえばPISAの場合，Replication Methodだけで80回の計算が必要です。 個々のPVについて80回の計算を行うとなると，PVが5つの場合は全部で400回の計算になります。 PISA2015以降はPVが10個になっているので，最終的な推定値を得るまでに800回以上の計算が必要となるのです。 PVを1つだけ使えば，計算回数を大きく抑えることができます。↩︎\n通常，LSAのデータセットに含まれるPVsは条件付けを行った能力分布から抽出されていますので， その個人レベルの平均は，通常のEAPではなく条件づけたEAPになります。 これが，シミュレーションでEAP（＝条件づけていないEAP）とPV3（≒条件づけたEAP）の値が微妙に違う理由です。↩︎",
    "crumbs": [
      "理論編",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>推算値法</span>"
    ]
  },
  {
    "objectID": "intsvy.html",
    "href": "intsvy.html",
    "title": "12  intsvyを使う",
    "section": "",
    "text": "12.1 intsvyのインストール\n理論編ではPISAを例に，LSAで一般的に利用されている技術 （標本ウェイト・Replication Method・項目反応理論・推算値法）について 解説してきました。 これらの説明を聞いて面倒だと思った人も多いでしょう。 幸い，こうした処理はPISAやTIMSSを分析するだけならば， それほど大きな壁ではありません。 基本的な分析（平均や相関，あるいは回帰）であれば， Replication MethodsやPVsの統合を自動化してくれるソフトウェアがあるからです。 ここでは，RでPISAやTIMSSといったLSAを分析するためのパッケージである intsvyを紹介します。\n以下のコマンドを入力すると， colab上でintsvyが使えるようになります。\n# R on Colab上でintsvyを使う\n# ダウンロード\nsystem(\"curl -L -o library.tar.gz https://github.com/kawa5902/LSAdata/raw/refs/heads/main/202502library.tar.gz\")\n# 解凍\nsystem(\"tar -xzf /content/library.tar.gz -C /content\")\n.libPaths(\"library\")\nなお，この方法は一般的なRのパッケージのインストール方法ではありません。 通常のRでは，パッケージを追加する際install.packages関数を使います。 たとえばintsvyをインストールする際は，以下のように行います。\n# インストール\ninstall.packages(\"intsvy\")\nColab上でもinstall.packages関数を利用してパッケージをインストールすることは可能です。 ただColabを終了すると，インストールしたパッケージはすべて消えてしまいます。 そのため再びColabを起動した際は，あらためてinstall.packagesを実行する必要があります。 intsvyのインストールには10分程度必要なので，1〜2回ならともかく 分析のたびにinstall.packagesを実行するのは苦痛です。\nそこで本書では，あらかじめColab上にインストールしたパッケージの塊（library.tar.gz）を 別の場所（github）1に保存しておき， それをダウンロードしてきて使うという方法を採用しています。 この方法なら1分弱でintsvyを利用可能になります。 ただし裏技に近い使い方なので，Colab以外では使用しないでください。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>intsvyを使う</span>"
    ]
  },
  {
    "objectID": "intsvy.html#平均や分散の計算pvを使わない場合",
    "href": "intsvy.html#平均や分散の計算pvを使わない場合",
    "title": "12  intsvyを使う",
    "section": "12.2 平均や分散の計算（PVを使わない場合）",
    "text": "12.2 平均や分散の計算（PVを使わない場合）\nここではPISA2012の日本のデータを例に，いくつかintsvyを使った分析をしてみましょう。\n\n# データの読み込み\nurl &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012stuJPN.csv\"\njpn2012 &lt;- read.csv(url)\n\n最初に，ESCSの平均値を計算することを考えましょう。 まず，ESCSは欠測値として9999が設定されているので， 事前にNAに変換しておく必要があります。 続いてpisa.mean関数を使うことで，平均を求めることができます。 この関数は，標本ウェイトやreplication weightを考慮した計算を行ってくれるので， 引数を設定するだけで適切な推定値や標準誤差が算出されます。 なお，本書ではpisa.mean関数がintsvyパッケージに含まれていることを明示するため， intsvy::pisa.meanという具合に，関数の前にパッケージ名を示す記法を採用しています。 引数のvariableに与えるのは文字なので，ダブルクオーテーション（\"\"）で囲むことを忘れないでください。\n\n# 欠測をNAに変換\njpn2012$ESCS[jpn2012$ESCS == 9999] &lt;- NA\nintsvy::pisa.mean(variable = \"ESCS\", data = jpn2012)\n\n  Freq        Mean       s.e.        SD         s.e\n1 6185 -0.07151303 0.01524119 0.7036702 0.007597166\n\n\n度数分布はpisa.table関数です。 この関数は度数（Freq）と標本ウェイトを考慮した割合（Percentage）， および割合の標準誤差（Std.err）を算出します。 pisa.mean関数の場合と同じく，intsvy::pisa.tableとして利用します。\n\nintsvy::pisa.table(variable = \"ST03Q01\", data = jpn2012)\n\n   ST03Q01 Freq Percentage Std.err.\n1        1  521       8.20     0.36\n2        2  456       7.27     0.38\n3        3  501       7.89     0.38\n4        4  532       8.30     0.36\n5        5  533       8.43     0.34\n6        6  521       8.07     0.30\n7        7  574       9.00     0.40\n8        8  560       8.94     0.36\n9        9  541       8.56     0.43\n10      10  547       8.64     0.32\n11      11  510       7.98     0.38\n12      12  555       8.72     0.38\n\n\nいずれの関数も引数byを設定することで， 下位集団ごとの推定値を得ることが可能です。 引数byに与えるのも文字なので，ダブルクオーテーション（\"\"）で囲んでください。 ここでは， 男女（ST04Q01）別のESCSの平均値と， 男女（ST04Q01）別の生まれ月（ST03Q01）の度数分布を示しています。\n\nintsvy::pisa.mean(variable = \"ESCS\", by = \"ST04Q01\", data = jpn2012)\n\n  ST04Q01 Freq        Mean       s.e.        SD         s.e\n1       1 2974 -0.07228828 0.02079859 0.7075644 0.010526624\n2       2 3211 -0.07079883 0.01925711 0.7001372 0.008863656\n\nintsvy::pisa.table(variable = \"ST03Q01\", by = \"ST04Q01\", data = jpn2012)\n\n   ST04Q01 ST03Q01 Freq Percentage Std.err.\n1        1       1  263       8.73     0.51\n2        1       2  225       7.60     0.51\n3        1       3  226       7.48     0.49\n4        1       4  249       8.11     0.48\n5        1       5  268       9.00     0.49\n6        1       6  247       7.97     0.42\n7        1       7  263       8.57     0.58\n8        1       8  264       8.78     0.49\n9        1       9  249       8.40     0.62\n10       1      10  275       9.16     0.50\n11       1      11  226       7.43     0.47\n12       1      12  266       8.76     0.51\n13       2       1  258       7.73     0.49\n14       2       2  231       6.97     0.46\n15       2       3  275       8.25     0.49\n16       2       4  283       8.47     0.46\n17       2       5  265       7.92     0.48\n18       2       6  274       8.15     0.45\n19       2       7  311       9.38     0.51\n20       2       8  296       9.08     0.50\n21       2       9  292       8.70     0.50\n22       2      10  272       8.17     0.51\n23       2      11  284       8.49     0.49\n24       2      12  289       8.69     0.52\n\n\npisa.rho関数を使うと，指定した変数間の相関係数（およびその標準誤差）を算出できます。 ここでは，PV1READ・PV1MATH・ESCSの3つの変数間の相関係数を出力しています。\n\nintsvy::pisa.rho(variables = c(\"PV1READ\", \"PV1MATH\", \"ESCS\"), data = jpn2012)\n\n        PV1READ Rho PV1READ s.e. PV1MATH Rho PV1MATH s.e. ESCS Rho ESCS s.e.\nPV1READ       1.000        0.000       0.861        0.006    0.289     0.024\nPV1MATH       0.861        0.006       1.000        0.000    0.320     0.025\nESCS          0.289        0.024       0.320        0.025    1.000     0.000\nattr(,\"class\")\n[1] \"intsvy.rho\" \"matrix\"     \"array\"",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>intsvyを使う</span>"
    ]
  },
  {
    "objectID": "intsvy.html#平均や分散の計算pvを使う場合",
    "href": "intsvy.html#平均や分散の計算pvを使う場合",
    "title": "12  intsvyを使う",
    "section": "12.3 平均や分散の計算（PVを使う場合）",
    "text": "12.3 平均や分散の計算（PVを使う場合）\n前の節で取り上げた関数のうち，pisa.mean関数にはPVを考慮した pisa.mean.pvという関数が存在します。 この関数では，読解リテラシーや数学リテラシーの平均値と標準偏差を算出することが可能です。 PVの設定にはやや癖があり，paste0関数を使うことになっています。 また，引数byを設定することで，男女別の平均値などを出力することもできます。 ここでは，数学リテラシー（paste0(\"PV\", 1:5, \"MATH\")）の平均値の出力と， それをさらに男女（ST04Q01）別に計算する方法を示します。 paste0内の数値（1:5）は，PVの数に対応しています。 PISA2012ではPV1からPV5までが存在するので，paste0(\"PV\", 1:5, \"MATH\")というわけです。 PISA2015以降ではPVが10個になりますので，paste0(\"PV\", 1:10, \"MATH\")とします。\n\nintsvy::pisa.mean.pv(pvlabel = paste0(\"PV\", 1:5, \"MATH\"), data = jpn2012)\n\n  Freq   Mean s.e.    SD  s.e\n1 6351 536.41 3.59 93.52 2.19\n\nintsvy::pisa.mean.pv(\n  pvlabel = paste0(\"PV\", 1:5, \"MATH\"), by = \"ST04Q01\", data = jpn2012\n)\n\n  ST04Q01 Freq   Mean s.e.    SD  s.e\n1       1 3021 527.01 3.59 88.06 2.63\n2       2 3330 544.88 4.62 97.41 2.65",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>intsvyを使う</span>"
    ]
  },
  {
    "objectID": "intsvy.html#回帰分析",
    "href": "intsvy.html#回帰分析",
    "title": "12  intsvyを使う",
    "section": "12.4 回帰分析",
    "text": "12.4 回帰分析\n回帰分析を行う関数として，pisa.reg，pisa.reg.pv関数が用意されています。 前者がPVを使わない場合，後者はPVを使う場合の関数です。 ここでは，PV1READを従属変数，ESCSを独立変数とした場合の回帰分析の例を示します。 式で言うと，\\(PV1READ = \\beta_0 + \\beta_1 ESCS + \\epsilon\\)という状態です。\n\nintsvy::pisa.reg(y = \"PV1READ\", x = \"ESCS\", data = jpn2012)\n\n            Estimate Std. Error t value\n(Intercept)   543.78       3.32  163.92\nESCS           39.24       3.69   10.63\nR-squared       0.08       0.01    5.95\n\n\n出力は，Estimateの列が推定値，Std.Errの列が標準誤差を示します。 t valueの列やはR-squaredの行は気にしなくて構いません2。 ここでは，(Intercept)が\\(\\beta_0\\)，ESCSが\\(\\beta_1\\)に該当しますので， ESCSが1単位上昇するとPV1READが39.24ポイント上昇するという関係があることになります3。 intsvyを使うと，回帰係数にも標準誤差を算出してくれます。 標準誤差の解釈は，平均値の標準誤差とほぼ同様で 「母集団でPV1READを従属変数・ESCSを独立変数とする回帰分析を行った場合， ESCSの係数は39.24±3.69のどこかにある」（と信じよう） という意味になります4。\nPVを使う場合は，以下のようになります。 PVの書き方は，pisa.mean.pvの場合と同じです。\n\nintsvy::pisa.reg.pv(\n  x = \"ESCS\", pvlabel = paste0(\"PV\", 1:5, \"READ\"), data = jpn2012\n)\n\n            Estimate Std. Error t value\n(Intercept)   543.59       3.34  162.58\nESCS           37.99       3.91    9.71\nR-squared       0.08       0.01    5.42\n\n\n出力の読み方は，先ほどとほぼ同じです。 PV1からPV5までを考慮すると， ESCSが1単位上昇すると読解リテラシーが37.99ポイント上昇するという関係があることになります。 標準誤差もPV1のみの場合は3.69だったのに対し，PV1からPV5を使うと3.91になっています。 推算値の使い方でも説明しましたが， 一般的な傾向として，PVをすべて使うと，PVが1つの場合に比べて標準誤差が大きくなります。\npisa.reg関数・pisa.reg.pv関数のいずれについても，重回帰分析を行うことも可能です。 重回帰分析を行う場合は，引数xに独立変数（仮にA・B・Cとします）を c(\"A\", \"B\", \"C\")の形で指定します。 ここでは，pisa.reg.pv関数で読解リテラシーを従属変数， 性別（ST04Q01）とESCS（ESCS）を独立変数とした場合の重回帰分析の例を示します。 式で言うと，\\(読解リテラシー = \\beta_0 + \\beta_1 性別 + \\beta_2 ESCS + \\epsilon\\)という状態です。\n\nintsvy::pisa.reg.pv(\n  x = c(\"ST04Q01\", \"ESCS\"), pvlabel = paste0(\"PV\", 1:5, \"READ\"), data = jpn2012\n)\n\n            Estimate Std. Error t value\n(Intercept)   577.85       5.10  113.30\nST04Q01       -22.53       3.54   -6.36\nESCS           38.00       3.94    9.65\nR-squared       0.09       0.01    6.51\n\n\n出力の読み方は，pisa.reg関数と同じです。 この場合，「性別（ST04Q01）が同じ集団で比べると， ESCSが1単位上昇すると読解リテラシーが38.00上昇する」という関係があることになります5。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>intsvyを使う</span>"
    ]
  },
  {
    "objectID": "intsvy.html#相関係数pvを使う場合",
    "href": "intsvy.html#相関係数pvを使う場合",
    "title": "12  intsvyを使う",
    "section": "12.5 相関係数（PVを使う場合）",
    "text": "12.5 相関係数（PVを使う場合）\n2025年1月時点では，intsvyでPVを使った場合の相関係数は計算できません。 理由は不明ですが，pisa.rho.pv関数が実装されていないからです。 PV1からPV5を使って相関係数を算出する場合は， pisa.rho関数を使って自分で推定値を計算する必要があります。 たとえば，読解リテラシー（PV1READからPV5READ）とESCSの相関係数が計算したい場合は， 次のように入力し，ESCS Rhoの列の出力を見る必要があります。\n\nintsvy::pisa.rho(\n  variables = c(\"PV1READ\", \"PV2READ\", \"PV3READ\", \"PV4READ\", \"PV5READ\", \"ESCS\"),\n  data = jpn2012\n)\n\n        PV1READ Rho PV1READ s.e. PV2READ Rho PV2READ s.e. PV3READ Rho\nPV1READ       1.000        0.000       0.885        0.005       0.887\nPV2READ       0.885        0.005       1.000        0.000       0.883\nPV3READ       0.887        0.005       0.883        0.005       1.000\nPV4READ       0.888        0.005       0.883        0.005       0.884\nPV5READ       0.886        0.005       0.882        0.005       0.885\nESCS          0.289        0.024       0.273        0.024       0.277\n        PV3READ s.e. PV4READ Rho PV4READ s.e. PV5READ Rho PV5READ s.e. ESCS Rho\nPV1READ        0.005       0.888        0.005       0.886        0.005    0.289\nPV2READ        0.005       0.883        0.005       0.882        0.005    0.273\nPV3READ        0.000       0.884        0.005       0.885        0.006    0.277\nPV4READ        0.005       1.000        0.000       0.883        0.005    0.279\nPV5READ        0.006       0.883        0.005       1.000        0.000    0.284\nESCS           0.026       0.279        0.025       0.284        0.025    1.000\n        ESCS s.e.\nPV1READ     0.024\nPV2READ     0.024\nPV3READ     0.026\nPV4READ     0.025\nPV5READ     0.025\nESCS        0.000\nattr(,\"class\")\n[1] \"intsvy.rho\" \"matrix\"     \"array\"     \n\n\nESCS Rhoの列を見ると，PV1READからPV5READとESCSの相関係数が出力されています。 この5つの値をRubinのルールに従って平均したものが読解リテラシーとESCSの相関係数になります6。 同様に，ESCS s.e.の列を使えば，相関係数の標準誤差を算出することも可能です。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>intsvyを使う</span>"
    ]
  },
  {
    "objectID": "intsvy.html#footnotes",
    "href": "intsvy.html#footnotes",
    "title": "12  intsvyを使う",
    "section": "",
    "text": "筆者のgithubです。PISAやTIMSSの日本のデータセットを置いています。↩︎\n興味のある方は，回帰係数の検定／R2乗値について調べてみてください。↩︎\n回帰分析については，単回帰分析をご覧ください。↩︎\n標準誤差の解釈については，標準誤差をご覧ください。↩︎\n重回帰分析の解釈については，重回帰分析をご覧ください。↩︎\nRubinのルールについては，推算値の使い方をご覧ください。↩︎",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>intsvyを使う</span>"
    ]
  },
  {
    "objectID": "pisa_timss.html",
    "href": "pisa_timss.html",
    "title": "13  PISAとTIMSSの概要",
    "section": "",
    "text": "13.1 PISA\nintsvyを使って本格的に分析を行う前に， 分析結果を解釈する上で必要になる PISAとTIMSSの概要を簡単にまとめておきましょう。 より詳細な説明は，PISAやTIMSSのホームページや それぞれのTechnical Reportを参照してください。\nPISAはOECD（経済協力開発機構）が実施する国際的な学力調査です。 その目的は， 「各国の子供たちが将来生活していく上で必要とされる知識や技能が， 義務教育終了段階でどの程度身に付いているかを測定すること」[1]とされています。 この目的のもと，PISAは 多くの国で義務教育終了段階にあたる15歳児（ただし学校に通う者に限る）を対象に行われています。 日本では高校1年生が調査対象に該当し，だいたい6月〜8月頃に調査を受けています。 なお日本では15歳≒高校1年生なので受検者は100%が高校1年生ですが， 他の国・地域では飛び級・留年などがあるため， （日本で言う）中学2年生や高校2年生が調査に参加していることもあります。\nPISAの標本抽出は，学校・生徒という層化二段抽出法が採用されています。 日本では普通科や商業科といった「学科」を抽出単位とし， 抽出された各学科の1年生からさらに35人を抽出する形を取っています。 標準誤差の算出は，Replication Methodの章で扱ったように FayによるBRR法（Balanced Repeated Replication Method）が採用されています。\nPISA調査の主たる調査対象は， 読解リテラシー（Reading Literacy）1・ 数学リテラシー（Mathematics Literacy）・ 科学リテラシー（Scientific Literacy）の3分野です。 個々のリテラシーの概要については，公開された項目が教育政策研究所のウェブサイトに掲載されているので， それを参照するとよいでしょう。 各回の調査では，3つのリテラシー以外にも追加調査（金融リテラシーなど）が行われることもあります。\nPISAの得点算出にはIRTが利用されています。 PISA2012まではRasch Modelと部分採点モデルが採用されていましたが， 2015年は1PLモデルと2PLモデル・部分採点モデルのハイブリッドモデルになりました。 その後は2PLモデルと部分採点モデルを中心としつつ，独自の工夫をこらしたモデルが採用されているようです。 もっとも分析者がこれらのモデルを意識する必要はほとんどなく， データセット内に含まれたPVsを使えば分析が可能です2。 PVの数は2012年調査までは5でしたが，2015年調査から10に変更されました。\nPISAは2000年から開始され，3年おきに実施されています。 ただし2021年はコロナのために延期され，2022年に実施されています。 3年ごとに主たる調査領域（main domain）が変更され， 2000年は読解，2003年は数学，2006年は科学，2009年は読解・・・となっています。 最新のPISA2022の主たる領域は，数学リテラシーです。 PISAの得点はIRTによって共通の尺度上に構成されており， 最初に主たる調査領域になった年度のOECD加盟国の平均を500・標準偏差を100とした数値に変換されています3。\nPISAは，2015年からテストのCBT（Computer-based Testing）化が進められています。 これによって重複テスト分冊法よりもさらに複雑な出題4が可能になっています。 さらに2018年以降はMultistage Adaptive Testingと呼ばれる，受検者の能力に応じて 出題される項目の難易度が変わるテスト設計が採用されました。\nPISAでは，学力テストに加え，生徒や学校に対する質問調査も実施されています。 これ以外に保護者調査や教員調査が実施される国・地域もありますが，日本は参加していません。 質問項目の内容は， OECDのウェブサイト（PISA data and methodology） から確認できます。 このサイトからは，PISAの個票データやTechnical Reportなどもダウンロード可能です。 ただ基本的に英語なので，日本語でどのような設問が出題されたか知りたい場合は， 明石書店から発刊されている『生きるための知識と技能』という書籍の付録を見る必要があります。\nPISAの参加国は，回を重ねるごとに増加する傾向があります。 初回のPISA2000は32カ国でしたが，最新のPISA2022では81の国と地域が参加しています。 日本はPISA2000以降，すべての調査に参加しています。 ただし初期のPISA2000やPISA2003では，日本の生徒・学校が回答していない質問が多数見られます5。 日本のデータを使った分析をする場合は，PISA2006以降が望ましいかもしれません。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>PISAとTIMSSの概要</span>"
    ]
  },
  {
    "objectID": "pisa_timss.html#timss",
    "href": "pisa_timss.html#timss",
    "title": "13  PISAとTIMSSの概要",
    "section": "13.2 TIMSS",
    "text": "13.2 TIMSS\nTIMSSは，IEA（国際教育到達度評価学会）が実施する数学と理科の国際的な学力調査です。 第4学年・第8学年に在籍する子どもの学力を国際的な尺度によって測定し， 学力と学習環境等との関係を明らかにすることを目的としています。 学校に通う15歳児を対象にするPISAに対し，TIMSSは学年を調査対象にしていることになります。 ちなみに日本では第4学年は9歳か10歳，第8学年は13歳か14歳ですが， 他の国・地域では留年や飛び級があるので，必ずしもこの年齢に該当しない子どもも受検しています。\nTIMSSの標本抽出は，最初に学校を抽出し， 続いて学校から1（ないしそれ以上）の学級を抽出するという 層化二段クラスターサンプリングが採用されています。 標本ウェイトの生成など，基本的な考え方はPISAと大きく変わりません。\nただし標準誤差を算出する際のReplication MethodはPISAと違い， JackKnife法（JK法）の一種であるJRR（Jackknife Repeated Replication）法が採用されています。 JRRは抽出された学校を75のペア6にグループ化（Zoneと呼ばれます）し， 「一つのZoneだけ，片方の学校のウェイトを0倍・もう片方の学校のウェイトを2倍にする」 という手順で新たな標本を作成します。 個々のZoneには2つの学校がありますので，いずれを0にするかによって， 1つのZoneからは2つの標本が生成できます。 75のZoneがありますから，全部で150の標本が生成されることになります。\nJRRのZoneとウェイトの関係を，表 13.1をもとに説明しましょう。 まず各学校（s1〜s150）は，2つずつ75のZoneに分かれています。 JRRで標本を生成する際は，まずZone 1でs1のウェイトを2倍，s2のウェイトを0倍にします（r1）。 次にZone 1でs1のウェイトを0倍，s2のウェイトを2倍にします（r2）。 その後も，Zone 2でs3のウェイトを2倍，s4のウェイトを0倍（r3）， Zone 2でs4のウェイトを0倍，s4のウェイトを2倍（r4）・・・という作業を続け， r1からr150まで150の標本を生成することになります。\n\n\n\n表 13.1: Sampling Zoneとウェイトの関係\n\n\n\n\n\n標本\nZone 1\nZone 2\nZone 3\n…\nZone 75\n\n\n\n\n\ns1 s2\ns3 s4\ns5 s6\n…\ns149 s150\n\n\nr1\n2 0\n1 1\n1 1\n…\n1 1\n\n\nr2\n0 2\n1 1\n1 1\n…\n1 1\n\n\nr3\n1 1\n2 0\n1 1\n…\n1 1\n\n\nr4\n1 1\n0 2\n1 1\n…\n1 1\n\n\nr5\n1 1\n1 1\n2 0\n…\n1 1\n\n\nr6\n1 1\n1 1\n0 2\n…\n1 1\n\n\n⋮\n⋮ ⋮\n⋮ ⋮\n⋮ ⋮\n⋮\n⋮ ⋮\n\n\nr149\n1 1\n1 1\n1 1\n…\n2 0\n\n\nr150\n1 1\n1 1\n1 1\n…\n0 2\n\n\n\n\n\n\nこのとき推定値の分散\\(Var_{jrr}\\)は， 最終的な推定値を\\(t_0\\)， \\(t_{hi}\\)をZone \\(h\\)において学校\\(i\\)のウェイトを2倍（ペアになる学校のウェイトは0）にしたときの推定値 としたとき，以下の式で与えられます。\n\\[Var_{jrr}(t_0) = \\frac{1}{2}\\sum_{h=1}^{75}\\sum_{i=1}^2(t_{hi}-t_0)^2\\]\nもっともこの式を覚える必要はありません。 PISAの分析でも利用したintsvyを使えば自動的に分散が出力されるからです。\nTIMSSの調査領域は，数学と科学です。PISAと違い，こちらは 日本でもおなじみの数学（あるいは算数）と理科のテストと思っても，それほど間違いではありません。 PISAと同じく 国立教育政策研究所のウェブサイト に公開項目が掲載されていますので，確認してみてください。\n得点の算出には，PISAと同じくIRTが利用されており， 異なるTIMSS間であっても得点を比較することが可能です。 IRTのモデルには3PLが採用され，PVは5つの値が生成されています。 なおTIMSS1995の得点は，それ以降のTIMSSと比較可能にするために再推定が行われています。 TIMSS1995のデータセットには，TIMSS1995用の得点と，後のTIMSSと比較可能にした得点の2つが 存在するので，利用する際は注意が必要です。\n現在のTIMSSは，1995年から開始され，4年おきに実施されています。 ただし1995年・1999年のTIMSSは現在の形とはかなり違います。 TIMSS1995はもともとThe Third International Mathematics and Science Studyの略でした。 IEAは1995年以前にも国際的な学力調査を実施しており， TIMSS1995は「3回目の国際学力調査」という意味だったのです。 その後，1999年にTIMSSを再実施するということでTIMSS-Repeatという名前で TIMSS1999が実施されました。 そしてTIMSS1999の後も，4年おきに数学と理科の国際調査を継続していくことになり， あらためてTIMSS（Trends in International Mathematics and Science Study）として TIMSS1995・TIMSS1999も含めて整備されたのが現在のTIMSSです。 こうした事情があるため，TIMSS1995・TIMSS1999はそれ以降のTIMSSとは設計がかなり違います。 たとえばTIMSS1995は第3学年・第7学年でも調査を行っていましたし， TIMSS1999は第8学年しか調査していません。 現在のように，第4学年・第8学年を調査するようなったのは，TIMSS2003からです。\nTIMSSでは学力テストに加え， 児童生徒・学校・教科を担当する教員・保護者に対する質問調査が行われています。 PISAとは違って，日本はこちらの調査には参加しています。 そのためTIMSSの日本のデータでは，教員票・保護者票を使った分析が可能です。 日本は初回から参加していますが， 初期のTIMSSでは日本は児童生徒質問の一部に回答しておらず， やや分析に利用しづらいものになっています。 TIMSS2007以降は国際調査とほぼ同じ設問に回答しています。\nTIMSSのデータセットは，IEAのウェブサイトからダウンロード可能です。 ダウンロードしたデータには出題された生徒質問・学校質問などのデータも含まれています。 ただ基本的に英語なので，日本語で設問の内容を知りたいときは， 明石書店から発刊されている書籍『算数・数学教育／理科教育の国際比較』を見る必要があります。 ちなみにTIMSS2019については，先の国立教育政策研究所のウェブサイトで質問項目を見ることができます。\n\n\n\n\n1. 国立教育政策研究所. (2024年). 生きるための知識と技能8 OECD生徒の学習到達度調査（PISA）. 明石書店.",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>PISAとTIMSSの概要</span>"
    ]
  },
  {
    "objectID": "pisa_timss.html#footnotes",
    "href": "pisa_timss.html#footnotes",
    "title": "13  PISAとTIMSSの概要",
    "section": "",
    "text": "読解リテラシーは，日本では「読解力」と訳されています。ただ， 他の2つが〇〇リテラシーなのに，読解だけ読解力なのは統一感を欠きますので，本書では〇〇リテラシーで統一しています。↩︎\nもちろん得点算出のプロセスを検討したい場合は，IRTを学ぶ必要があります。↩︎\n読解リテラシーは2000年以降のすべてのPISAと得点を比べられますが， 数学リテラシーは2003年以降，科学リテラシーは2006年以降のPISAとしか得点を比べられないということです。↩︎\n詳しくはPISA2015 Technical ReportのChapter 2をご覧ください。↩︎\nたとえばPISA2000では，日本は家庭環境に関する設問にはほとんど回答していません。↩︎\n国や地域によって75ではないこともあります。↩︎",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>PISAとTIMSSの概要</span>"
    ]
  },
  {
    "objectID": "pisa.html",
    "href": "pisa.html",
    "title": "14  PISAの分析",
    "section": "",
    "text": "14.1 あらためて家族構成と学力\nここまでの説明を踏まえれば，十分にPISAを分析することが可能です。 PISAデータを使った分析例をいくつか挙げていきましょう。\n最初に，相関係数と回帰分析で取り上げた家族構成と学力の関連について， 標本ウェイトやreplication methods，そしてPVsを踏まえて再検討してみます。 以下では，ひとり親家庭の変数を作るために，carというパッケージのrecode関数を利用しています。 Colabでintsvyを使うための設定をしていれば，carは含まれているはずです。\n# データのダウンロード\njpn2012 &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012stuJPN.csv\")\n# carパッケージのrecode関数を使う\njpn2012$single &lt;- car::recode(jpn2012$FAMSTRUC, \"1=1; 2:3=0; else = NA\")\nintsvy::pisa.table(\"single\", data = jpn2012)\n\n  single Freq Percentage Std.err.\n0      0 5327      87.84     0.58\n1      1  740      12.16     0.58\n最初に，ひとり親家庭とそれ以外の家庭のあいだにある平均値の差を見てみましょう。 1がひとり親家庭，0がそれ以外の家庭を表します。\nまずは単純な無作為抽出を前提に，平均値と標準誤差を計算します。 PVはPV1READのみを使用します。\n# PV1のみ。単純な無作為抽出を想定\ntapply(jpn2012$PV1READ, jpn2012$single, mean)\n\n       0        1 \n545.8272 515.3054 \n\n# 標準誤差\ntapply(jpn2012$PV1READ, jpn2012$single, function(x) sd(x) / sqrt(length(x)))\n\n       0        1 \n1.318133 3.591218\n続いて標本ウェイト，replication methodを考慮した上で， 5つのPVを使った場合の推定値を計算します。 これには2つの方法があり，pisa.mean.pv関数で引数byを設定する方法と， pisa.reg.pv関数の独立変数にsingleを指定する方法が使えます。\n# 5つのPVを使い，weightを考慮\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:5, \"READ\"), by = \"single\", data = jpn2012)\n\n  single Freq   Mean s.e.     SD  s.e\n1      0 5327 545.70  3.6  95.58 2.04\n2      1  740 514.56  6.0  96.14 3.49\n3   &lt;NA&gt;  284 451.31 11.2 113.22 6.35\n\n# pisa.mean.pvと同じことを回帰分析で実行\nintsvy::pisa.reg.pv(\"single\", paste0(\"PV\", 1:5, \"READ\"), data = jpn2012)\n\n            Estimate Std. Error t value\n(Intercept)   545.70       3.60  151.41\nsingle        -31.14       5.39   -5.77\nR-squared       0.01       0.00    3.03\n出力が違うのでわかりにくいかもしれませんが， 回帰分析の切片（Intercept）の値は，それ以外（single=0）の平均値（545.70）と同じです。 回帰分析の係数（single）の値は，ひとり親家庭とそれ以外の家庭の平均値の差 （514.56 - 545.70）と同じになっています。 いずれにせよ，ひとり親家庭のほうが31.14ポイント成績が低いということです。\n単純な無作為抽出を前提にした推定では， それ以外の家庭の平均値は545.83・標準誤差1.3， ひとり親家庭の平均値は515.31・標準誤差は3.6でした。 標本ウェイトやreplication methodsを考慮すると， それ以外の家庭の平均値は545.70・標準誤差3.6， ひとり親家庭の平均値は514.56・標準誤差は6.0になっています。 平均値はほとんど変わりませんが， 標準誤差が大きくなることがわかります。\n標準誤差が大きいということは，母集団における真の値の範囲が広がるということです。 （約）95%信頼区間を考えると， 単純な無作為抽出の場合， それ以外の家庭の平均値は545.83±2×1.3， ひとり親家庭の平均値は515.31±2×3.6の範囲にあります。 他方で適切な推定では， それ以外の家庭の平均値は545.70±2×3.6， ひとり親家庭の平均値は514.56±2×6.0の範囲にあるということになります。 今回はいずれの推定でも「ひとり親家庭のほうが平均値が低い」という解釈に違いはありません1が， 場合によっては推定法によって判断が変わってくることもあるでしょう。 LSAで単純な無作為抽出を前提とした分析を行うと，標準誤差を小さめに見積もってしまうので注意が必要です。\n続いて重回帰分析を行います。 ここでは，従属変数に読解リテラシー，独立変数にESCSとsingleを設定します。 単純な無作為抽出を仮定したモデルでは，PV1READを従属変数に使います。\n# 単純な無作為抽出を前提に，重回帰分析の係数と標準誤差を算出\njpn2012$ESCS[jpn2012$ESCS == 9999] &lt;- NA\nround(summary(lm(PV1READ ~ ESCS + single, data = jpn2012))$coefficients, 2)\n\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   546.84       1.27  429.91        0\nESCS           37.85       1.72   22.05        0\nsingle        -12.96       3.74   -3.47        0\n\n# PVやウェイトを考慮した回帰分析\nintsvy::pisa.reg.pv(\n  c(\"ESCS\", \"single\"), paste0(\"PV\", 1:5, \"READ\"),\n  data = jpn2012\n)\n\n            Estimate Std. Error t value\n(Intercept)   546.55       3.29  165.93\nESCS           36.06       3.71    9.72\nsingle        -14.63       4.49   -3.25\nR-squared       0.08       0.01    5.47\n回帰分析の推定結果を見ると，回帰係数の推定値はそれほど変わりません。 ただ，単純な無作為抽出を前提にした推定は標準誤差を過小推定しています。 たとえばsingleの偏回帰係数を比べると， 単純な無作為抽出の場合は-12.96（標準誤差3.74）に対して， 適切な推定の場合は-14.63（標準誤差4.49）です。 それほど大きな差ではありませんが，判断が変わってくる場合もあるでしょうから， 回帰分析の場合も単純な無作為抽出を前提とした分析は望ましくありません。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>PISAの分析</span>"
    ]
  },
  {
    "objectID": "pisa.html#学校データの結合",
    "href": "pisa.html#学校データの結合",
    "title": "14  PISAの分析",
    "section": "14.2 学校データの結合",
    "text": "14.2 学校データの結合\nPISAでは生徒質問だけでなく，学校質問も行われています。 そこで，学校データを利用することを考えてみましょう。 学校データの分析は，次の3ステップで行うことが可能です。\n最初にPISA2012の日本の学校データをjpn2012schに格納し， 生徒データ（jpn2012）とマージすることで 新しくjpn2012allというデータフレームを作成します。 学校データは，生徒データと同じくgithubにあるものを利用しています。 続いてマージには，Rのmerge関数を利用します。 結合したいデータフレームに加え， 引数byで生徒データ・学校データで共通する変数を指定することで， データフレームを結合できます。 最後にマージしたデータの分析をintsvyで行います。 ここでは，学校が所在する市町村のおよその人口を尋ねたSC03Q01変数と 生徒の数学リテラシーの得点の関連を検討しています。\n\njpn2012sch &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2012schJPN.csv\")\njpn2012all &lt;- merge(\n  jpn2012, jpn2012sch,\n  by = c(\"CNT\", \"SUBNATIO\", \"STRATUM\", \"SCHOOLID\", \"OECD\", \"NC\")\n)\n\n# SC03Q01\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:5, \"MATH\"), \"SC03Q01\", data = jpn2012all)\n\n  SC03Q01 Freq   Mean  s.e.    SD  s.e\n1       2   95 414.45 14.58 81.06 5.79\n2       3 1689 518.73  8.26 86.39 3.97\n3       4 3144 539.58  5.85 92.70 4.00\n4       5 1423 557.88 10.79 93.65 4.32\n\n\nSC03Q01の選択肢は， 「1:人口3000人未満の市町村」 「2:人口3000人〜約1万5000人未満の市町村」 「3:人口1万5000人〜約10万人未満の市町村」 「4:人口10万〜約100万人未満の都市」 「5:人口100万人以上の大都市」の5つです。 1に該当する生徒の数は0人（出力なし）， 2に該当する生徒の数はわずか95人ですから， 3・4・5のいずれかに該当する生徒がほとんどです。 数学リテラシーの平均値を見ると，3が518.73，4が539.58，5が557.88なので， 都市規模が大きいほど数学リテラシーが高いという結果になっていることがわかります。\nもっとも標準誤差（s.e.）も大きいので，母集団では差がないかもしれません。 （約）95%信頼区間を考えてみると， 3は502.2〜535.24，4は527.88〜551.28，5は536.30〜579.46となります。 3の「人口1万5000〜約10万人未満の市町村」の生徒の平均値が 5の「人口100万人以上の大都市」の生徒の平均値より低いとは言えそうですが， 4の「人口10万人〜約100万人未満の都市」の生徒の平均値が 5の「人口100万人以上の大都市」の生徒の平均値より低いかどうかはわかりません。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>PISAの分析</span>"
    ]
  },
  {
    "objectID": "pisa.html#pisa2012以外のデータを扱う",
    "href": "pisa.html#pisa2012以外のデータを扱う",
    "title": "14  PISAの分析",
    "section": "14.3 PISA2012以外のデータを扱う",
    "text": "14.3 PISA2012以外のデータを扱う\nここまで説明してきた内容は，PISA2012以外のPISAにもほぼ同様に当てはめることが可能です。 注意が必要な点は，PISA2015以降はPVが10個に増えていること， PISA2000はウェイトの変数名が異なることなどです。 データセットによってESCSの欠測値も異なっており， PISA2000に至ってはそもそもESCS変数が存在しません。\nここでは，PISA2012以外のPISAデータを使って， 平均値を算出する手順とESCSを独立変数とした回帰分析を行う手順を示します。\n\n14.3.1 PISA2000の場合\nPISA2000のデータを分析する場合，ウェイト変数が小文字になっている点に注意が必要です。 変数名を大文字にする処理は面倒で，dplyrパッケージのrename_with関数を使うことで対処します。 さらにPVsの変数名も小文字なので，PVの指定がpaste0(\"pv\", 1:5, \"read\")になります。 PISA2000の日本のデータにはESCS変数が存在しませんので，回帰分析は省略します。\n\njpn2000read &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2000stu_readJPN.csv\")\n# dplyrの導入\nsuppressMessages(library(dplyr)) # suppressMessagesでログを抑制\n\njpn2000read &lt;- jpn2000read |&gt;\n  rename_with(toupper, matches(\"^w_\"))\nintsvy::pisa.mean.pv(paste0(\"pv\", 1:5, \"read\"), data = jpn2000read)\n\n  Freq   Mean s.e.    SD  s.e\n1 5256 522.23 5.21 85.78 3.04\n\n\n\n\n14.3.2 PISA2003からPISA2009の場合\nダウンロードするデータが違うだけで，他の操作はPISA2012と共通です。 ただしESCSの欠測値が2003年と2006年は999，2009年は9997と9999になっている点に注意が必要です。 以下の分析では，PISA2009のESCSについて「999より上の値をNAにする」という処理を施しました。\n\njpn2003 &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2003stuJPN.csv\")\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:5, \"READ\"), data = jpn2003)\n\n  Freq   Mean s.e.     SD  s.e\n1 4707 498.11 3.92 105.51 2.53\n\njpn2003$ESCS[jpn2003$ESCS == 999] &lt;- NA\nintsvy::pisa.reg.pv(x = \"ESCS\", paste0(\"PV\", 1:5, \"READ\"), data = jpn2003)\n\n            Estimate Std. Error t value\n(Intercept)   501.85       3.38  148.50\nESCS           46.69       3.76   12.40\nR-squared       0.11       0.01    7.19\n\njpn2006 &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2006stuJPN.csv\")\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:5, \"READ\"), data = jpn2006)\n\n  Freq   Mean s.e.     SD  s.e\n1 5952 497.96 3.65 102.39 2.41\n\njpn2006$ESCS[jpn2006$ESCS == 999] &lt;- NA\nintsvy::pisa.reg.pv(x = \"ESCS\", paste0(\"PV\", 1:5, \"READ\"), data = jpn2006)\n\n            Estimate Std. Error t value\n(Intercept)   500.39       3.36  148.75\nESCS           39.22       3.03   12.93\nR-squared       0.07       0.01    7.33\n\njpn2009 &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2009stuJPN.csv\")\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:5, \"READ\"), data = jpn2009)\n\n  Freq   Mean s.e.     SD  s.e\n1 6088 519.86 3.47 100.36 2.93\n\njpn2009$ESCS[jpn2009$ESCS &gt; 999] &lt;- NA\nintsvy::pisa.reg.pv(x = \"ESCS\", paste0(\"PV\", 1:5, \"READ\"), data = jpn2009)\n\n            Estimate Std. Error t value\n(Intercept)   521.95       3.03  172.51\nESCS           40.08       2.83   14.16\nR-squared       0.09       0.01    8.97\n\n\n\n\n14.3.3 PISA2015以降の場合\nPISA2015以降はPVが10個になっている点に注意が必要です。 具体的には，paste0関数の書き方が変わり，1:5が1:10になります。 またESCSの欠測ははじめからNAが指定されているので， PISA2012までのように欠測を気にする必要はありません2。\n\njpn2015 &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2015stuJPN.csv\")\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:10, \"READ\"), data = jpn2015)\n\n  Freq   Mean s.e.    SD  s.e\n1 6647 515.96  3.2 92.44 1.83\n\nintsvy::pisa.reg.pv(x = \"ESCS\", paste0(\"PV\", 1:10, \"READ\"), data = jpn2015)\n\n            Estimate Std. Error t value\n(Intercept)   524.60       2.87  182.86\nESCS           41.27       2.43   16.96\nR-squared       0.10       0.01    8.71\n\njpn2018 &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2018stuJPN.csv\")\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:10, \"READ\"), data = jpn2018)\n\n  Freq   Mean s.e.    SD  s.e\n1 6109 503.86 2.67 97.12 1.68\n\nintsvy::pisa.reg.pv(x = \"ESCS\", paste0(\"PV\", 1:10, \"READ\"), data = jpn2018)\n\n            Estimate Std. Error t value\n(Intercept)   507.51       2.43  209.10\nESCS           37.59       2.84   13.26\nR-squared       0.08       0.01    6.90\n\njpn2022 &lt;- read.csv(\"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/pisa2022stuJPN.csv\")\nintsvy::pisa.mean.pv(paste0(\"PV\", 1:10, \"READ\"), data = jpn2022)\n\n  Freq   Mean s.e.    SD  s.e\n1 5760 515.85 3.18 96.26 1.86\n\nintsvy::pisa.reg.pv(x = \"ESCS\", paste0(\"PV\", 1:10, \"READ\"), data = jpn2022)\n\n            Estimate Std. Error t value\n(Intercept)   516.81       2.90  178.00\nESCS           39.89       2.95   13.54\nR-squared       0.09       0.01    6.96\n\n\n\n\n14.3.4 異なるPISAの結果を比較する場合\n異なるPISAの得点を比較する場合，統計的検定を行う必要があります。 本書の範囲を超えるので詳細は省略しますが， PISAで異なるサイクルの得点を比較する場合は，標準誤差に加えて， Link Errorと呼ばれる誤差を考慮する必要があります。\nPISAでは，尺度調整にIRTが利用されています。 尺度調整では，異なるサイクル間での能力比較で 説明したように，共通項目への受検者の反応が手がかりになります。 このとき共通項目の数や性質によって，調整に若干の誤差が生じます。 これを，Link Errorと呼びます。 異なるサイクル間で平均値を比較する場合， Link Errorも付加して標準誤差を計算しなければなりません。 詳細はTechnical ReportやData Analysis Manualに記載されていますので，参照してください。\nなお，個々のサイクルで平均値の（約）95%信頼区間を計算すれば， （ある程度ですが）学力が上がった／下がったという判断は可能です。 たとえばPISA2000とPISA2022の読解リテラシーを比べると， 前者は522.23（標準誤差5.21），後者は515.85（標準誤差3.18）です。 ここで信頼区間を考えると， 前者は522.23 ± 2 * 5.21 = 532.65〜511.81， 後者は515.85 ± 2 * 3.18 = 522.21〜509.49なので， 日本の読解リテラシーは2000年と2022年調査を比べると， 上がったとも下がったとも言えないと判断できます3。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>PISAの分析</span>"
    ]
  },
  {
    "objectID": "pisa.html#footnotes",
    "href": "pisa.html#footnotes",
    "title": "14  PISAの分析",
    "section": "",
    "text": "2つの集団間の平均値に差があるかどうか判定するには， 単回帰分析の係数（今回はsingle）の値を見ることが有効です。 独立変数が0と1のいずれかを取る単回帰分析の係数は，実質的に集団間の平均値の差を意味します。 ですからsingleの係数の信頼区間の最大値がマイナス（-31.14 + 2 * 5.39 = -20.36)ということは， 母集団において，ひとり親家庭（single = 1）の平均値がそれ以外の家庭（single = 0）より （小さく見積もっても）約20ポイント低いということを意味します。↩︎\nPISA2015からはSPSSという統計ソフトのデータを直接にRで読み込めます。 欠測の情報もSPSSで指定されていたものを読み取れるため，最初からNAになっているのです。↩︎\nこれは簡便な方法であり，正確ではありません。 詳しく知りたい方は「平均値の差の検定」について学んだ上で， PISA Data Analysis Manualの第13章を読んでください。↩︎",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>PISAの分析</span>"
    ]
  },
  {
    "objectID": "timss.html",
    "href": "timss.html",
    "title": "15  TIMSSの分析",
    "section": "",
    "text": "15.1 ファイル名\nintsvyを使えば，TIMSSもPISAと同じように分析することが可能です。 ただ，いくつか違う点もあります。\nTIMSSのデータファイルは，国ごとに分割され，命名規則に従ってファイル名が付けられています。 分析者にとって重要になるのは，主として以下のファイルです。 ここでは第4学年（ファイル名がAで始まる）のファイルを例に説明します。 第8学年のファイルは，ファイル名がBで始まることと， BTM（数学の教員質問）・BTS（理科の教員質問）の二種類が存在する点が違います。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "timss.html#ファイル名",
    "href": "timss.html#ファイル名",
    "title": "15  TIMSSの分析",
    "section": "",
    "text": "ACG: 第4学年・学校質問（school context data）\nASG: 第4学年・生徒質問（student context data）\nASH: 第4学年・家庭質問（home context data）\nAST: 第4学年・生徒教員リンク（student-teacher linkage）\nATG: 第4学年・教員質問（teacher context data）",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "timss.html#intsvyによるtimssの分析",
    "href": "timss.html#intsvyによるtimssの分析",
    "title": "15  TIMSSの分析",
    "section": "15.2 intsvyによるTIMSSの分析",
    "text": "15.2 intsvyによるTIMSSの分析\nここでは最新のTIMSS2019を例に，intsvyによる分析方法を示します。 最初にデータを読み込みます。 TIMSSのデータファイルはSPSSというソフトウェア向けのファイルフォーマットで 公開されているので，Rのforeignというパッケージにある read.spss関数を使って読み込みます。 後にintsvyを使う関係上，read.spss関数の設定は， 以下のようにしてください。\n\nurl_stu &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2019/asgjpnm7.sav\"\njpn09g4stu &lt;- foreign::read.spss(url_stu,\n  use.value.labels = FALSE,\n  to.data.frame = TRUE, use.missings = FALSE\n)\n\nまず児童に尋ねた家庭のある本の冊数（ASBG04変数）の回答と， 男女（ITSEX変数）の人数を確認してみましょう。 いずれの処理も，timss.table関数で実行できます。 出力は，pisa.tableの場合と同じです。\n\n# 家庭にある本の冊数\nintsvy::timss.table(\"ASBG04\", data = jpn09g4stu)\n\n  ASBG04 Freq Percentage Std.err.\n1      1  595      14.51     0.72\n2      2 1220      29.55     0.81\n3      3 1545      36.63     0.86\n4      4  521      12.12     0.60\n5      5  295       6.88     0.42\n9      9   14       0.31     0.09\n\n# 性別\nintsvy::timss.table(\"ITSEX\", data = jpn09g4stu)\n\n  ITSEX Freq Percentage Std.err.\n1     1 2038      48.39     0.48\n2     2 2158      51.61     0.48\n\n\n続いて算数・理科の平均値を計算します。 timss.mean.pv関数を使うと，5つのPVを使い， 平均値の計算とJK法による標準誤差の算出まで行ってくれます。 pisa.mean.pv関数と同じく，引数byを指定することで男女（ITSEX）別や 本の冊数（ASBG04）別の平均値も計算してくれます。\n\n# 算数の平均点\nintsvy::timss.mean.pv(paste0(\"ASMMAT0\", 1:5), data = jpn09g4stu)\n\n  Freq   Mean s.e.    SD s.e\n1 4196 592.96 1.75 70.21   1\n\n# 理科の平均点\nintsvy::timss.mean.pv(paste0(\"ASSSCI0\", 1:5), data = jpn09g4stu)\n\n  Freq   Mean s.e.    SD  s.e\n1 4196 561.66 1.77 68.91 1.56\n\n# 男女別\nintsvy::timss.mean.pv(paste0(\"ASMMAT0\", 1:5), by = \"ITSEX\", data = jpn09g4stu)\n\n  ITSEX Freq   Mean s.e.    SD  s.e\n1     1 2038 593.34 2.18 67.11 1.29\n2     2 2158 592.59 1.94 72.99 1.31\n\n# 家にある本の冊数別\nintsvy::timss.mean.pv(paste0(\"ASSSCI0\", 1:5), by = \"ASBG04\", data = jpn09g4stu)\n\n  ASBG04 Freq   Mean  s.e.    SD   s.e\n1      1  595 528.26  3.46 66.41  2.90\n2      2 1220 547.75  2.78 66.93  1.96\n3      3 1545 572.66  2.20 64.69  2.00\n4      4  521 582.04  3.94 64.46  3.02\n5      5  295 599.91  4.76 64.51  3.68\n6      9   14 487.47 27.14 86.89 18.28\n7   &lt;NA&gt;    6 597.36 18.86 81.25 30.20",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "timss.html#学校票の結合",
    "href": "timss.html#学校票の結合",
    "title": "15  TIMSSの分析",
    "section": "15.3 学校票の結合",
    "text": "15.3 学校票の結合\n学校票を結合する方法もPISAとほぼ同様です。 以下では，学校票のデータをjpn09g4schに格納し，生徒票のデータとmerge関数で結合しています。\n\nurl_sch &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2019/acgjpnm7.sav\"\njpn09g4sch &lt;- foreign::read.spss(url_sch,\n  use.value.labels = FALSE,\n  to.data.frame = TRUE, use.missings = FALSE\n)\n\njpn09g4v1 &lt;- merge(jpn09g4stu, jpn09g4sch,\n  by = c(\n    \"IDCNTRY\", \"IDSCHOOL\", \"IDPOP\", \"IDGRADER\", \"IDGRADE\",\n    \"WGTADJ1\", \"WGTFAC1\", \"VERSION\", \"SCOPE\"\n  )\n)\n\n結合した後は，timss.table関数などを使って分析が可能です。 以下の例では，経済的に恵まれない家庭の児童の割合（ACBG03A変数）の回答について， 学校票の回答割合（table関数を使って度数分布のみ出力）と， timss.table関数を使った児童の割合を出力しています。\n\n# ACBG03Aの回答（学校単位）\ntable(jpn09g4sch$ACBG03A)\n\n\n 1  2  3  4 \n77 56 13  1 \n\nround(prop.table(table(jpn09g4sch$ACBG03A)) * 100, 1)\n\n\n   1    2    3    4 \n52.4 38.1  8.8  0.7 \n\n# ACBG03Aの回答（児童単位）\nintsvy::timss.table(\"ACBG03A\", data = jpn09g4v1)\n\n  ACBG03A Freq Percentage Std.err.\n1       1 2207      51.69     4.17\n2       2 1569      38.21     4.22\n3       3  386       9.34     2.38\n4       4   34       0.76     0.76\n\n\n回答は「1: 0〜10%」「2: 11〜25%」「3: 26〜50%」「4: 50%より多い」の4択です。 度数分布を見ると，1が77校（52.4%）・2が56校（38.1%）・・・であることがわかります。 またtimss.tableの結果から，1の学校に所属する児童の割合が51.69%でもっとも多いことがわかります。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "timss.html#保護者票の結合",
    "href": "timss.html#保護者票の結合",
    "title": "15  TIMSSの分析",
    "section": "15.4 保護者票の結合",
    "text": "15.4 保護者票の結合\nTIMSSでは保護者票を結合することも可能です。 ここでは先ほど学校票を結合したデータフレームjpn09g4v1にさらに保護者票を結合します。\n\nurl_par &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2019/ashjpnm7.sav\"\njpn09g4home &lt;- foreign::read.spss(url_par,\n  use.value.labels = FALSE,\n  to.data.frame = TRUE, use.missings = FALSE\n)\njpn09g4v2 &lt;- merge(jpn09g4v1, jpn09g4home,\n  by = c(\n    \"IDCNTRY\", \"IDSCHOOL\", \"IDCLASS\", \"IDSTUD\", \"IDPOP\", \"IDGRADER\",\n    \"IDGRADE\", \"ASDAGE\", \"ASBGHRL\", \"ASDGHRL\", \"VERSION\", \"SCOPE\"\n  )\n)\n\n母親の学歴（ASBH15B変数）の回答割合に注目してみましょう。 ここでは回答者の母親学歴の分布（table関数で出力）， 母親学歴ごとの児童の分布（timss.table関数で出力）， 母親学歴ごとの児童の数学の平均値（timss.mean.pv関数で出力）のそれぞれを出力します。\n\n# 母親の学歴\ntable(jpn09g4home$ASBH15B)\n\n\n   3    4    5    6    7    8    9   99 \n 149 1205  108 1672  821   47    7   76 \n\nintsvy::timss.table(\"ASBH15B\", data = jpn09g4v2)\n\n   ASBH15B Freq Percentage Std.err.\n3        3  149       3.63     0.31\n4        4 1205      29.97     0.92\n5        5  108       2.67     0.24\n6        6 1672      40.85     0.79\n7        7  821      19.74     0.90\n8        8   47       1.12     0.22\n9        9    7       0.16     0.06\n99      99   76       1.85     0.23\n\nintsvy::timss.mean.pv(paste0(\"ASMMAT0\", 1:5), by = \"ASBH15B\", data = jpn09g4v2)\n\n  ASBH15B Freq   Mean  s.e.    SD   s.e\n1       3  149 540.60  5.31 62.61  4.45\n2       4 1205 575.01  2.16 66.46  1.95\n3       5  108 579.11  5.71 57.77  4.26\n4       6 1672 599.69  2.31 67.40  1.52\n5       7  821 625.30  2.92 65.49  2.09\n6       8   47 633.01  9.00 62.05  7.51\n7       9    7 548.29 36.66 93.37 32.29\n8      99   76 561.35 11.55 74.87  8.18\n9    &lt;NA&gt;  111 546.08  9.21 65.53  5.74\n\n\n母親の学歴の回答は， 「1:学校に行っていない」 「2:小学校」 「3:中学校」 「4:高等学校」 「5:高等学校の専攻科」 「6:短期大学，高等専門学校，専門学校」 「7:大学」 「8:大学院」 「9:あてはまらない」 の9択です。 回答者の人数を見ると， 6（短期大学，高等専門学校，専門学校）が1672人でもっとも多く， ついで4（高等学校）が1205人です。 児童の割合に注目すると，6（短期大学，高等専門学校，専門学校）の母親のいる児童が 全体の40.85%ということになります。 数学の成績に着目すると，基本的に母親の学歴が高いほど（＝回答番号が3から8になるにつれて） 児童の成績が高くなることがわかります。 ただし，8（大学院）は保護者の数が少ないこともあって標準誤差（s.e.）が9.00と大きくなっています。",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "timss.html#教員票の結合",
    "href": "timss.html#教員票の結合",
    "title": "15  TIMSSの分析",
    "section": "15.5 教員票の結合",
    "text": "15.5 教員票の結合\nTIMSSでは，児童を教えている教員に対しても質問票が配布されています。 教員票を使う場合，ATGで始まる教員票に加え，ASTで始まるリンクファイルもダウンロードする必要があります。\nなお，今回のように複数のデータフレームを結合する場合，merge関数ではどうしても書きにくくなります。 そこで，dplyrパッケージを使った結合を行っています。 dplyrはRの処理を円滑に行うために開発されたパッケージの一つです。 現代のRプログラミングでは必須とも言えるものなので， Rに関心のある方は学んでみるとよいでしょう。 dplyrを使った場合は，データフレーム間で共通する変数が自動的に認識されて結合されます。\n以下では分析例として，教員の学歴（ATBG04変数）の度数分布を表示しています。\n\nurl_l1 &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2019/astjpnm7.sav\"\nurl_l2 &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2019/atgjpnm7.sav\"\n\njpn09g4link &lt;- foreign::read.spss(url_l1,\n  use.value.labels = FALSE,\n  to.data.frame = TRUE, use.missings = FALSE\n)\njpn09g4tea &lt;- foreign::read.spss(url_l2,\n  use.value.labels = FALSE,\n  to.data.frame = TRUE, use.missings = FALSE\n)\n\n# dplyrを使うと簡単にマージ可能\nsuppressMessages(library(dplyr))\njpn09g4v3 &lt;- jpn09g4stu |&gt;\n  inner_join(jpn09g4link) |&gt;\n  inner_join(jpn09g4tea)\n\nJoining with `by = join_by(IDCNTRY, IDBOOK, IDSCHOOL, IDCLASS, IDSTUD, IDPOP,\nIDGRADER, IDGRADE, JKREP, JKZONE, ASMMAT01, ASMMAT02, ASMMAT03, ASMMAT04,\nASMMAT05, ASSSCI01, ASSSCI02, ASSSCI03, ASSSCI04, ASSSCI05, ASMNUM01, ASMNUM02,\nASMNUM03, ASMNUM04, ASMNUM05, ASMGEO01, ASMGEO02, ASMGEO03, ASMGEO04, ASMGEO05,\nASMDAT01, ASMDAT02, ASMDAT03, ASMDAT04, ASMDAT05, ASMKNO01, ASMKNO02, ASMKNO03,\nASMKNO04, ASMKNO05, ASMAPP01, ASMAPP02, ASMAPP03, ASMAPP04, ASMAPP05, ASMREA01,\nASMREA02, ASMREA03, ASMREA04, ASMREA05, ASSLIF01, ASSLIF02, ASSLIF03, ASSLIF04,\nASSLIF05, ASSPHY01, ASSPHY02, ASSPHY03, ASSPHY04, ASSPHY05, ASSEAR01, ASSEAR02,\nASSEAR03, ASSEAR04, ASSEAR05, ASSKNO01, ASSKNO02, ASSKNO03, ASSKNO04, ASSKNO05,\nASSAPP01, ASSAPP02, ASSAPP03, ASSAPP04, ASSAPP05, ASSREA01, ASSREA02, ASSREA03,\nASSREA04, ASSREA05, ASSENV01, ASSENV02, ASSENV03, ASSENV04, ASSENV05, ASMIBM01,\nASMIBM02, ASMIBM03, ASMIBM04, ASMIBM05, ASSIBM01, ASSIBM02, ASSIBM03, ASSIBM04,\nASSIBM05, VERSION, SCOPE)`\nJoining with `by = join_by(IDCNTRY, IDSCHOOL, IDPOP, IDGRADER, IDGRADE,\nVERSION, SCOPE, IDTEALIN, IDTEACH, IDLINK, IDSUBJ, ITCOURSE)`\n\n# ATBG04: 教員の学歴\ntable(jpn09g4tea$ATBG04)\n\n\n  4   5   6 \n 14 255  13 \n\nround(prop.table(table(jpn09g4tea$ATBG04)) * 100, 1)\n\n\n   4    5    6 \n 5.0 90.4  4.6 \n\n\nほとんどの教員が「5: 大卒」であることがわかります。 「4: 短大卒」や「6: 大学院卒」もわずかにいます。\n教員票を使った分析をする際に注意することは，標本ウェイトが変わるという点です。 TIMSSでは，児童を担当している教員はすべて教員票の対象になっています。 そのため算数や理科で複数の担任が担当していた場合， 児童1人に対して2名以上の教員票があるということも珍しくありません。 そのため教員票を結合すると，個々の教員に担当している児童が接続され， データセット内に同じ児童のデータが複数存在することになるのです。 このまま平均値などを計算すると，児童がダブルカウント（場合によってはトリプルカウント）されるため， 標本ウェイトを調整し，ダブルカウントの児童のウェイトは半分にするといった処理が行われています。 このウェイトをTIMSSでは教員ウェイト（TCHWGT）と呼んでいます。 intsvyでは，引数のtimss4_confを設定することでウェイトを変更可能です。 ただしこの場合は，timss.mean.pvではなく，intsvy.mean.pv関数を使う必要があります。 以下の例では，ウェイトを変更しなかった場合と変更した場合の推定値を比較しています。 度数（Freq）がjpn09g4v3では変わっていることも確認してください。\n\n# 正しい推定値（児童票のみ）\nintsvy::timss.mean.pv(paste0(\"ASMMAT0\", 1:5), data = jpn09g4stu)\n\n  Freq   Mean s.e.    SD s.e\n1 4196 592.96 1.75 70.21   1\n\n# 正しい推定値（学校票・保護者票を追加しても問題ない）\nintsvy::timss.mean.pv(paste0(\"ASMMAT0\", 1:5), data = jpn09g4v2)\n\n  Freq   Mean s.e.    SD s.e\n1 4196 592.96 1.75 70.21   1\n\n# ウェイトを変更せずに教員票を含むデータセットを使うと間違った推定値が出力される\nintsvy::timss.mean.pv(paste0(\"ASMMAT0\", 1:5), data = jpn09g4v3)\n\n  Freq  Mean s.e.   SD s.e\n1 7946 593.3 1.88 70.5   1\n\n# timss09g4_tchconfでウェイトを変更\ntimss09g4_tchconf &lt;- intsvy::timss4_conf\ntimss09g4_tchconf$variables$weight &lt;- \"TCHWGT\"\n# ウェイトを変更すると適切な推定値が得られる\nintsvy::intsvy.mean.pv(\n  pvnames = paste0(\"ASMMAT0\", 1:5),\n  data = jpn09g4v3, config = timss09g4_tchconf\n)\n\n  Freq   Mean s.e.    SD s.e\n1 7946 592.96 1.75 70.21   1\n\n# 教員の学歴別に算数の平均値を計算\nintsvy::intsvy.mean.pv(\n  pvnames = paste0(\"ASMMAT0\", 1:5), by = \"ATBG04\",\n  data = jpn09g4v3, config = timss09g4_tchconf\n)\n\n  ATBG04 Freq   Mean s.e.    SD  s.e\n1      4  353 591.46 5.65 65.12 2.96\n2      5 7133 593.30 1.89 70.33 1.02\n3      6  358 582.92 5.50 71.14 2.71\n4   &lt;NA&gt;  102 626.24 3.01 60.08 7.04",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "timss.html#第8学年のデータを扱う",
    "href": "timss.html#第8学年のデータを扱う",
    "title": "15  TIMSSの分析",
    "section": "15.6 第8学年のデータを扱う",
    "text": "15.6 第8学年のデータを扱う\n第8学年のデータも第4学年のデータと同様に分析可能です。 違いはファイル名と，教員票が数学と理科のそれぞれに存在する点です。\n\nurl_g8s &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2019/bsgjpnm7.sav\"\njpn09g8stu &lt;- foreign::read.spss(\n  url_g8s, to.data.frame = TRUE, use.value.labels = FALSE, use.missings = FALSE\n)\nintsvy::timss.mean.pv(paste0(\"BSMMAT0\", 1:5), data = jpn09g8stu)\n\n  Freq   Mean s.e.    SD  s.e\n1 4446 594.23 2.72 84.14 2.06\n\n\n以下の例では，第8学年の数学の平均値を教員の学歴（BTBG04変数）別に出力しています。 最初に，複数のデータファイルをlapply関数を使って一気にダウンロードしています。 その上でpurrrのreduce関数を使って複数のデータフレームを結合し，intsvy.mean.pv関数で分析しています。 数学の教員ウェイトを使う必要があるので，標本ウェイトはMATWGTに変更しています。 出力を見ると，標準誤差（s.e.）がNaNになっている箇所がありますが， これは該当する教員が1名しかいないので標準誤差が計算できなかったためです。\n\n# 複数のファイルを一気にダウンロード\nurl_g8 &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2019/b\"\njpn09g8data &lt;- lapply(c(\"sg\", \"st\", \"tm\"), function(x) {\n  foreign::read.spss(paste0(url_g8, x, \"jpnm7.sav\"),\n    use.value.labels = FALSE,\n    to.data.frame = TRUE, use.missings = FALSE\n  )\n})\n# データフレームを結合\njpn09g8 &lt;- jpn09g8data |&gt;\n  purrr::reduce(inner_join)\n\nJoining with `by = join_by(IDCNTRY, IDBOOK, IDSCHOOL, IDCLASS, IDSTUD, IDPOP,\nIDGRADER, IDGRADE, JKREP, JKZONE, BSMMAT01, BSMMAT02, BSMMAT03, BSMMAT04,\nBSMMAT05, BSSSCI01, BSSSCI02, BSSSCI03, BSSSCI04, BSSSCI05, BSMALG01, BSMALG02,\nBSMALG03, BSMALG04, BSMALG05, BSMAPP01, BSMAPP02, BSMAPP03, BSMAPP04, BSMAPP05,\nBSMDAT01, BSMDAT02, BSMDAT03, BSMDAT04, BSMDAT05, BSMGEO01, BSMGEO02, BSMGEO03,\nBSMGEO04, BSMGEO05, BSMKNO01, BSMKNO02, BSMKNO03, BSMKNO04, BSMKNO05, BSMNUM01,\nBSMNUM02, BSMNUM03, BSMNUM04, BSMNUM05, BSMREA01, BSMREA02, BSMREA03, BSMREA04,\nBSMREA05, BSSAPP01, BSSAPP02, BSSAPP03, BSSAPP04, BSSAPP05, BSSBIO01, BSSBIO02,\nBSSBIO03, BSSBIO04, BSSBIO05, BSSCHE01, BSSCHE02, BSSCHE03, BSSCHE04, BSSCHE05,\nBSSEAR01, BSSEAR02, BSSEAR03, BSSEAR04, BSSEAR05, BSSKNO01, BSSKNO02, BSSKNO03,\nBSSKNO04, BSSKNO05, BSSPHY01, BSSPHY02, BSSPHY03, BSSPHY04, BSSPHY05, BSSREA01,\nBSSREA02, BSSREA03, BSSREA04, BSSREA05, BSSENV01, BSSENV02, BSSENV03, BSSENV04,\nBSSENV05, BSMIBM01, BSMIBM02, BSMIBM03, BSMIBM04, BSMIBM05, BSSIBM01, BSSIBM02,\nBSSIBM03, BSSIBM04, BSSIBM05, VERSION, SCOPE)`\nJoining with `by = join_by(IDCNTRY, IDSCHOOL, IDPOP, IDGRADER, IDGRADE,\nVERSION, SCOPE, IDTEALIN, IDTEACH, IDLINK, IDSUBJ, ITCOURSE)`\n\n# timss8_confを修正\ntimss09g8m_tchconf &lt;- intsvy::timss8_conf\ntimss09g8m_tchconf$variables$weight &lt;- \"MATWGT\"\n# 教員の学歴（BTBG04）ごとの数学の平均値を出力\nintsvy::intsvy.mean.pv(\n  pvnames = paste0(\"BSMMAT0\", 1:5), by = \"BTBG04\",\n  data = jpn09g8, config = timss09g8m_tchconf\n)\n\n  BTBG04 Freq   Mean s.e.    SD   s.e\n1      4   72 581.96 6.51 73.97 14.05\n2      5 5136 595.35 3.15 85.08  2.13\n3      6  834 588.82 4.93 77.29  3.12\n4     99   36 568.53  NaN 88.02   NaN\n5   &lt;NA&gt;   35 587.10  NaN 70.07   NaN\n\n# SEがNAなのは該当する教員が1名しかいないため\ntable(jpn09g8data[[3]]$BTBG04, exclude = NULL)\n\n\n   4    5    6   99 &lt;NA&gt; \n   2  179   27    1    1 \n\nintsvy::intsvy.mean.pv(\n  pvnames = paste0(\"BSMMAT0\", 1:5),\n  data = jpn09g8, config = timss09g8m_tchconf\n)\n\n  Freq   Mean s.e.    SD  s.e\n1 6113 594.23 2.72 84.14 2.06",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "timss.html#過去のtimss",
    "href": "timss.html#過去のtimss",
    "title": "15  TIMSSの分析",
    "section": "15.7 過去のTIMSS",
    "text": "15.7 過去のTIMSS\nTIMSS2019の分析方法は，過去のTIMSSにも適用可能です。 たとえばTIMSS2003で，第4学年の日本の平均値を出力する方法は，以下のようになります。\n\nurl_03 &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss2003/ASGJPNm3.sav\"\njpn03g4stu &lt;- foreign::read.spss(url_03,\n  use.value.labels = FALSE,\n  to.data.frame = TRUE, use.missings = FALSE\n)\nintsvy::timss.mean.pv(paste0(\"ASSSCI0\", 1:5), data = jpn03g4stu)\n\n  Freq   Mean s.e.    SD  s.e\n1 4535 543.47 1.54 73.12 1.14\n\n\nただし，TIMSS1995だけは現在のTIMSSと調査設計が違うので注意が必要です。 SPSSファイルの場合，JRRの計算に必要なJKREP変数が小文字になっているので， そのままだとintsvyが動きません。 PVの変数名も小文字なので，引数もpaste0(\"asssci0\", 1:5)になります。 さらにTIMSS1995では第3学年も調査対象になっていたので， 第4学年のデータを得るには引数byに学年（IDGRADE変数）を指定する必要もあります。\n\nurl_95 &lt;- \"https://raw.githubusercontent.com/kawa5902/LSAdata/refs/heads/main/timss1995/ASGJPNm1.sav\"\njpn95stu &lt;- foreign::read.spss(url_95,\n  use.value.labels = FALSE,\n  to.data.frame = TRUE, use.missings = FALSE\n)\n\nre-encoding from CP1252\n\n# jkrepをJKREPに変更\nnames(jpn95stu)[names(jpn95stu) == \"jkrep\"] &lt;- \"JKREP\"\n# byにIDGRADEを指定し，学年ごとに結果を出力\nintsvy::timss.mean.pv(paste0(\"asssci0\", 1:5), by = \"IDGRADE\", data = jpn95stu)\n\n  IDGRADE Freq   Mean s.e.    SD  s.e\n1       3 4306 501.03 1.63 73.68 1.29\n2       4 4306 553.18 1.74 72.50 1.21",
    "crumbs": [
      "実践編",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>TIMSSの分析</span>"
    ]
  },
  {
    "objectID": "data_prep.html",
    "href": "data_prep.html",
    "title": "16  LSAのデータを入手する",
    "section": "",
    "text": "16.1 TIMSSについて\n本書では日本のデータを使って話を進めてきましたが， せっかくの国際学力調査なのだから他国のデータも使いたいという人はいるでしょう。 そこで付録として，他国のデータを入手する方法について説明しておきます。 ただし，この章の作業を実行するには， RやPythonを自分のパソコンにインストールして操作する必要があります。 これは本書の範囲を超えていますので， いったんRやPythonを学んだ後に作業をすることをお薦めします1。\nPISAとTIMSSの概要で触れたように， TIMSSのデータは，IEAのウェブサイトからダウンロード可能です。 IEAのData Repositoryにアクセスし， 画面下部にある\"I agree to the terms and conditions\"をクリックすれば TIMSS1995からTIMSS2023までのデータが取得できます。 データの種類は，基本的に\"SPSS Data & Documentation\"を選択すればよいでしょう。 すべての国のデータが一度にダウンロードされるのでファイルサイズは1GB前後になります。 できるだけ安定した回線でダウンロードしてください。\nダウンロードしたファイル（zipファイルです）を解凍すると， DataフォルダにTIMSSのsavファイルが国ごとに保存されています。 ここから必要なデータを選んで分析に利用します。\nおそらく一番簡単な方法は，Colabにファイルをアップロードしてしまうことでしょう。 Colabへのファイルのアップロード方法を解説しているサイトはいくつかあるので， 「Colab ファイルのアップロード」といった単語で検索し，必要なファイルをアップロードしてください。\nなお，多数のファイルをアップロードするとColabが動かなくなることがあります。 その場合は，自分のPCにRをインストールして分析してみてください。",
    "crumbs": [
      "補足",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>LSAのデータを入手する</span>"
    ]
  },
  {
    "objectID": "data_prep.html#pisa",
    "href": "data_prep.html#pisa",
    "title": "16  LSAのデータを入手する",
    "section": "16.2 PISA",
    "text": "16.2 PISA\nPISAのデータは OECDのウェブサイト（PISA data and methodology） からダウンロード可能です。 PISA PUF Users Data Collectionへ アクセスして必要事項を記載したうえで，Public Use Files (PUFs)の利用に同意するとデータをダウンロードできます。\nPISAのデータファイルは，TIMSSと違い，すべての国のデータが1つのファイルにまとまっています。 そのため分析する前に「国ごとにファイルを分割する」という作業が必要になります。 分割せずに分析してもよいのですが，データのファイルサイズが大きいので， それなりにメモリを積んだPCでないとフリーズしてしまいます。\nさらに面倒なことに，PISA2012まではデータがtxtファイルで公開されています。 そのためtxtファイルをSPSSファイルに変換し，その上で国ごとにファイルを分割するという 作業が必要になります。 以下では，（1）PISA2012までのtxtファイルをSPSSファイルに分割する方法， （2）すべての国のデータを国ごとに分割する方法，の2つを解説します。\n\n16.2.1 PISA2012までのtxtファイルをSPSSファイルに変換する方法\nすべての国のデータが保存された巨大なtxtファイルを扱うという作業は，Rではちょっと面倒です。 そこで，Pythonを使ってtxtファイルをSPSSファイルに変換します。 Pythonのインストールについては，たとえば 「Windows版Pythonのインストール」 を参照してください。 なお，ColabにPISAのtxtファイルをアップロードしても， ファイルサイズが大きすぎてフリーズします。 そのため作業は自分のPCで行う必要があります。\nPythonをインストールしたら， 著者のGitHubから 「spsファイルを使ってtxtファイルをSPSSファイルに変換するプログラム」 （txt2csv_sps.py）をダウンロードし任意のフォルダに配置します。 さらに同じフォルダに，PISAのtxtファイルと，txtファイルをSPSSに変換するためのspsファイルを配置してください。 その上で，コマンドプロンプトを開いて以下のようにすると，PISAのcsvファイルを取得することができます。 ここでは，PISA2012の学校ファイル（INT_SCQ12_DEC03.txt）を例にしています。\npython txt2csv_sps.py \\\nINT_SCQ12_DEC03.txt \\\n\"SPSS syntax to read in school questionnaire data file.txt\" \\\npisa2012sch\nコードを実行すると，pisa2012sch.csvというcsvファイルが生成されます。\n\n\n16.2.2 PISAファイルを国ごとに分割する\nPISAのデータファイルは，すべての参加国・地域のデータを含んでいます。 学校ファイルはそれほどでもありませんが，生徒ファイルはサイズが大きく， 取り回しが厄介です。\nそのため国ごとにデータを分割し，必要に応じて利用することを薦めます。 この作業もColabで実行することは難しいので，自分のPCにRをインストールして作業したほうが良いでしょう。\n\npisa2012sch &lt;- read.csv(\"pisa2012sch.csv\")\ncnts &lt;- unique(pisa2012sch$CNT)\n\nfor (cnt in cnts) {\n  dat &lt;- subset(pisa2012sch, CNT == cnt)\n  filename &lt;- paste0(\"pisa2012\", cnt, \"sch.csv\")\n  write.csv(dat, file = filename, row.names = FALSE)\n}\n\nこのコードを実行すると，pisa2012JPNsch.csv等の名前のcsvファイルが生成されます。\n\n\n16.2.3 PISA2015以降\nPISA2015以降はSPSSやSASのファイルが公開されていますので， SPSSファイルをダウンロードしforeign::read.spss関数を使うことで，データを入手できます。 ただしファイルサイズが大きいので，Colabでは作業せず， 自分のPCにRをインストールして操作したほうが良いでしょう。 ここでは，PISA2015の生徒ファイル（CY6_MS_CMB_STU_QQQ）を読み込む操作を示しておきます。\n\npisa2015stu &lt;- foreign::read.spss(\n  \"CY6_MS_CMB_STU_QQQ.sav\", to.data.frame = TRUE,\n  use.value.labels = FALSE, use.missings = FALSE\n)\n\nいったんファイルを読み込んだら， PISAファイルを国ごとに分割すると同じ操作を行い， ファイルを国ごとに分割することを薦めます。 そうでないとファイルサイズが大きすぎて，データを読み込むだけで時間がかかるからです。",
    "crumbs": [
      "補足",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>LSAのデータを入手する</span>"
    ]
  },
  {
    "objectID": "data_prep.html#footnotes",
    "href": "data_prep.html#footnotes",
    "title": "16  LSAのデータを入手する",
    "section": "",
    "text": "ウェブ上にはRやPythonの使い方を解説したページが多数存在しますので， いずれかのページを参考にインストールやプログラムの実行方法を学ぶと良いと思います。↩︎",
    "crumbs": [
      "補足",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>LSAのデータを入手する</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "17  まとめ",
    "section": "",
    "text": "17.1 「なぜLSAを学ぶのか」への回答\n本書では，LSAに採用されている技術を学ぶとともに， PISAやTIMSSといったLSAのデータをRを使って分析してきました。 最後に，ここまでに学んだ知識を使い 「なぜLSAを学ぶのか」 という本書冒頭の問いに答えてみましょう。\nLSAを学ぶ理由は， そこで使われている技術を知らなければ 日本の学力実態やその変化を知ることができないからです。 学力の変化を捉えることができないということは， 社会の変化や教育政策の変化によって， 子どもたちがどのような影響を受けているか把握できないということです。 LSAが知られていない状況で日本の教育の問題点やその改善策を論じても意味はなく， 「いきあたりばったり」の教育政策にならざるを得ません。 日本の教育政策の問題点を指摘した書籍はいくつもありますが[1–4]， 問題を生み出す要因の一つに，そもそも本書で論じてきたような 適切に学力を把握する方法が知られていないことがあると言ってもよいでしょう。 教育政策の現状を医療に例えるなら， 「検査をせずに治療を進め，さらに治療の結果も確認していない」状態です。 これで日本の教育が良くなったとしても，それはただの偶然です。\nそして本書で私が言いたいことは，教育の検査（その一つがLSAです）は， 「それなりに難しい」ということです。 項目反応理論（IRT）を学ぶと理解できるようになりますが， 私たちが慣れ親しんだ「100点満点のテスト」（≒古典的テスト理論）では， 学力の変化を捉えることができません。 日本の教育界では，2020年頃から「学力の変化を捉えることができる」を謳い文句に， IRTがにわかに注目を集めています。 しかしIRTを導入したら，学力テストが自動的にLSAになるわけではありません。 推算値法（PVs）で学んだように， IRTの一般的な能力推定法（MLEやEAP）には母集団の能力推定に偏りが生じるという欠点があります。 この欠点を改善するにはテストの項目数を増やす必要がありますが， 180を超える項目を出題するのは，現実的な方法ではありません。 ですから，LSAでは条件づけたPVsを導入することが重要になります。 LSAを設計・実施する人はもちろんですが， 分析・解釈する人もPVsの適切な利用法を知っておく必要があるのです。\nIRTやPVsといった複雑な手法を組み込んだ調査を，毎年度， しかも全国のすべての児童生徒を対象に実施することはほぼ不可能です。 項目反応理論の章で説明したように， IRTを活かすには事前に十分な数の項目を用意しておく必要があります。 100を超える項目を用意し，項目の困難度や識別力といったパラメータを分析する作業には 1年でも短すぎるでしょう。 さらにIRTでは項目の秘匿が条件になるので， 不必要に多数の児童生徒を調査してしまうとせっかく用意した項目が漏洩し， IRTの前提が崩れる危険があります。 そのためLSAでは，標本抽出が有力な選択肢となるのです。\nもちろん，学校を対象とした調査で標本抽出を行うのは容易なことではありません。 さまざまな標本抽出法が存在しますし， 標本抽出に伴う推定値のズレや誤差をどうやって算出するかも難しい問題です。 標本ウェイトやReplication Methodsは， こうした問題に対処するために考案されてきた技術です。\n要するに，現代のLSAを理解するには （そしてPISAやTIMSS，あるいは全国学力・学習状況調査について発言するなら） 標本ウェイト・ Replication Method・ 項目反応理論・ 推算値法の4つの技術に関する知識が必要なのです。 そして，これらの知識は調査を実施する人はもちろんですが， 調査を分析する人や調査結果を解釈する人たちにも必要です。 そうでないと，誤った分析や解釈をしてしまうでしょう。 誤った分析や解釈は，当然ながら誤った教育政策につながっていきます。 日本の学校教育や教育政策について学力調査の結果をもとに論じる人は， 本書で示したような知識を身に着けておくべきなのです1。\n断っておきますが，本書はLSAの入門書に過ぎず， 本書が説明していない内容は多岐にわたります。 本書で示した最低限の内容を知らない人たちが教育政策を論じる （さらには教育政策を変更する）ところに， 日本の教育の大きな難点があるように私は思います。",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>まとめ</span>"
    ]
  },
  {
    "objectID": "summary.html#さらに学ぶために",
    "href": "summary.html#さらに学ぶために",
    "title": "17  まとめ",
    "section": "17.2 さらに学ぶために",
    "text": "17.2 さらに学ぶために\n本書はLSAについて学ぶための「とっかかり」に過ぎません。 そこで最後に，さらにLSAを学ぶためのヒントになる書籍をいくつか紹介しておきます。 トピックごとに紹介しますので，自身の興味・関心に合わせて学ぶとよいでしょう。",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>まとめ</span>"
    ]
  },
  {
    "objectID": "summary.html#社会調査について",
    "href": "summary.html#社会調査について",
    "title": "17  まとめ",
    "section": "17.3 社会調査について",
    "text": "17.3 社会調査について\n\n\n17.3.1 入門・社会調査法\n\n\n著者: 轟亮・ 杉野勇・ 平沢和司（編）\n出版社: 法律文化社\n発売日: 2021年（第4版）\n\n主に量的調査法を使った社会調査の入門書です。 第4版ではインターネット調査や研究倫理にも触れており，社会調査の基本を学べる良書です。\n\n\n17.3.2 入門・社会統計学\n\n\n著者: 杉野勇\n出版社: 法律文化社\n発売日: 2017年\n\nRを使って社会調査法の知識を学ぶテキストです。 同じ著者が書いた『入門・社会調査法』と合わせて読むと良いと思います。\n\n\n17.3.3 社会調査法\n\n\n著者: 伊達平和・高田聖治\n出版社: 学術図書出版社\n発売日: 2020年\n\n社会調査の入門書で，層化抽出や多段抽出，及び標準誤差の算出法について解説している点がポイントです。\n\n\n17.3.4 概説 標本調査法\n\n\n著者: 土屋隆裕\n出版社: 朝倉書店\n発売日: 2009年\n\n層化や多段抽出といった標本抽出法について解説しています。数式多めなので詳しく知りたい人向け。\n\n\n17.3.5 Analyzing Complex Survey Data\n\n\n著者: Eun Sul Lee & Ronald N. Forthofer\n出版社: Sage\n発売日: 2006年（2nd ed）\n\nSageのQuantitative Applications in the Social Sciences シリーズ（いわゆる「緑本」）。 Complex Surveyについて学ぶ場合，英語の方が早いです。\n\n\n17.3.6 Complex Surveys: A Guide to Analysis Using R\n\n\n著者: Thomas Lumley\n出版社: Wiley\n発売日: 2010年\n\nRのsurveyパッケージ開発者の本。RでComplex Surveyを分析する場合は必読。 いきなり読むと挫折するので注意。 ちなみに読まなくてもPISAやTIMSSは分析できます。\n\n\n17.3.7 データ分析の力\n\n\n著者: 伊藤公一朗\n出版社: 光文社新書\n発売日: 2017年\n\nデータから因果関係を見極める方法についてわかりやすく解説した新書。 数式なしで因果推論の概要を掴むために。\n\n\n17.3.8 欠測データ処理\n\n\n著者: 高橋将宜・渡辺美智子\n出版社: 共立出版\n発売日: 2017年\n\n多重代入法（Multiple Imputation: MI）のテキスト。Rによるコードも豊富に記載されています。 推算値を理解するにはMIの知識が必要ですし，調査データの分析で欠測処理は避けて通れないので必読。",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>まとめ</span>"
    ]
  },
  {
    "objectID": "summary.html#教育測定について",
    "href": "summary.html#教育測定について",
    "title": "17  まとめ",
    "section": "17.4 教育測定について",
    "text": "17.4 教育測定について\n\n\n17.4.1 テストは何を測るのか\n\n\n著者: 光永悠彦\n出版社: ナカニシヤ出版\n発売日: 2017年\n\n項目反応理論の入門書。まずはこの辺から始めると良いと思います。\n\n\n17.4.2 Rによる項目反応理論\n\n\n著者: 加藤健太郎・山田剛史・川端一光\n出版社: オーム社\n発売日: 2014年\n\nRで学ぶ項目反応理論の入門書。Rと項目反応理論の両方を学べます。\n\n\n17.4.3 心理統計学の基礎\n\n\n著者: 南風原朝和\n出版社: 有斐閣\n発売日: 2002年\n\nタイトルそのままに心理統計学の基礎を学べます。 社会統計学と心理統計学は微妙に違うので，社会調査に関心があるなら後回しでok。 逆に，個人（集団ではない）の能力測定に関心がある場合はこちらから。",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>まとめ</span>"
    ]
  },
  {
    "objectID": "summary.html#lsaについて",
    "href": "summary.html#lsaについて",
    "title": "17  まとめ",
    "section": "17.5 LSAについて",
    "text": "17.5 LSAについて\n\n\n17.5.1 PISA Data Analysis Manual: SPSS 2nd ed\n\n\n著者: OECD\n出版社: OECD Publishing\n発売日: 2009年\n\nPISAで利用されている技術と分析方法についてSPSSを使って解説した本（無料でダウンロード可）。 PISAの技術概要の基礎を知ることができます。\n\n\n17.5.2 PISA調査の解剖\n\n\n著者: 袰岩晶・篠原真子・篠原康正\n出版社: 東信堂\n発売日: 2019年\n\nPISA調査の技術概要について，日本語で解説したおそらく唯一の本。 初学者には難易度高めだが，LSAを語るための必読書。 Rによる解説付き。\n\n\n17.5.3 Handbook of International Large-Scale Assessment\n\n\n著者: Leslie Rutkowski, Matthias von Davier, David Rutkowski\n出版社: Routledge\n発売日: 2023年\n\nLSAの概要と2020年以降の話題についてまとめた本。 LSAでマルチレベルモデルや因果推論をするにはどうすればいいか（そして，標本ウェイトはどう扱うか？）について言及があるので， LSAを使って論文を書きたい人に役立ちます。 初学者には難易度高め。",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>まとめ</span>"
    ]
  },
  {
    "objectID": "summary.html#rについて",
    "href": "summary.html#rについて",
    "title": "17  まとめ",
    "section": "17.6 Rについて",
    "text": "17.6 Rについて\nRについては，ウェブ上に無料の資料が数多くあります。 むしろ多すぎて，どれを選べばいいのかわからない・・・というレベルかもしれません。 ここでは私が見つけたサイトを載せておきます。\n\nRによる社会調査データ分析の手引き：社会調査向けです。\n私たちのR：Rについて学びたい人向けです。\n\n\n\n17.6.1 Rユーザのための RStudio［実践］入門\n\n\n著者: 松村優哉・湯谷啓明・紀ノ定保礼・前田和寛\n出版社: 技術評論社\n発売日: 2021年\n\n本書ではほとんどスルーしていたtidyverseの入門書。 Rを使った現代的なデータ分析をするための本ですが，ある程度Rに慣れた後に学ぶのが吉。\n\n\n\n\n\n\n1. 小針誠. (2018年). アクティブラーニング—学校教育の理想と現実. 講談社現代新書.\n\n\n2. 寺沢拓敬. (2020年). 小学校英語のジレンマ. 岩波新書.\n\n\n3. 松岡亮二. (2021年). 教育論の新常識—格差・学力・政策・未来. 中公新書ラクレ.\n\n\n4. 川口俊明 (編). (2022年). 教育格差の診断書. 岩波書店.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>まとめ</span>"
    ]
  },
  {
    "objectID": "summary.html#footnotes",
    "href": "summary.html#footnotes",
    "title": "17  まとめ",
    "section": "",
    "text": "LSAを学ぶのは大変すぎるという方は，学力調査には言及せず， 日本の学校教育の在り方について論じればよいと思います。 もっともTIMSSはともかく，PISAや全国学力・学習状況調査に触れずに日本の学校教育を論じるというのは かなり難しい気もしますが・・・。↩︎",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>まとめ</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "1. 袰岩晶・篠原真子・篠原康正. (2019).\nPISA調査の解剖ー能力評価・調査のモデル. 東信堂.\n\n\n2. 杉野勇. (2017). 入門・社会統計学: 2\nステップで基礎から【Rで】学ぶ. 法律文化社.\n\n\n3. 伊達平和・高田聖治. (2020). 社会調査法. 学術図書出版社.\n\n\n4. 高橋将宜・渡辺美智子. (2017). 欠測データ処理. 共立出版.\n\n\n5. Wu, M. (2005). The role of plausible values in large-scale surveys.\nStudies in Educational Evaluation, 31(2-3), 114–128.\n\n\n6. 国立教育政策研究所. (2024). 生きるための知識と技能8\nOECD生徒の学習到達度調査（PISA）. 明石書店.\n\n\n7. 松岡亮二. (2021). 教育論の新常識—格差・学力・政策・未来.\n中公新書ラクレ.\n\n\n8. 川口俊明 (Ed.). (2022). 教育格差の診断書. 岩波書店.\n\n\n9. 川口俊明. (2020). 全国学力テストはなぜ失敗したのか.\n岩波書店.\n\n\n10. 小針誠. (2018). アクティブラーニング—学校教育の理想と現実.\n講談社現代新書.\n\n\n11. 寺沢拓敬. (2020). 小学校英語のジレンマ. 岩波新書.\n\n\n12. 加藤健太郎・山田剛史・川端一光. (2014).\nRによる項目反応理論. オーム社.\n\n\n13. 光永悠彦. (2017).\nテストは何を測るのか—項目反応理論の考え方. ナカニシヤ出版.\n\n\n14. Zheng, X. (2024). On generating plausible values for multilevel\nmodelling with large-scale-assessment data. British Journal of\nMathematical and Statistical Psychology, 77(1), 212–236.",
    "crumbs": [
      "参考文献"
    ]
  }
]